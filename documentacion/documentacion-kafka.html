<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="author" content="v1.3.5 2020-11-30">
<title>Kafka: Instalaci√≥n y operaciones</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="book">
<div id="header">
<h1>Kafka: Instalaci√≥n y operaciones</h1>
<div class="details">
<span id="author" class="author">v1.3.5 2020-11-30</span><br>
</div>
<div id="toc" class="toc">
<div id="toctitle">Contenidos</div>
<ul class="sectlevel1">
<li><a href="#_introducci√≥n_a_kafka">1. Introducci√≥n a Kafka</a></li>
<li><a href="#_zookeeper">2. Zookeeper</a>
<ul class="sectlevel2">
<li><a href="#_introducci√≥n">2.1. Introducci√≥n</a></li>
<li><a href="#_instalaci√≥n_de_zookeeper">2.2. Instalaci√≥n de Zookeeper</a>
<ul class="sectlevel3">
<li><a href="#_sistemas_operativos">2.2.1. Sistemas operativos</a></li>
<li><a href="#_java">2.2.2. java</a></li>
<li><a href="#_producci√≥n">2.2.3. Producci√≥n</a></li>
<li><a href="#_lab_instalaci√≥n_de_zookeeper">2.2.4. Lab: Instalaci√≥n de Zookeeper</a></li>
</ul>
</li>
<li><a href="#_configuraci√≥n">2.3. Configuraci√≥n</a></li>
<li><a href="#_ejecuci√≥n">2.4. Ejecuci√≥n</a></li>
<li><a href="#_operaciones_de_zookeeper">2.5. Operaciones de Zookeeper</a>
<ul class="sectlevel3">
<li><a href="#_ejemplos">2.5.1. Ejemplos</a></li>
<li><a href="#_creaci√≥n_del_grupo">2.5.2. Creaci√≥n del grupo</a></li>
<li><a href="#_unirse_a_un_grupo">2.5.3. Unirse a un grupo</a></li>
<li><a href="#_encontrar_a_los_miembros_en_un_grupo">2.5.4. Encontrar a los miembros en un grupo</a></li>
<li><a href="#_eliminar_un_miembro">2.5.5. Eliminar un miembro</a></li>
<li><a href="#_eliminaci√≥n_de_un_grupo">2.5.6. Eliminaci√≥n de un grupo</a></li>
<li><a href="#_lab_operaciones_con_zookeeper">2.5.7. Lab: Operaciones con Zookeeper</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_instalaci√≥n_de_kafka">3. Instalaci√≥n de Kafka</a>
<ul class="sectlevel2">
<li><a href="#_lab_instalaci√≥n_de_kafka">3.1. Lab: Instalaci√≥n de kafka</a>
<ul class="sectlevel3">
<li><a href="#_instalaci√≥n_de_software">3.1.1. Instalaci√≥n de software</a></li>
<li><a href="#_puesta_en_marcha">3.1.2. Puesta en marcha</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_topics">4. Topics</a>
<ul class="sectlevel2">
<li><a href="#_lab_creaci√≥n_de_topics_y_particionado">4.1. Lab: Creaci√≥n de Topics y particionado</a>
<ul class="sectlevel3">
<li><a href="#_creaci√≥n_de_topic">4.1.1. Creaci√≥n de topic</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_productores_y_consumidores">5. Productores y consumidores</a>
<ul class="sectlevel2">
<li><a href="#_lab_produciendo_y_consumiendo">5.1. Lab: Produciendo y consumiendo</a></li>
</ul>
</li>
<li><a href="#_log_compaction">6. Log Compaction</a>
<ul class="sectlevel2">
<li><a href="#_configuraci√≥n_2">6.1. Configuraci√≥n</a></li>
<li><a href="#_tuning">6.2. Tuning</a>
<ul class="sectlevel3">
<li><a href="#_log_cleaner_dedupe_buffer_size">6.2.1. log.cleaner.dedupe.buffer.size</a></li>
<li><a href="#_log_cleaner_threads">6.2.2. log.cleaner.threads</a></li>
<li><a href="#_particiones">6.2.3. particiones</a></li>
<li><a href="#_min_cleanable_dirty_ratio">6.2.4. min.cleanable.dirty.ratio</a></li>
</ul>
</li>
<li><a href="#_lab_log_compaction">6.3. Lab: Log compaction</a></li>
</ul>
</li>
<li><a href="#_configuraci√≥n_de_kafka">7. Configuraci√≥n de kafka</a>
<ul class="sectlevel2">
<li><a href="#_configuraci√≥n_del_broker">7.1. Configuraci√≥n del Broker</a></li>
<li><a href="#_optimizaci√≥n">7.2. Optimizaci√≥n</a>
<ul class="sectlevel3">
<li><a href="#_message_max_bytes">7.2.1. message.max.bytes</a></li>
<li><a href="#_num_replica_fetchers">7.2.2. num.replica.fetchers</a></li>
<li><a href="#_replica_fetch_max_bytes">7.2.3. replica.fetch.max.bytes</a></li>
<li><a href="#_replica_socket_receive_buffer_bytes">7.2.4. replica.socket.receive.buffer.bytes</a></li>
<li><a href="#_num_partitions">7.2.5. num.partitions</a></li>
<li><a href="#_num_io_threads">7.2.6. num.io.threads</a></li>
<li><a href="#_num_recovery_threads_per_data_dir">7.2.7. num.recovery.threads.per.data.dir</a></li>
</ul>
</li>
<li><a href="#_lab_creaci√≥n_de_un_cl√∫ster_multi_broker">7.3. Lab: Creaci√≥n de un Cl√∫ster Multi-Broker</a></li>
<li><a href="#_configuraci√≥n_del_topic">7.4. Configuraci√≥n del Topic</a></li>
<li><a href="#_lab_configurar_particiones_y_r√©plicas">7.5. Lab: Configurar particiones y r√©plicas</a></li>
<li><a href="#_configuraci√≥n_de_producers">7.6. Configuraci√≥n de Producers</a></li>
<li><a href="#_configuraci√≥n_de_consumers">7.7. Configuraci√≥n de Consumers</a></li>
</ul>
</li>
<li><a href="#_operaciones_con_kafka">8. Operaciones con Kafka</a>
<ul class="sectlevel2">
<li><a href="#_utilidades_y_herramientas">8.1. Utilidades y herramientas</a>
<ul class="sectlevel3">
<li><a href="#_kafka_preferred_replica_election_sh_deprecada">8.1.1. kafka-preferred-replica-election.sh (deprecada)</a></li>
<li><a href="#_kafka_leader_election_sh">8.1.2. kafka-leader-election.sh</a></li>
<li><a href="#_kafka_mirror_maker_sh">8.1.3. kafka-mirror-maker.sh</a></li>
<li><a href="#_kafka_replay_log_producer_sh">8.1.4. kafka-replay-log-producer.sh</a></li>
<li><a href="#_kafka_replica_verification_sh">8.1.5. kafka-replica-verification.sh</a></li>
<li><a href="#_kafka_broker_api_versions_sh">8.1.6. kafka-broker-api-versions.sh</a></li>
<li><a href="#_kafka_consumer_groups_sh">8.1.7. kafka-consumer-groups.sh</a></li>
</ul>
</li>
<li><a href="#_lab_balanceando_las_particiones">8.2. Lab: Balanceando las particiones</a></li>
<li><a href="#_crecimiento_de_un_cl√∫ster">8.3. Crecimiento de un cl√∫ster</a></li>
<li><a href="#_lab_crecimiento_del_cluster">8.4. Lab: Crecimiento del cluster</a></li>
<li><a href="#_kafka_tools">8.5. Kafka Tools</a>
<ul class="sectlevel3">
<li><a href="#_clone">8.5.1. Clone</a></li>
<li><a href="#_trim">8.5.2. trim</a></li>
<li><a href="#_remove">8.5.3. remove</a></li>
<li><a href="#_elect">8.5.4. elect</a></li>
<li><a href="#_set_replication_factor">8.5.5. set-replication-factor</a></li>
<li><a href="#_reorder">8.5.6. reorder</a></li>
<li><a href="#_balance">8.5.7. balance</a></li>
</ul>
</li>
<li><a href="#_lab_usando_kafka_tools">8.6. Lab: Usando Kafka Tools</a></li>
</ul>
</li>
<li><a href="#_desarrollo_con_kafka">9. Desarrollo con kafka</a>
<ul class="sectlevel2">
<li><a href="#_implementaci√≥n_kafka">9.1. Implementaci√≥n kafka</a></li>
<li><a href="#_lenguaje_de_programaci√≥n">9.2. Lenguaje De programaci√≥n</a></li>
<li><a href="#_objetivo">9.3. Objetivo</a></li>
<li><a href="#_lab_instalaci√≥n_del_entorno_de_desarrollo_de_kafka">9.4. Lab: Instalaci√≥n del entorno de desarrollo de Kafka</a>
<ul class="sectlevel3">
<li><a href="#_ejecuci√≥n_de_prueba">9.4.1. Ejecuci√≥n de prueba</a></li>
<li><a href="#_preparaci√≥n_de_proyecto_plantilla">9.4.2. Preparaci√≥n de proyecto plantilla</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_kafka_java_api">10. Kafka Java API</a>
<ul class="sectlevel2">
<li><a href="#_dependencias">10.1. Dependencias</a></li>
<li><a href="#_api_para_producer">10.2. API para Producer</a></li>
<li><a href="#_api_para_consumer">10.3. API para Consumer</a></li>
<li><a href="#_garant√≠a_de_entrega">10.4. Garant√≠a de entrega</a>
<ul class="sectlevel3">
<li><a href="#_at_most_once">10.4.1. At most once</a></li>
<li><a href="#_at_least_once">10.4.2. At least once</a></li>
<li><a href="#_exactly_once">10.4.3. Exactly-once</a></li>
</ul>
</li>
<li><a href="#_lab_invocando_productores_y_consumidores">10.5. Lab: Invocando productores y consumidores</a>
<ul class="sectlevel3">
<li><a href="#_creaci√≥n_de_topics">10.5.1. Creaci√≥n de topics</a></li>
<li><a href="#_creaci√≥n_de_productor">10.5.2. Creaci√≥n de productor</a></li>
<li><a href="#_simple_consumer">10.5.3. Simple Consumer</a></li>
<li><a href="#_prueba_de_ejecuci√≥n">10.5.4. Prueba de ejecuci√≥n</a></li>
<li><a href="#_partitionproducer">10.5.5. PartitionProducer</a></li>
<li><a href="#_groups">10.5.6. Groups</a></li>
<li><a href="#_autocommit">10.5.7. Autocommit</a></li>
<li><a href="#_partitionconsumer">10.5.8. PartitionConsumer</a></li>
<li><a href="#_seekconsumer">10.5.9. SeekConsumer</a></li>
<li><a href="#_consumer_info">10.5.10. Consumer Info</a></li>
<li><a href="#_transaccionalidad">10.5.11. Transaccionalidad</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_esquemas_en_kafka">11. Esquemas en Kafka</a>
<ul class="sectlevel2">
<li><a href="#_tipos_de_serializaci√≥n_en_kafka">11.1. Tipos de serializaci√≥n en kafka</a>
<ul class="sectlevel3">
<li><a href="#_ejemplos_esquemas_idl">11.1.1. Ejemplos Esquemas-IDL</a></li>
</ul>
</li>
<li><a href="#_avro">11.2. Avro</a></li>
<li><a href="#_esquemas_de_avro">11.3. Esquemas de Avro</a></li>
<li><a href="#_tipos_de_datos">11.4. Tipos de datos</a>
<ul class="sectlevel3">
<li><a href="#_compactaci√≥n">11.4.1. Compactaci√≥n</a></li>
<li><a href="#_integraci√≥n">11.4.2. Integraci√≥n</a></li>
</ul>
</li>
<li><a href="#_esquemas_en_avro">11.5. Esquemas en Avro</a></li>
</ul>
</li>
<li><a href="#_schema_registry">12. Schema Registry</a>
<ul class="sectlevel2">
<li><a href="#_integraci√≥n_de_datos">12.1. Integraci√≥n de datos</a></li>
<li><a href="#_flujo_de_trabajo">12.2. Flujo de trabajo</a></li>
<li><a href="#_ejemplos_2">12.3. Ejemplos</a></li>
<li><a href="#_estrategias_de_nombres">12.4. Estrategias de nombres.</a></li>
</ul>
</li>
<li><a href="#_kafka_streams_api">13. Kafka Streams API</a>
<ul class="sectlevel2">
<li><a href="#_caracter√≠sticas">13.1. Caracter√≠sticas</a></li>
<li><a href="#_streams">13.2. Streams</a></li>
<li><a href="#_kstreams_y_ktables">13.3. KStreams y KTables</a>
<ul class="sectlevel3">
<li><a href="#_kstream">13.3.1. KStream</a></li>
<li><a href="#_ktable">13.3.2. KTable</a></li>
<li><a href="#_gobalktable">13.3.3. GobalKTable</a></li>
</ul>
</li>
<li><a href="#_ventanas_windows">13.4. Ventanas (Windows)</a></li>
<li><a href="#_transformaciones">13.5. Transformaciones</a>
<ul class="sectlevel3">
<li><a href="#_transformaciones_sin_estado">13.5.1. Transformaciones sin estado</a></li>
<li><a href="#_transformaciones_con_estado">13.5.2. Transformaciones con estado</a></li>
</ul>
</li>
<li><a href="#_salida_de_datos">13.6. Salida de datos</a></li>
<li><a href="#_estado_en_streams">13.7. Estado en Streams</a>
<ul class="sectlevel3">
<li><a href="#_transform_processor">13.7.1. Transform Processor</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_kafka_connect">14. Kafka Connect</a>
<ul class="sectlevel2">
<li><a href="#_tipos">14.1. Tipos</a></li>
<li><a href="#_modos_de_ejecuci√≥n">14.2. Modos de ejecuci√≥n</a></li>
<li><a href="#_replicator">14.3. Replicator</a>
<ul class="sectlevel3">
<li><a href="#_caracter√≠sticas_2">14.3.1. Caracter√≠sticas</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_monitorizaci√≥n_de_kafka">15. Monitorizaci√≥n de Kafka</a>
<ul class="sectlevel2">
<li><a href="#_m√©tricas_de_los_brokers">15.1. M√©tricas de los Brokers</a>
<ul class="sectlevel3">
<li><a href="#_sistemas">15.1.1. Sistemas</a></li>
</ul>
</li>
<li><a href="#_m√©tricas_de_los_consumidores_y_productores">15.2. M√©tricas de los Consumidores y Productores</a></li>
<li><a href="#_herramientas_java_para_monitorizar">15.3. Herramientas JAVA para monitorizar</a>
<ul class="sectlevel3">
<li><a href="#_gcviewer">15.3.1. GCViewer</a></li>
<li><a href="#_visualgc">15.3.2. visualgc</a></li>
<li><a href="#_jconsole">15.3.3. JConsole</a></li>
<li><a href="#_jvisualvm">15.3.4. JVisualVM</a></li>
<li><a href="#_jcmd">15.3.5. JCMD</a></li>
<li><a href="#_jmc">15.3.6. JMC</a></li>
</ul>
</li>
<li><a href="#_jmx_brokers">15.4. JMX - Brokers</a>
<ul class="sectlevel3">
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_underreplicatedpartitions">15.4.1. JMX MBean: kafka.server:type=ReplicaManager.UnderReplicatedPartitions</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypekafkacontroller_offlinepartitionscount">15.4.2. JMX MBean: kafka.controller:type=KafkaController.OfflinePartitionsCount</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypekafkacontroller_activecontrollercount">15.4.3. JMX MBean: kafka.controller:type=KafkaController.ActiveControllerCount*</a></li>
<li><a href="#_jmx_mbean_kafka_servertypebrokertopicmetrics_bytesinoutpersec">15.4.4. JMX MBean: kafka.server:type=BrokerTopicMetrics.Bytes[In,Out]PerSec</a></li>
<li><a href="#_jmx_mbean_kafka_servertypebrokertopicmetrics_messagesinpersec">15.4.5. JMX MBean: kafka.server:type=BrokerTopicMetrics.MessagesInPerSec</a></li>
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_partitionscount">15.4.6. JMX MBean: kafka.server:type=ReplicaManager.PartitionsCount</a></li>
<li><a href="#_jmx_mbean_kafka_servertypereplicamanager_leadercount">15.4.7. JMX MBean: kafka.server:type=ReplicaManager.LeaderCount</a></li>
<li><a href="#_jmx_mbean_kafka_networktyperequestmetrics_tipo_nombre">15.4.8. JMX MBean: kafka.network:type=RequestMetrics.[tipo].[nombre]</a></li>
<li><a href="#_topicnombre_topicpartitionparticion">15.4.9. &#8230;&#8203;,topic=[nombre_topic],partition=[particion]</a></li>
<li><a href="#_jmx_mbean_kafka_controllertypecontrollerstats_uncleanleaderelectionspersec">15.4.10. JMX MBean: kafka.controller:type=ControllerStats.UncleanLeaderElectionsPerSec</a></li>
</ul>
</li>
<li><a href="#_jmx_productores">15.5. JMX - Productores</a></li>
<li><a href="#_jmx_consumidores">15.6. JMX - Consumidores</a>
<ul class="sectlevel3">
<li><a href="#_jmx_mbeankafka_consumertypeconsumer_fetch_manager_metricsclient_idclient_idtopictopic_name">15.6.1. JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id][,topic=&lt;topic_name]</a></li>
<li><a href="#_jmx_mbeankafka_consumertypeconsumer_coordinator_metricsclient_idclient_idtopictopic_name">15.6.2. JMX MBean:kafka.consumer:type=consumer-coordinator-metrics,client-id=[client_id][,topic=&lt;topic_name]</a></li>
<li><a href="#_lag">15.6.3. Lag</a></li>
<li><a href="#_cuotas">15.6.4. Cuotas</a></li>
</ul>
</li>
<li><a href="#_lab_monitorizacion">15.7. Lab: Monitorizacion</a>
<ul class="sectlevel3">
<li><a href="#_cmak">15.7.1. CMAK</a></li>
<li><a href="#_burrow">15.7.2. Burrow</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_seguridad_en_kafka">16. Seguridad en Kafka</a>
<ul class="sectlevel2">
<li><a href="#_c√≥mo_funciona_la_seguridad">16.1. C√≥mo funciona la seguridad</a></li>
<li><a href="#_certificados_keystores_y_trustores">16.2. Certificados, Keystores y Trustores</a></li>
<li><a href="#_seguridad_en_clientes">16.3. Seguridad en clientes</a>
<ul class="sectlevel3">
<li><a href="#_sasl">16.3.1. SASL</a></li>
</ul>
</li>
<li><a href="#_autenticaci√≥n_sasl">16.4. Autenticaci√≥n SASL</a>
<ul class="sectlevel3">
<li><a href="#_sasl_plaintext">16.4.1. SASL PLAINTEXT</a></li>
<li><a href="#_sasl_scram">16.4.2. SASL SCRAM</a></li>
<li><a href="#_sasl_gssapi_kerberos">16.4.3. SASL GSSAPI (Kerberos)</a></li>
</ul>
</li>
<li><a href="#_autorizaci√≥n">16.5. Autorizaci√≥n</a>
<ul class="sectlevel3">
<li><a href="#_operaciones">16.5.1. Operaciones</a></li>
<li><a href="#_recursos">16.5.2. Recursos</a></li>
</ul>
</li>
<li><a href="#_lab_aplicando_seguridad_en_kafka">16.6. Lab: Aplicando seguridad en Kafka</a>
<ul class="sectlevel3">
<li><a href="#_creaci√≥n_del_keystore_y_la_pareja_de_claves_p√∫blicaprivada">16.6.1. Creaci√≥n del keystore y la pareja de claves p√∫blica/privada</a></li>
<li><a href="#_securizando_los_brokers">16.6.2. Securizando los Brokers</a></li>
<li><a href="#_securizando_los_clientes">16.6.3. Securizando los Clientes</a></li>
<li><a href="#_autenticar_clientes">16.6.4. Autenticar clientes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introducci√≥n_a_kafka">1. Introducci√≥n a Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Kafka</strong> es un sistema <strong>distribuido</strong> para el procesamiento de <strong>streams</strong>, escrito en <strong>Scala</strong> y <strong>Java</strong>.</p>
</li>
<li>
<p>El objetivo de <strong>Kafka</strong> es ofrecer una plataforma de baja latencia y alto rendimiento para gestionar feedings en tiempo real. Para ello, dispone de una capa de almacenamiento de tipo publicador/suscriptor altamente escalable (basado en transaction logs).</p>
</li>
<li>
<p><strong>Kafka</strong> permite conectar a m√∫ltiples sistemas para importar o exportar informaci√≥n, y ofrece un <strong>API</strong> de <strong>Java</strong> para procesar los streams.</p>
</li>
<li>
<p>Para usar <strong>Kafka</strong>, es imprescindible disponer de <strong>Zookeeper</strong>, ya que es vital para descubrir los <strong>brokers</strong>, y tambi√©n para guardar la configuraci√≥n a nivel de <strong>topic</strong></p>
</li>
<li>
<p><strong>Kafka</strong> es un proyecto desarrollado por <strong>LinkedIn</strong>.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-01.png" alt="kafka introduccion 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En 2011, <strong>Kafka</strong> es liberado y se convierte en un proyecto de <strong>c√≥digo abierto</strong>, gestionado por la <strong>Apache software foundation</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-02.png" alt="kafka introduccion 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En noviembre de 2014, varios ingenieros que trabajaban desarrollando <strong>Kafka</strong> en <strong>LinkedIn</strong>, crearon una nueva compa√±√≠a llamada <strong>Confluent</strong>, centrada en dicho proyecto.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-03.png" alt="kafka introduccion 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El nombre del proyecto, se debe al escritor <strong>Franz Kafka</strong>, puesto que es un "sistema optimizado para escribir"</p>
</li>
<li>
<p><strong>Kafka</strong> est√° compuesto por tres tipos de componentes:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Productores</strong></p>
</li>
<li>
<p><strong>Consumidores</strong></p>
</li>
<li>
<p><strong>Colas</strong> (o topics)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> Puede usarse de dos formas:</p>
<div class="ulist">
<ul>
<li>
<p>Como un modelo de colas, donde los mensajes son distribuidos a los clientes</p>
</li>
<li>
<p>Como un modelo de publicador/suscriptor, donde el mismo mensaje es enviado a los distintos clientes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-introduccion-04.png" alt="kafka introduccion 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para ello, <strong>Kafka</strong> dispone de un <strong>Broker</strong>. Este es el servidor principal de <strong>Kafka</strong>, sus funciones son:</p>
<div class="ulist">
<ul>
<li>
<p>Almacena los distintos topics</p>
</li>
<li>
<p>Se encarga de gestionar las particiones</p>
</li>
<li>
<p>Se encarga de gestionar d√≥nde se realizan las escrituras en disco</p>
</li>
<li>
<p>Tambi√©n controla la seguridad</p>
</li>
<li>
<p>Se utiliza para crear cl√∫sters y poder escalar el servicio (para ello, usa <strong>Zookeeper</strong>)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect1">
<h2 id="_zookeeper">2. Zookeeper</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introducci√≥n">2.1. Introducci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>ZooKeeper es un servicio de coordinaci√≥n distribuido para la construcci√≥n de aplicaciones distribuidas generales.</p>
</li>
<li>
<p>Escribir aplicaciones distribuidas es dif√≠cil. Es duro principalmente debido al fracaso parcial.</p>
</li>
<li>
<p>ZooKeeper no puede hacer que los fallos parciales desaparezcan, ya que son intr√≠nsecos a los sistemas distribuidos.</p>
</li>
<li>
<p>Lo que hace ZooKeeper es proporcionar un grupo de herramientas para construir aplicaciones distribuidas que pueden manejar de forma segura
los fallos.</p>
</li>
<li>
<p>Caracter√≠sticas:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Simple</strong>: es, en su n√∫cleo, un sistema de archivos desnudo que expone algunas simples operaciones y algunas extraciones extra, tales como ordenaciones y notificaciones.</p>
</li>
<li>
<p><strong>Expresivo</strong>: las primitivas de ZooKeeper son un grupo rico de bloques de construcci√≥n que se pueden utilizar para construir una gran clase de estructuras de datos de coordinaci√≥n y protocolos.
Por ejemplo se incluyen colas distribuidas, bloqueos distribuidas y elecci√≥n de l√≠deres entre un grupo de compa√±eros.</p>
</li>
<li>
<p><strong>Disponible</strong>: se ejecuta en una colecci√≥n de m√°quinas y est√° dise√±ado para tener alta disponibilidad. Puede ayudarnos a evitar la introducci√≥n de puntos individuales de fallos en su sistema.</p>
</li>
<li>
<p><strong>Facilita las interacciones poco acopladas</strong>: las interacciones se apoyan en los participantes, que no necesitan saber unos de otros, utilizando un mecanismo de encuentro.</p>
</li>
<li>
<p><strong>Es una librer√≠a</strong>: que proporciona un repositorio compartido de implementaciones y recetas de c√≥digo abierto y patrones comunes de coordinaci√≥n. A los programadores individuales se les ahorra la carga de
escribiendo protocolos comunes ellos mismos.</p>
</li>
<li>
<p><strong>Es de alto rendimiento</strong>. En Yahoo!, donde se cre√≥, el rendimiento de un grupo de ZooKeeper se ha comparado con m√°s de 10.000 operaciones por segundo para escritura dominantes generadas por cientos de clientes.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_instalaci√≥n_de_zookeeper">2.2. Instalaci√≥n de Zookeeper</h3>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta cuales son los requisitos de instalaci√≥n de Zookeeper.</p>
</li>
<li>
<p>Se trata de una herramienta java, pero que debe instalarse en ciertos sistemas operativos.</p>
</li>
<li>
<p>Hay que tener en cuenta que tenemos cuatro componentes de instalaci√≥n distintos:</p>
<div class="ulist">
<ul>
<li>
<p>Client: Se trata de las librerias java cliente, que permiten conectarse a Zookeeper</p>
</li>
<li>
<p>Server: Se trata del servicio java que se ejecuta en los nodos de Zookeeper</p>
</li>
<li>
<p>Native Client: Se trata de un cliente implementado en C que permite conectarse a Zookeeper</p>
</li>
<li>
<p>Contrib: Se trata de los add-ons opcionales de zookeeper.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para ver como instalarlo, debemos observar las limitaciones de sistemas operativos:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sistemas_operativos">2.2.1. Sistemas operativos</h4>
<div class="ulist">
<ul>
<li>
<p>Dependiendo si est√° orientado para desarrollo o producci√≥n, existen distintas opciones:</p>
<div class="ulist">
<ul>
<li>
<p>GNU/Linux: Sirve tanto para cliente, servidor, cliente nativo y addons en entornos de desarrollo y producci√≥n</p>
</li>
<li>
<p>Solaris, FreeBSD, Windows: Sirve para cliente y servidor en entornos de desarrollo y producci√≥n, sin embargo no est√° soportado el cliente nativo ni los addons de terceros</p>
</li>
<li>
<p>OSX: Solo sirve para cliente y servidor en modo desarrollo. No est√° soportado el cliente nativo ni los addons de terceros</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_java">2.2.2. java</h4>
<div class="ulist">
<ul>
<li>
<p>En cuanto a la versi√≥n de java, es imprescindible conocer que versi√≥n de java es compatible con Zookeeper.</p>
<div class="ulist">
<ul>
<li>
<p>Java 8 (OpenJDK, Oracle)como versi√≥n m√≠nima</p>
</li>
<li>
<p>Java 11 OpenJDK LTS</p>
</li>
</ul>
</div>
</li>
<li>
<p>Tambi√©n es posible instalarlo en java 12 y 13, pero no en java 9 y 10</p>
</li>
<li>
<p>La recomendaci√≥n es usar la √∫ltima LTS compatible, que en este caso es la 11</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_producci√≥n">2.2.3. Producci√≥n</h4>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que zookeeper es la base de m√∫ltiples aplicaciones.</p>
</li>
<li>
<p>Kafka usa Zookeeper para los metadatos del cluster y es un sistema cr√≠tico.</p>
</li>
<li>
<p>En caso de perder Zookeeper, el mapa de las particiones asignadas a los brokers y las configuraciones de los topics se perder√°n, perdiendo la funcionalidad, y por ende, todos los datos.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_memoria">2.2.3.1. Memoria</h5>
<div class="ulist">
<ul>
<li>
<p>Un cluster de zookeeper no posee un uso intensivo de memoria. La memoria f√≠sica necesaria escala seg√∫n el n√∫mero de znodes que posea.</p>
</li>
<li>
<p>A mayor n√∫mero de particiones, mayor el uso de memoria de Zookeeper.</p>
</li>
<li>
<p>Un punto de partida ser√≠a los 4GB de ram para entornos de producci√≥n.</p>
</li>
<li>
<p>Se debe evitar el uso de SWAP en estos sistemas.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_cpu">2.2.3.2. CPU</h5>
<div class="ulist">
<ul>
<li>
<p>Zookeeper no posee un uso intensivo de cpu.</p>
</li>
<li>
<p>Si el sistema est√° compartido con otros servicios, es imprescindible la dedicaci√≥n de una CPU a zookeeper, ya que es sensible a la latencia.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_discos">2.2.3.3. Discos</h5>
<div class="ulist">
<ul>
<li>
<p>Se recomienda el uso de SSDs para poseer baja latencia de escritura en disco con un tama√±o de 64GB.</p>
</li>
<li>
<p>Cada petici√≥n en Zookeeper se debe almacenar en disco en cada servidor en el quorum antes de que est√© disponible para lectura.</p>
</li>
<li>
<p>Para evitar mantenimientos es recomendable definir (para versiones superiores a la 3.4.0):</p>
<div class="ulist">
<ul>
<li>
<p><strong>autopurge.purgeInterval</strong>: Intervalo en horas para que la tarea de purga se dispare. Por defecto est√° deshabilitado</p>
</li>
<li>
<p><strong>autopurge.snapRetainCount</strong>: Permite definir el almacenamiento de los √∫ltimos snapshots y logs de transacciones en el directorio de datos. Por defecto es 3</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>autopurge.purgeInterval: 12
autopurge.snapRetainCount: 4</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma conseguimos limpiar zookeeper y evitar mantenimientos costosos.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_m√°quina_virtual">2.2.3.4. M√°quina virtual</h5>
<div class="ulist">
<ul>
<li>
<p>El uso del heap en Zookeeper no es intensivo, con 1GB deber√≠a ser suficiente, aunque se debe monitorizar para comprobar que las recolecciones de basura de la m√°quina virtual no pasan continuamente.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_alta_disponibilidad">2.2.3.5. Alta disponibilidad</h5>
<div class="ulist">
<ul>
<li>
<p>En un entorno de producci√≥n, los servidores de zookeeper deben desplegarse en m√∫ltiples nodos.</p>
<div class="ulist">
<ul>
<li>
<p>Los servidores deben estar en un conjunto de 2n+1, donde n debe ser 0 o m√°s. Es decir, deben ser impares.</p>
</li>
<li>
<p>Permite poseer elecciones de mayor√≠a en caso de la caida de n servidores.</p>
</li>
<li>
<p>Si queremos una tolerancia de dos servidores fallidos, debemos usar n=2:</p>
<div class="ulist">
<ul>
<li>
<p>2*2 + 1 = 5</p>
</li>
</ul>
</div>
</li>
<li>
<p>De esta forma mantendremos el sistema en alta disponibilidad.</p>
</li>
<li>
<p>Se suele comenzar con sistemas de tolerancia 1 o 2, con 3 o 5 instancias de servidor.</p>
</li>
<li>
<p>Hay que pensar que cuando se realiza una operaci√≥n de escritura, se debe propagar y confirmar en todos los miembros.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se recomienda poseer un sistema redundado de red y no alojarlo en el mismo rack</p>
</li>
<li>
<p>En caso de usar virtualizaci√≥n, es recomendable usar distintas zonas de disponibilidad</p>
</li>
<li>
<p>Ante la duda, es mejor comenzar con un sistema simple y controlado de tres nodos en producci√≥n y ampliarlo solo si es necesario.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect3">
<h4 id="_lab_instalaci√≥n_de_zookeeper">2.2.4. Lab: Instalaci√≥n de Zookeeper</h4>
<div class="ulist">
<ul>
<li>
<p>Para probar ZooKeeper, es m√°s sencillo ejecutarlo en modo independiente con un solo servidor de ZooKeeper.</p>
</li>
<li>
<p>Podemos hacerlo en una m√°quina de desarrollo, por ejemplo.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_requisitos">2.2.4.1. Requisitos</h5>
<div class="ulist">
<ul>
<li>
<p>Java.</p>
</li>
<li>
<p>Descargar una versi√≥n estable de ZooKeeper de Apache ZooKeeper, y desempaquetar el tarball en un lugar adecuado (/usr/local/zookeeper o /opt/zookeeper):</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En nuestra m√°quina virtual, el software del curso se ha descargado en /home/kafka/Desktop/software</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_instalaci√≥n">2.2.4.2. Instalaci√≥n</h5>
<div class="ulist">
<ul>
<li>
<p>Para instalarlo, primero comprobamos que poseemos la versi√≥n de java correcta, ya que en sistema operativo, cumplimos las mejores condiciones con Linux.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Prueba de versi√≥n de java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java -version
openjdk version &quot;11.0.8&quot; 2020-07-14 LTS
OpenJDK Runtime Environment 18.9 (build 11.0.8+10-LTS)
OpenJDK 64-Bit Server VM 18.9 (build 11.0.8+10-LTS, mixed mode, sharing)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos comprobar como la versi√≥n de java es la 11</p>
</li>
<li>
<p>Ahora descomprimimos el software de kafka en /opt</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Comandos de instalaci√≥n de zookeeper</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd Desktop/software/
[kafka@kafka-server software]$ tar xf apache-zookeeper-*-bin.tar.gz
[kafka@kafka-server software]$ sudo mv apache-zookeeper-*-bin /opt/apache-zookeeper</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A√±adimos las variables de entorno al sistema para facilitar su uso:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creaci√≥n de variables de inicio para todos los usuarios</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ echo export ZOOKEEPER_HOME=/opt/apache-zookeeper &gt;&gt; zookeeper_path.sh
[kafka@kafka-server software]$ echo 'export PATH=${PATH}:${ZOOKEEPER_HOME}/bin' &gt;&gt; zookeeper_path.sh
[kafka@kafka-server software]$ sudo mv zookeeper_path.sh /etc/profile.d/
[kafka@kafka-server software]$ sudo chmod ugo+x /etc/profile.d/zookeeper_path.sh</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, para evitar tener que reiniciar el entorno gr√°fico para aplicar las variables lanzamos la siguiente sentencia</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creaci√≥n de variables de inicio para todos los usuarios</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ source /etc/profile.d/zookeeper_path.sh</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Fin del laboratorio</p>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_configuraci√≥n">2.3. Configuraci√≥n</h3>
<div class="paragraph">
<p>Los archivos de configuraci√≥n se llama convencionalmente <strong>zoo.cfg</strong> y se coloca en el subdirectorio <strong>conf</strong>
(normalmente se colocar en <strong>/etc/zookeeper</strong>, o en el directorio definido por la variable <strong>ZOOCFGDIR</strong>, si se establece).</p>
</div>
<div class="listingblock">
<div class="title">Ejemplo de variables de zoo.conf</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">tickTime=2000
dataDir=/disk1/zookeeper
dataLogDir=/disk2/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
server.1=zookeeper1:2888:3888
server.2=zookeeper2:2888:3888
server.3=zookeeper3:2888:3888
maxClientCnxns=0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es un archivo de propiedades est√°ndar de Java, y las tres propiedades siguientes son las minimas requeridas para ZooKeeper:</p>
<div class="ulist">
<ul>
<li>
<p><strong>tickTime</strong> : es la unidad de tiempo b√°sica en ZooKeeper (especificada en milisegundos). Se usa para los heartbeats, la sesi√≥n m√≠nima es dos veces el tickTime</p>
</li>
<li>
<p><strong>dataDir</strong> : es la ubicaci√≥n local del sistema de archivos donde ZooKeeper almacena datos persistentes</p>
</li>
<li>
<p><strong>clientPort</strong> : es el puerto donde escucha las conexiones del cliente (2181 es una opci√≥n com√∫n).</p>
</li>
</ul>
</div>
</li>
<li>
<p>Cada servidor del grupo de servidores de ZooKeeper tiene un identificador num√©rico que es √∫nico
dentro del grupo y debe estar comprendido entre 1 y 255.</p>
</li>
<li>
<p>El n√∫mero de servidor se especifica en <strong>texto sin formato</strong> en un archivo denominado <strong>myid</strong> en el directorio especificado por la propiedad <strong>dataDir</strong>.</p>
</li>
<li>
<p>Tambi√©n necesitamos dar a todos los servidores las identidades y ubicaciones de red de los dem√°s servidores pertenecientes al grupo.</p>
</li>
<li>
<p>En Zookeeper, el archivo de configuraci√≥n debe incluir una l√≠nea para cada servidor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Formato</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">server.n = hostname:port:port</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El valor de <strong>n</strong> se sustituye por el <strong>n√∫mero de servidor</strong>.</p>
</li>
<li>
<p>Hay dos configuraciones para los puertos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>puerto que los seguidores</strong> utilizan para <strong>conectar con el l√≠der</strong></p>
</li>
<li>
<p><strong>puerto para la elecci√≥n del l√≠der</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los servidores escuchan en tres puertos:</p>
<div class="ulist">
<ul>
<li>
<p>El <strong>2181</strong> para conexiones de cliente;</p>
</li>
<li>
<p>El <strong>2888</strong> para conexiones seguidoras, si ellos son el l√≠der;</p>
</li>
<li>
<p>El <strong>3888</strong> para otras conexiones de servidor durante la fase de elecci√≥n de l√≠der.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Cuando un servidor ZooKeeper se inicia, lee el archivo <strong>myid</strong> para determinar qu√© tipo de servidor es,
y luego lee el <strong>archivo de configuraci√≥n</strong> para determinar los puertos que debe escuchar y descubrir las direcciones de red de los otros servidores del grupo.</p>
</li>
<li>
<p>Los clientes que se conecten a este grupo ZooKeeper deben usar</p>
<div class="ulist">
<ul>
<li>
<p>Zookeeper1: 2181</p>
</li>
<li>
<p>Zookeeper2: 2181</p>
</li>
<li>
<p>Zookeeper3: 2181</p>
</li>
</ul>
</div>
</li>
<li>
<p>Es similar a la cadena del host en el constructor para el objeto ZooKeeper.</p>
</li>
<li>
<p>En el grupo de replica (<strong>replicaSet</strong>), <strong>hay dos propiedades obligatorias adicionales</strong>:</p>
<div class="ulist">
<ul>
<li>
<p><strong>initLimit</strong></p>
</li>
<li>
<p><strong>syncLimit</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Medidas m√∫ltiples de tickTime</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><strong>InitLimit</strong></p>
<div class="ulist">
<ul>
<li>
<p>Cantidad de tiempo que permite a los seguidores conectarse y sincronizarse con el
l√≠der.</p>
</li>
<li>
<p>Si la mayor√≠a de seguidores no sincronizan dentro de este per√≠odo, el l√≠der renuncia a su
liderazgo y otra elecci√≥n de l√≠der tiene lugar.</p>
</li>
<li>
<p>Si esto ocurre a menudo (se puede ver en el registro), es un signo de que la <strong>configuraci√≥n es demasiado baja</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>SyncLimit</strong> es la cantidad de tiempo que permite a un seguidor sincronizar con el l√≠der.</p>
<div class="ulist">
<ul>
<li>
<p>Si un seguidor no se sincroniza dentro de este per√≠odo, se reiniciar√°.</p>
</li>
<li>
<p>Los clientes que estuvieron vinculados a este seguidor se conectar√°n a otro.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>La siguiente directiva se recomienda definir para evitar rechazos de conexi√≥n de zookeeper cuando el cluster crece:</p>
</li>
<li>
<p><strong>maxClientCnxns</strong>: Indica el n√∫mero m√°ximo de clientes que podemos tener. Por defecto son 60, es recomendable poner infinito.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>maxClientCnxns=0</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_ejecuci√≥n">2.4. Ejecuci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>Para ejecutarlo, solo necesitamos usar el siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start</code></pre>
</div>
</div>
<div class="paragraph">
<p>o bien:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Ejecuci√≥n para la versi√≥n 3.4.14, para otras, hay que cambiar las versiones de paquetes</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre>[kafka@kafka-server zookeeper-3.4.14]$ java -cp zookeeper-3.4.14.jar:lib/slf4j-a.25.jar:lib/slf4j-log4j12-1.7.25.jar:lib/log4j-1.2.17.jar:conf org.apache.zookeeper.server.quorum.QuorumPeerMain conf/zoo.cfg</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para comprobar si ZooKeeper se est√° ejecutando, ejecutamos comando ruok ("¬øEst√° bien?") al puerto cliente utilizando <strong>nc</strong> (telnet tambi√©n funciona):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo ruok| nc localhost 2181
imok</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>ZooKeeper nos indica, "Estoy bien".</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_operaciones_de_zookeeper">2.5. Operaciones de Zookeeper</h3>
<div class="ulist">
<ul>
<li>
<p>Aqu√≠ podemos observar el listado de comandos que podemos ejecutar en Zookeeper</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/zookeeper-operaciones-01.png" alt="zookeeper operaciones 01" width="600">
</div>
<div class="title">Figure 1. Listado de operaciones</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Adem√°s del comando <strong>mntr</strong>, ZooKeeper expone estad√≠sticas a trav√©s de JMX.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En la documentaci√≥n de zookeeper explica como se exponen las estad√≠sticas JMX</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Tenemos las herramientas de monitorizaci√≥n y recipientes en <strong>src/contrib</strong> de la distribuci√≥n.</p>
</li>
<li>
<p>Desde la versi√≥n 3.5.0 de ZooKeeper, hay un servidor web incorporado para proporcionar la misma informaci√≥n, en <strong><a href="http://localhost:8080/commands" class="bare">http://localhost:8080/commands</a></strong> para obtener una lista de los comandos de la versi√≥n.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_ejemplos">2.5.1. Ejemplos</h4>
<div class="ulist">
<ul>
<li>
<p>Imaginemos un grupo de servidores que proporcionan alg√∫n servicio a los clientes.</p>
</li>
<li>
<p>Queremos:</p>
<div class="ulist">
<ul>
<li>
<p>Que los clientes puedan localizar a uno de los servidores para que puedan utilizar el servicio y mantener la lista de servidores perteneciente al grupo.</p>
</li>
<li>
<p>La lista de miembros no puede almacenarse en un solo nodo de la red, ya que un fallo de ese nodo significar√≠a la caida de todo el sistema (<strong>alta disponibilidad</strong>).</p>
</li>
<li>
<p>¬øComo eliminamos un servidor de la lista del grupo si falla?. Algunos procesos deben ser los responsables de la eliminaci√≥n de servidores caidos, pero no pueden ser los servidores, ya que no est√°n en ejecuci√≥n!</p>
</li>
</ul>
</div>
</li>
<li>
<p>En definitiva es una <strong>estructura de datos distribuida activa</strong>, y puede cambiar su estado con una entrada cuando se produce alg√∫n evento externo.</p>
</li>
<li>
<p>ZooKeeper nos proporciona este servicio.</p>
</li>
<li>
<p><strong>Pertenencia al grupo en ZooKeeper</strong></p>
<div class="ulist">
<ul>
<li>
<p>Pensemos que ZooKeeper proporciona un sistema de archivos con una alta disponibilidad.</p>
</li>
<li>
<p>No tiene archivos y directorios, sino un concepto unificado de un <strong>nodo</strong>, llamado
<strong>znode</strong>, que act√∫a tanto como un contenedor de datos (como un archivo) y un contenedor de otros <strong>znodes</strong> (como un directorio).</p>
</li>
<li>
<p>Los <strong>znodes</strong> forman un espacio de nombres jer√°rquico, y la de crear la lista de miembros es un <strong>znode padre</strong> con el nombre del grupo y <strong>znodes secundarios</strong> con los nombres de los miembros del grupo (servidores).</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/zookeeper-operaciones-02.png" alt="zookeeper operaciones 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En una aplicaci√≥n real debemos imaginarnos el almacenamiento de datos sobre los miembros, como nombres de host, con sus <strong>znodes</strong>.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_creaci√≥n_del_grupo">2.5.2. Creaci√≥n del grupo</h4>
<div class="ulist">
<ul>
<li>
<p>Vemos mediante el API JavaKeeper de Java la escritura de un programa para <strong>crear un znode</strong> de ejemplo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.CountDownLatch</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.CreateMode</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.WatchedEvent</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher.Event.KeeperState</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooDefs.Ids</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooKeeper</span>;

<span class="directive">public</span>        <span class="type">class</span> <span class="class">CreateGroup</span>        <span class="directive">implements</span>        Watcher        {

                <span class="directive">private</span>        <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> SESSION_TIMEOUT = <span class="integer">5000</span>;
                <span class="directive">private</span>        ZooKeeper zk;
                <span class="directive">private</span>        <span class="predefined-type">CountDownLatch</span>        connectedSignal        = <span class="keyword">new</span> <span class="predefined-type">CountDownLatch</span>(<span class="integer">1</span>);

                <span class="directive">public</span> <span class="type">void</span> connect(<span class="predefined-type">String</span> hosts) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>        {
                                zk        = <span class="keyword">new</span> ZooKeeper(hosts, SESSION_TIMEOUT,        <span class="local-variable">this</span>);
                                connectedSignal.await();
                }

                <span class="annotation">@Override</span>
                <span class="directive">public</span> <span class="type">void</span> process(WatchedEvent event)        { <span class="comment">//        Interfaz observadora</span>
                                <span class="keyword">if</span>        (event.getState()        ==        KeeperState.SyncConnected)        {
                                                connectedSignal.countDown();
                                }
                }

                <span class="directive">public</span> <span class="type">void</span>        create(<span class="predefined-type">String</span> groupName) <span class="directive">throws</span>        KeeperException,
                                                <span class="exception">InterruptedException</span> {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;
                                <span class="predefined-type">String</span>        createdPath        = zk.create(path, <span class="predefined-constant">null</span><span class="comment">/*data*/</span>,        Ids.OPEN_ACL_UNSAFE,
                                                                CreateMode.PERSISTENT);
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Created        </span><span class="delimiter">&quot;</span></span> +        createdPath);
                }

                <span class="directive">public</span> <span class="type">void</span> close() <span class="directive">throws</span>        <span class="exception">InterruptedException</span>        {
                                zk.close();
                }
                <span class="directive">public</span>        <span class="directive">static</span>        <span class="type">void</span>        main(<span class="predefined-type">String</span><span class="type">[]</span>        args)        <span class="directive">throws</span>        <span class="exception">Exception</span>        {
                                CreateGroup        createGroup        =        <span class="keyword">new</span>        CreateGroup();
                                createGroup.connect(args[<span class="integer">0</span>]);
                                createGroup.create(args[<span class="integer">1</span>]);
                                createGroup.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando se ejecuta el m√©todo <strong>main()</strong>, se crea una instancia de <strong>CreateGroup</strong> y luego llama al m√©todo <strong>Connect()</strong> que instancia un nuevo <strong>objeto ZooKeeper</strong>, que es el objeto principal del cliente y la que <strong>mantiene la conexi√≥n entre el cliente y el servicio ZooKeeper</strong>.</p>
</li>
<li>
<p>El constructor toma <strong>3 argumentos</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Direcci√≥n del host (y opcionalmente su puerto 2181) del servicio ZooKeeper</p>
</li>
<li>
<p>Tiempo de espera de la sesi√≥n en milisegundos (establecido a 5 segundos)</p>
</li>
<li>
<p>Una instancia de un objeto <strong>Watcher</strong> (observador).</p>
</li>
<li>
<p>El objeto Watcher recibe devoluciones de llamada de ZooKeeper para informarle de varios eventos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>En este escenario, <strong>CreateGroup</strong> es un <strong>Watcher</strong>, as√≠ que pasamos esto al <strong>constructor</strong> de ZooKeeper.</p>
</li>
<li>
<p>Cuando se crea una instancia de ZooKeeper, <strong>se inicia un subproceso para conectarse al servicio ZooKeeper</strong>.</p>
</li>
<li>
<p>La llamada al constructor debe volver de inmediato, por lo que es importante esperar la conexi√≥n antes de utilizar el objeto ZooKeeper.</p>
</li>
<li>
<p>Se hace uso de Java <strong>CountDownLatch</strong> (del paquete <strong>java.util.concurrent</strong>) para el <strong>bloqueo</strong> hasta que la instancia de ZooKeeper est√° lista.</p>
</li>
<li>
<p>Aqu√≠ es donde entra el <strong>Watcher</strong>.</p>
</li>
<li>
<p>La interfaz <strong>Watcher</strong> tiene un solo m√©todo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">void</span> process(evento WatchedEvent);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando el cliente se ha conectado al servidor de ZooKeeper, el <strong>watcher</strong> recibe una llamada a su m√©todo <strong>process()</strong> con un evento que indica que se ha conectado.</p>
</li>
<li>
<p>Al recibir un evento de conexi√≥n (representado por <strong>enum Watcher.Event.KeeperState</strong>, con el valor <strong>SyncConnected</strong>), nosotros decrementamos el contador en <strong>CountDownLatch</strong>, utilizando su m√©todo <strong>countDown()</strong>.</p>
</li>
<li>
<p>El <strong>CountDownLatch</strong> (cerrojo) se cre√≥ con un recuento a 1, que representa el n√∫mero de eventos que deben ocurrir antes de que libere todos los hilos en espera.</p>
</li>
<li>
<p>Despu√©s de llamar a <strong>countDown()</strong> una vez, el contador alcanzar√° 0 y devuelve el <strong>m√©todo await()</strong>.</p>
</li>
<li>
<p>El m√©todo <strong>connect()</strong> ahora ha regresado, y el m√©todo siguiente a ser invocado es el m√©todo <strong>create()</strong> en la instancia de ZooKeeper.</p>
</li>
<li>
<p>Los argumentos que toma son:</p>
<div class="ulist">
<ul>
<li>
<p>El camino (representado por una cadena recibida en arg[1])</p>
</li>
<li>
<p>Contenido del znode (una matriz de bytes nula en este caso)</p>
</li>
<li>
<p>Un acceso a la lista de control (o ACL para abreviar, que aqu√≠ est√° completamente abierta, permitiendo que cualquier cliente las lea o escriba en el znode)</p>
</li>
<li>
<p>Naturaleza del znode que se va a crear: ef√≠meros, <strong>ephemeral</strong> o persistentes, <strong>persistent</strong>.</p>
</li>
<li>
<p>Un <strong>znode ef√≠mero</strong> ser√° borrado por el servicio de ZooKeeper cuando el cliente que lo cre√≥ se desconecta, expl√≠citamente o porque el cliente lo termina por cualquier raz√≥n.</p>
</li>
<li>
<p>Un <strong>znode persistent</strong>, por otro lado, <strong>NO</strong> es eliminado cuando el cliente se desconecta ya que queremos que vida m√°s tiempo el znode que representa que la vida del programa que lo crea.</p>
</li>
</ul>
</div>
</li>
<li>
<p>El valor de retorno del m√©todo <strong>create()</strong> es la camino creado por ZooKeeper.</p>
</li>
<li>
<p>Lo imprimirmos como mensaje de que la ruta de acceso se cre√≥ correctamente.</p>
</li>
<li>
<p>Notaremos c√≥mo el camino devuelta por create() puede diferir del pasado al m√©todo cuando vemos znodes secuenciales.</p>
</li>
<li>
<p>Para ver el programa en acci√≥n, necesitamos tener ZooKeeper corriendo en la m√°quina local, y ejecutamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export CLASSPATH=/home/kafka/Desktop/software/libs/*:$ZOOKEEPER_HOME/*:\ $ZOOKEEPER_HOME/lib/*:$ZOOKEEPER_HOME/conf
[kafka@kafka-server ~]$ java com.kafka.zookeeper.CreateGroup localhost zoo</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_unirse_a_un_grupo">2.5.3. Unirse a un grupo</h4>
<div class="ulist">
<ul>
<li>
<p>Una vez creado el Grupo necesitamos registrar a un miembro en el grupo.</p>
</li>
<li>
<p><strong>Cada miembro se ejecutar√° como un programa y se unir√° al grupo</strong>.</p>
</li>
<li>
<p>Cuando el programa salga, debe ser eliminado del grupo, creandolo como <strong>znode ef√≠mero</strong> en el espacio de nombres de ZooKeeper.</p>
</li>
<li>
<p>El programa <strong>JoinGroup</strong> implementa esta idea:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">JoinGroup.java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.CreateMode</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooDefs.Ids</span>;

<span class="directive">public</span>        <span class="type">class</span>        <span class="class">JoinGroup</span>        <span class="directive">extends</span>        ConnectionWatcher        {

                <span class="directive">public</span> <span class="type">void</span>        join(<span class="predefined-type">String</span>        groupName, <span class="predefined-type">String</span> memberName) <span class="directive">throws</span> KeeperException,
                                                <span class="exception">InterruptedException</span>        {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName + <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + memberName;
                                <span class="predefined-type">String</span>        createdPath        = zk.create(path,        <span class="predefined-constant">null</span><span class="comment">/*data*/</span>, Ids.OPEN_ACL_UNSAFE,
                                                CreateMode.EPHEMERAL);
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Created        </span><span class="delimiter">&quot;</span></span> +        createdPath);
                }

                <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">Exception</span>        {
                                JoinGroup joinGroup        = <span class="keyword">new</span> JoinGroup();
                                joinGroup.connect(args[<span class="integer">0</span>]);
                                joinGroup.join(args[<span class="integer">1</span>],        args[<span class="integer">2</span>]);

                                <span class="comment">//        Se mantiene durmiendo hasta que el proceso sea matado o interrumpido el hilo de ejecucii√≥n</span>
                                <span class="predefined-type">Thread</span>.sleep(<span class="predefined-type">Long</span>.MAX_VALUE);
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La l√≥gica para crear y conectarse ha sido refactorizada en <strong>ConnectionWatcher</strong> :</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">ConnectionWatcher.java</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.CountDownLatch</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.WatchedEvent</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.Watcher.Event.KeeperState</span>;
<span class="keyword">import</span> <span class="include">org.apache.zookeeper.ZooKeeper</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConnectionWatcher</span> <span class="directive">implements</span> Watcher {

                <span class="directive">private</span>        <span class="directive">static</span> <span class="directive">final</span> <span class="type">int</span> SESSION_TIMEOUT = <span class="integer">5000</span>;
                <span class="directive">protected</span> ZooKeeper zk;
                <span class="directive">private</span>        <span class="predefined-type">CountDownLatch</span>        connectedSignal        = <span class="keyword">new</span> <span class="predefined-type">CountDownLatch</span>(<span class="integer">1</span>);
                <span class="directive">public</span>        <span class="type">void</span> connect(<span class="predefined-type">String</span>        hosts) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>        {
                                zk = <span class="keyword">new</span> ZooKeeper(hosts, SESSION_TIMEOUT, <span class="local-variable">this</span>);
                                connectedSignal.await();
                }

                <span class="annotation">@Override</span>
                <span class="directive">public</span> <span class="type">void</span>        process(WatchedEvent event)        {
                                <span class="keyword">if</span>        (event.getState() == KeeperState.SyncConnected)        {
                                                connectedSignal.countDown();
                                }
                }

                <span class="directive">public</span> <span class="type">void</span> close() <span class="directive">throws</span> <span class="exception">InterruptedException</span>        {
                                zk.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El c√≥digo para <strong>JoinGroup</strong> es muy similar a <strong>CreateGroup</strong>.</p>
</li>
<li>
<p>Crea un <strong>znode ef√≠mero</strong> como hijo del grupo znode en su m√©todo <strong>join()</strong>, luego simula hacer trabajo de alg√∫n tipo
durmiendo hasta que el proceso se termine por fuerza.</p>
</li>
<li>
<p>M√°s adelante, vemos que un <strong>znode ef√≠mero</strong> es eliminado por ZooKeeper.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_encontrar_a_los_miembros_en_un_grupo">2.5.4. Encontrar a los miembros en un grupo</h4>
<div class="listingblock">
<div class="title">ListGroup</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.util.List</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ListGroup</span>        <span class="directive">extends</span>        ConnectionWatcher        {
                                                <span class="directive">public</span>        <span class="type">void</span>        list(<span class="predefined-type">String</span>        groupName)        <span class="directive">throws</span>        KeeperException,
                                                <span class="exception">InterruptedException</span> {
                                <span class="predefined-type">String</span>        path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;

                                <span class="keyword">try</span>        {
                                                <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; children =        zk.getChildren(path, <span class="predefined-constant">false</span>);
                                                <span class="keyword">if</span>        (children.isEmpty())        {
                                                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">No members in group %s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,        groupName);
                                                                <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                                                }
                                                <span class="keyword">for</span>        (<span class="predefined-type">String</span>        child : children)        {
                                                                <span class="predefined-type">System</span>.out.println(child);
                                                }
                                }        <span class="keyword">catch</span>        (KeeperException.NoNodeException e)        {
                                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">Group %s        does not exist</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,        groupName);
                                                <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                                }
                }

                <span class="directive">public</span>        <span class="directive">static</span>        <span class="type">void</span>        main(<span class="predefined-type">String</span><span class="type">[]</span>        args)        <span class="directive">throws</span>        <span class="exception">Exception</span>        {
                                ListGroup        listGroup        =        <span class="keyword">new</span>        ListGroup();
                                listGroup.connect(args[<span class="integer">0</span>]);
                                listGroup.list(args[<span class="integer">1</span>]);
                                listGroup.close();
                }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el m√©todo <strong>list()</strong>, llamamos <strong>getChildren()</strong> con la ruta del <strong>znode</strong> y un indicador <strong>watch</strong> para recuperar una lista de rutas secundarias para el znode, que imprimimos.</p>
</li>
<li>
<p>Colocamos un <strong>watch</strong> en un <strong>znode</strong> para hacer que el <strong>watcher</strong> quede registrado como activo si el znode cambia de estado.</p>
</li>
<li>
<p>Viendo a los hijos de un znode se permitir√° a un programa recibir notificaciones de los miembros que se unan o abandonan el grupo, o del grupo que se elimina.</p>
</li>
<li>
<p>Capturamos <strong>KeeperException.NoNodeException</strong>, que se lanza en el caso cuando el <strong>grupo del znode no existe</strong>.</p>
</li>
<li>
<p>Vemos <strong>ListGroup</strong> en ejecuci√≥n, y comprobamos que el <strong>grupo zoo</strong> est√° vac√≠o, ya que no tenemos agregado a ning√∫n miembro a√∫n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java ListGroup localhost zoo
no members in group zoo</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos usar el programa <strong>JoinGroup</strong> para agregar algunos miembros al grupo.</p>
</li>
<li>
<p>Los lanzamos como procesos en background, ya que no terminan por s√≠ mismos (debido a la declaraci√≥n de sleep):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo pato &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo vaca &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java JoinGroup localhost zoo cabra &amp;
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  nuestra_cabra_pid = <span class="error">$</span>!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En la √∫ltima l√≠nea nos <strong>guardamos el ID de proceso del proceso Java que ejecuta el programa que agrega</strong> como un miembro.</p>
</li>
<li>
<p>Necesitamos recordar el ID para poder matar el proceso en un momento dado,</p>
</li>
<li>
<p>comprobamos los miembros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span>  java ListGroup localhost zoo
cabra
pato
vaca</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_eliminar_un_miembro">2.5.5. Eliminar un miembro</h4>
<div class="ulist">
<ul>
<li>
<p>Para ello matamos su proceso:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill $nuestra_cabra_pid</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y unos segundos m√°s tarde, ha desaparecido del grupo porque el proceso de la sesi√≥n de ZooKeeper ha finalizado (el tiempo de espera se ha establecido en 5 segundos)</p>
</li>
<li>
<p>y su <strong>znode ef√≠mero</strong> ha sido eliminado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java ListGroup localhost zoo
pato
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Resumen</p>
<div class="ulist">
<ul>
<li>
<p>Sabemos como construir una lista del grupo de nodos que est√°n participando en un sistema distribuido.</p>
</li>
<li>
<p>Los nodos <strong>NO</strong> tienen que tener conocimiento mutuo de su existencia.</p>
</li>
<li>
<p>Un cliente que desea utilizar los nodos de la lista para realizar algunos trabajo, por ejemplo, puede descubrir los nodos, sin que ellos sean conscientes de su existencia.</p>
</li>
<li>
<p>La pertenencia a un grupo no implica una sustituci√≥n sobre el manejo de errores de red cuando nos comunicamos con un nodo.</p>
</li>
<li>
<p>Incluso si un nodo es un miembro del grupo, las comunicaciones con √©l pueden fallar, y tales fallos deben ser manejados de la manera habitual (reintentar, probar con un miembro del grupo, etc.).</p>
</li>
<li>
<p><strong>Las herramientas de l√≠nea de comandos de ZooKeeper son para interactuar con el espacio de nombres de ZooKeeper</strong>.</p>
</li>
<li>
<p>Podemos usarlo para *listar los znodes bajo el znode /zoo como sigue:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh -server localhost ls /zoo
vaca, pato</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si lo ejecutamos sin argumentos nos muestra la ayuda.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_eliminaci√≥n_de_un_grupo">2.5.6. Eliminaci√≥n de un grupo</h4>
<div class="ulist">
<ul>
<li>
<p>La clase ZooKeeper proporciona una m√©todo <strong>Delete()</strong> que toma una ruta de acceso y un n√∫mero de versi√≥n.</p>
</li>
<li>
<p>Se eliminar√° un <strong>znode</strong> s√≥lo si el <strong>n√∫mero de versi√≥n especificado</strong> es el mismo que el <strong>n√∫mero de versi√≥n del znode</strong> que es tratado de eliminar, pues se trata de un mecanismo de bloqueo optimista que permite a los clientes detectar conflictos sobre la modificaci√≥n de un <strong>znode</strong>.</p>
</li>
<li>
<p>Sin embargo, podemos omitir la comprobaci√≥n de versiones mediante una versi√≥n con <strong>valor -1</strong> para eliminar el znode independientemente de su n√∫mero de versi√≥n.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>No hay ninguna operaci√≥n de borrado recursivo en ZooKeeper</strong>, por lo que enemos que eliminar los <strong>znodes hijos antes de los padres</strong>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto es lo que hace la clase <strong>DeleteGroup</strong>, que eliminar√° un grupo y todos sus miembros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.zookeeper</span>;

<span class="keyword">import</span> <span class="include">java.util.List</span>;

<span class="keyword">import</span> <span class="include">org.apache.zookeeper.KeeperException</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">DeleteGroup</span> <span class="directive">extends</span> ConnectionWatcher {


        <span class="directive">public</span> <span class="type">void</span> delete(<span class="predefined-type">String</span> groupName) <span class="directive">throws</span> KeeperException, <span class="exception">InterruptedException</span> {
                <span class="predefined-type">String</span> path = <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + groupName;

                <span class="keyword">try</span> {
                        <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; children = zk.getChildren(path, <span class="predefined-constant">false</span>);
                        <span class="keyword">for</span> (<span class="predefined-type">String</span> child : children) {
                                zk.delete(path + <span class="string"><span class="delimiter">&quot;</span><span class="content">/</span><span class="delimiter">&quot;</span></span> + child, -<span class="integer">1</span>);
                        }
                        zk.delete(path, -<span class="integer">1</span>);
                } <span class="keyword">catch</span> (KeeperException.NoNodeException e) {
                        <span class="predefined-type">System</span>.out.print(<span class="string"><span class="delimiter">&quot;</span><span class="content">El grupo</span><span class="delimiter">&quot;</span></span> + groupName + <span class="string"><span class="delimiter">&quot;</span><span class="content">no existe </span><span class="char">\n</span><span class="delimiter">&quot;</span></span>);
                        <span class="predefined-type">System</span>.exit(<span class="integer">1</span>);
                }
        }

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">Exception</span> {
                DeleteGroup deleteGroup = <span class="keyword">new</span> DeleteGroup();
                deleteGroup.connect(args[<span class="integer">0</span>]);
                deleteGroup.delete(args[<span class="integer">1</span>]);
                deleteGroup.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Finalmente, podemos eliminar el grupo de zoo que creamos anteriormente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java DeleteGroup localhost zoo
[kafka<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> java ListGroup localhost zoo
Grupo zoo no existe</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_lab_operaciones_con_zookeeper">2.5.7. Lab: Operaciones con Zookeeper</h4>
<div class="ulist">
<ul>
<li>
<p>El objetivo es poner en funcionamiento el servidor de zookeeper</p>
</li>
<li>
<p>Probaremos todo lo que hemos comentado en el tema anterior.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_configuraci√≥n_de_zookeeper">2.5.7.1. Configuraci√≥n de zookeeper</h5>
<div class="ulist">
<ul>
<li>
<p>En nuestro caso, vamos a crear nuestro fichero partiendo del ejemplo que viene en el directorio <strong>conf</strong>, vamos a renombrarlo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd /opt/apache-zookeeper/conf/
[kafka@kafka-server conf]$ cp zoo_sample.cfg zoo.cfg</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si nos fijamos, en este archivo vienen las siguientes configuraciones ya aplicadas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ egrep -v &quot;^#&quot; zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/tmp/zookeeper
clientPort=2181</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a cambiar el directorio donde guardamos los datos a:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">dataDir=/var/zookeeper</code></pre>
</div>
</div>
<div class="paragraph">
<p>Creamos el directorio y cambiamos sus permisos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ sudo mkdir /var/zookeeper
[kafka@kafka-server conf]$ sudo chown kafka:kafka /var/zookeeper/</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En un cl√∫ster <strong>Zookeeper</strong>, es necesario que cada nodo tenga su identificador creado, y aunque aqu√≠ no vayamos a crear un <strong>ensemble</strong>, daremos un id propio a nuestro nodo.</p>
</li>
<li>
<p>Nuestro nodo va a ser el nodo <strong>1</strong>, y esto es todo lo que debe figurar en nuestro fichero <strong>myid</strong>, que recordemos, debe ubicarse en la ruta de datos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ echo &quot;1&quot; &gt; /var/zookeeper/myid</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De la misma forma, vamos a a√±adir la ruta de nuestro nodo al fichero de configuraci√≥n (esto mismo, deber√≠amos hacerlo con los dem√°s nodos en caso de estar en un <strong>ensemble</strong>).</p>
</li>
<li>
<p>A√±adimos la siguiente l√≠nea a <strong>zoo.cfg</strong> (Recordad, en un entorno real usas el interfaz de red por el que esper√°is recibir conexiones, <strong>NUNCA</strong> localhost)</p>
</li>
<li>
<p>En este caso, el nombre de la m√°quina es master, y apunta a 127.0.0.1</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">server.1=kafka-server.local:2888:3888</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos tambi√©n la autorizaci√≥n de recibir comandos desde el puerto por defecto de 4 caracteres, como ruok, que probaremos m√°s tarde.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">4lw.commands.whitelist=*</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_ejecuci√≥n_2">2.5.7.2. Ejecuci√≥n</h5>
<div class="ulist">
<ul>
<li>
<p>Iniciamos <strong>Zookeeper</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos que est√° funcionando dici√©ndole <strong>"are you ok?"</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server conf]$ echo &quot;ruok&quot; | nc kafka-server.local 2181
imok</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_pruebas_con_java">2.5.7.3. Pruebas con Java</h5>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, usaremos los ejemplos que hemos visto durante el curso, (ya compilados en un jar, llamado api-zookeeper-1.0.0.jar).</p>
</li>
<li>
<p>Hay que acordarse de incluirlo en el CLASSPATH, al igual que las librer√≠as que usamos de <strong>Zookeeper</strong> (esto, podemos a√±adirlo al fichero profile.d o en el fichero .bash_profile del usuario, en este ejemplo supone que el jar est√° en /home/kafka/Desktop/software/libs)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export CLASSPATH=$ZOOKEEPER_HOME/dist-maven/*:$ZOOKEEPER_HOME/lib/*:/home/kafka/Desktop/software/libs/*</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Probamos a crear el grupo de servidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.CreateGroup kafka-server.local zoo
Created        /zoo</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora creamos los nodos ef√≠meros (y cogemos el id del nodo cabra):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo pato &amp;
[1] 13595
Created        /zoo/pato
[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo vaca &amp;
[2] 13633
Created        /zoo/vaca
[kafka@kafka-server software]$ java com.kafka.zookeeper.JoinGroup kafka-server.local zoo cabra &amp;
[3] 13663
Created        /zoo/cabra
[kafka@kafka-server software]$ nuestra_cabra_pid=$!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y miramos si nuestros nodos funcionan como esper√°bamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
cabra
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora, matamos el servidor <strong>cabra</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill -9 $nuestra_cabra_pid
[3]+  Killed                  java com.kafka.zookeeper.JoinGroup master zoo cabra</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos, que al ser un nodo ef√≠mero, desaparece:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
vaca
0    [main-SendThread(kafka-server.local:2181)] WARN  org.apache.zookeeper.ClientCnxn  - An exception was thrown while closing send thread for session 0x100001ee5910005.
EndOfStreamException: Unable to read additional data from server sessionid 0x100001ee5910005, likely server has closed socket
        at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1275)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si lo lanzamos de nuevo, comprobamos como el cliente conectado ha desaparecido del todo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
pato
vaca</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a proceder al borrado del grupo de servidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.DeleteGroup kafka-server.local zoo
1    [main-SendThread(kafka-server.local:2181)] WARN  org.apache.zookeeper.ClientCnxn  - An exception was thrown while closing send thread for session 0x100001ee5910007.
EndOfStreamException: Unable to read additional data from server sessionid 0x100001ee5910007, likely server has closed socket
        at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1275)</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora, consultamos qu√© nodos hay en dicho grupo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ java com.kafka.zookeeper.ListGroup kafka-server.local zoo
Group zoo        does not exist</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_prueba_con_zkcli_sh">2.5.7.4. Prueba con zkCli.sh</h5>
<div class="ulist">
<ul>
<li>
<p>Ahora, vamos a usar la herramienta proporcionada por <strong>Zookeeper</strong> para comunicarnos con √©l, el cliente.</p>
</li>
<li>
<p>Para arrancar el cliente escribimos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh -server kafka-server.local:2181
/bin/java
Connecting to kafka-server.local:2181
...
[zk: master:2181(CONNECTED) 0]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez dentro del cliente, podemos ejecutar m√∫ltiples operaciones, veremos las siguientes:</p>
<div class="ulist">
<ul>
<li>
<p>Creaci√≥n de nodos</p>
</li>
<li>
<p>Obtenci√≥n de datos</p>
</li>
<li>
<p>Modificaci√≥n de datos</p>
</li>
<li>
<p>Listar zNodes</p>
</li>
<li>
<p>Estado de un nodo</p>
</li>
<li>
<p>Borrar nodos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para crear un nodo tan s√≥lo tenemos que hacer uso de <strong>create</strong>, especificando la ruta y el contenido del nodo:</p>
</li>
<li>
<p>La sintaxis es:</p>
<div class="ulist">
<ul>
<li>
<p>create [opciones] ruta datos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear los nodos especificando contenido o dej√°ndolos sin √©l</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 0] create /vacio &quot;&quot;
Created /vacio
[zk: kafka-server.local:2181(CONNECTED) 1] create /concosas &quot;estas cosas tiene&quot;
Created /concosas</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los flags que vamos a usar son</p>
<div class="ulist">
<ul>
<li>
<p><strong>-s</strong> &#8594; Es un nodo secuencial, le asigna un n√∫mero de secuencial</p>
</li>
<li>
<p><strong>-e</strong> &#8594; Es ef√≠mero, se eliminar√° al cerrar el cliente</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 2] create -e /concosas/tmp1 &quot;soy temporal1&quot;
Created /concosas/tmp1
[zk: kafka-server.local:2181(CONNECTED) 3] create -s /concosas/seq &quot;Primero&quot;
Created /concosas/seq0000000001
[zk: kafka-server.local:2181(CONNECTED) 4] create -s /concosas/seq &quot;Segundo&quot;
Created /concosas/seq0000000002</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para obtener informaci√≥n almacenada en un nodo concreto, podemos usar <strong>get</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 5] get /concosas/tmp1
soy temporal1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si se quiere modificar el contenido de un <strong>zNode</strong> puedo hacer uso de <strong>set</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 6] set /concosas/tmp1 &quot;He cambiado&quot;
[zk: kafka-server.local:2181(CONNECTED) 7] get /concosas/tmp1
He cambiado</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si se quiere consultar los <strong>zNodes</strong> existentes, debo hacer uso de <strong>ls</strong>, cuya sintaxis es an√°loga a la de <strong>Unix</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 8] ls /
[concosas, vacio, zookeeper]
[zk: kafka-server.local:2181(CONNECTED) 9] ls /concosas
[seq0000000001, seq0000000002, tmp1]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para consultar el estado de un nodo, puedo hacer uso de <strong>stat</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 11] stat /concosas
cZxid = 0x1a
ctime = Mon Sep 28 12:14:04 UTC 2020
mZxid = 0x1a
mtime = Mon Sep 28 12:14:04 UTC 2020
pZxid = 0x1d
cversion = 3
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 17
numChildren = 3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, para borrar un nodo, puedo hacer uso de <strong>rmr</strong>, que borra un nodo <strong>de forma recursiva</strong>, es decir, tambi√©n borra sus hijos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 12] deleteall /concosas
[zk: kafka-server.local:2181(CONNECTED) 13] ls /
[vacio, zookeeper]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Salimos con el comando quit</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: kafka-server.local:2181(CONNECTED) 14] quit</code></pre>
</div>
</div>
<div class="paragraph">
<p>Para parar nuestro servidor, primero paramos los jobs en segundo plano de java:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kill %1
[kafka@kafka-server ~]$ kill %2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora paramos el servidor, y para ello escribimos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh stop
ZooKeeper JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Stopping zookeeper ... STOPPED</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_instalaci√≥n_de_kafka">3. Instalaci√≥n de Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>La instalaci√≥n de kafka es muy sencilla, ya que debemos haber instalado anteriormente zookeeper.</p>
</li>
<li>
<p>Con la instalaci√≥n de zookeeper lista, solo se necesita instalar kafka indicando la ruta del servidor de zookeeper disponible.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_instalaci√≥n_de_kafka">3.1. Lab: Instalaci√≥n de kafka</h3>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para este ejemplo debemos tener instalado <strong>Zookeeper</strong></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de nada, tenemos que descargar <strong>Kafka</strong>. Para ello iremos a:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://kafka.apache.org/downloads" class="bare">https://kafka.apache.org/downloads</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Y descargaremos la versi√≥n que queramos (Existen versiones que han sido compiladas con distintos est√°ndares de <strong>Scala</strong>, si no vais a usar <strong>Scala</strong>, escoged la recomendada)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-laboratorio-instalacion-01.png" alt="kafka laboratorio instalacion 01" width="600">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>El software est√° ya predescargado en el directorio /home/kafka/Desktop/software/</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_instalaci√≥n_de_software">3.1.1. Instalaci√≥n de software</h4>
<div class="ulist">
<ul>
<li>
<p>Descomprimimos <strong>Kafka</strong> y movemos a la ruta destino (por ejemplo /usr/local)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Hay que cambiar la versi√≥n por la que se haya descomprimido</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ tar xf kafka*.tgz
[kafka@kafka-server software]$ sudo mv kafka_2.13-2.6.0 /opt/kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos tambi√©n las variables de entorno de kafka:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ echo export KAFKA_HOME=/opt/kafka &gt;&gt; kafka_path.sh
[kafka@kafka-server software]$ echo 'export PATH=$PATH:$KAFKA_HOME/bin' &gt;&gt; kafka_path.sh
[kafka@kafka-server software]$ sudo mv kafka_path.sh /etc/profile.d/</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cambiamos los permisos para poder ejecutar el script y</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server software]$ sudo chmod ugo+x /etc/profile.d/kafka_path.sh
[kafka@kafka-server software]$ source /etc/profile.d/kafka_path.sh</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_puesta_en_marcha">3.1.2. Puesta en marcha</h4>
<div class="ulist">
<ul>
<li>
<p>Iniciamos <strong>Zookeeper</strong> en caso de que est√© apagado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que est√° funcionando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo ruok | nc kafka-server.local 2181
imok</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de ejecutar <strong>Kafka</strong>, hay que crear para √©l un fichero de configuraci√≥n.</p>
</li>
<li>
<p>En nuestro caso, vamos a ver el fichero por defecto, que est√° en <strong>$KAFKA_HOME/config/server.properties</strong></p>
</li>
<li>
<p>Este fichero contiene el <strong>Broker ID</strong> que va a ser usado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[kafka@kafka-server ~]$ cat /opt/kafka/config/server.properties | grep broker.id
broker.id=0</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Por defecto <strong>Kafka</strong> va a buscar el servidor <strong>Zookeeper</strong> en <strong>localhost:2181</strong>, si queremos cambiar esto, podemos editar la propiedad <strong>zookeeper.connect</strong>, para darle un listado de nodos del ensamble <strong>Zookeeper</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de configuraci√≥n de path de Zookeeper</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">zookeeper.connect=nodo1:2181,nodo2:2181,nodo3:2181</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para arrancar <strong>Kafka</strong> tenemos dos opciones:</p>
</li>
<li>
<p>Arrancarlo en primer plano:</p>
<div class="ulist">
<ul>
<li>
<p>kafka-server-start.sh ruta_al_fich_conf</p>
</li>
</ul>
</div>
</li>
<li>
<p>O bien, arrancarlo en segundo plano</p>
<div class="ulist">
<ul>
<li>
<p>kafka-server-start.sh -daemon ruta_al_fich_conf</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a arrancar <strong>Kafka</strong> usando nuestro fichero de configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh ${KAFKA_HOME}/config/server.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, ahora ya tenemos <strong>Kafka</strong> corriendo, vamos a ver qu√© ha creado en <strong>Zookeeper</strong></p>
</li>
<li>
<p>Nos conectamos con el cliente de <strong>Zookeeper</strong> desde otra shell</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server vagrant]$ zkCli.sh
/bin/java
Connecting to localhost:2181
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si consultamos qu√© hay ahora en <strong>Zookeeper</strong> con <strong>ls</strong>, veremos que se han creado muchas cosas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 0] ls /
[admin, brokers, cluster, config, consumers, controller, controller_epoch, isr_change_notification, latest_producer_id_block, log_dir_event_notification, vacio, zookeeper]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que dentro del nodo <strong>brokers</strong> existen 3 nodos hijo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 1] ls /brokers
[ids, seqid, topics]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos su contenido, vemos que no existe ning√∫n elemento en <strong>topics</strong> (normal, no hemos creado ning√∫n topic), mientras que debajo de <strong>ids</strong> tenemos la lista de <strong>brokers</strong> existentes (en nuestro caso s√≥lo tenemos 1). Si queremos tener m√°s <strong>brokers</strong> levantados, aseguraros de darles distintos ids.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 2] ls /brokers/topics
[]
[zk: localhost:2181(CONNECTED) 3] ls /brokers/ids
[0]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pedimos informaci√≥n del <strong>broker</strong> mediante <strong>get</strong>, que me mostrar√° por ejemplo d√≥nde estamos escuchando, en que host y en que puerto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 4] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://kafka-server.local:9092&quot;],&quot;jmx_port&quot;:-1,&quot;port&quot;:9092,&quot;host&quot;:&quot;kafka-server.local&quot;,&quot;version&quot;:4,&quot;timestamp&quot;:&quot;1601301843441&quot;}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, comentar que dentro de un cl√∫ster, puede haber m√∫ltiples <strong>brokers</strong>, pero s√≥lo uno de ellos puede ejercer de <strong>controlador</strong>.</p>
</li>
<li>
<p>Podemos consultar qu√© <strong>broker</strong> est√° haciendo dicha funci√≥n, solicitando los datos del nodo <strong>/controller</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[zk: localhost:2181(CONNECTED) 5] get /controller
{&quot;version&quot;:1,&quot;brokerid&quot;:0,&quot;timestamp&quot;:&quot;1601301843543&quot;}</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_topics">4. Topics</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Los <strong>Topics</strong> son la base de <strong>Kafka</strong>, son los equivalentes a las colas de mensajer√≠a (se inserta o leen mensajes).</p>
</li>
<li>
<p>El <strong>Broker</strong> es el encargado de guardar las distintas colas (<strong>topics</strong>), se utilizan tambi√©n para crear los <strong>clusters</strong>, y se sincronizan mediante <strong>Zookeeper</strong>.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-01.jpg" alt="kafka topics 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Topics</strong> son las distintas colas de mensajes que se encuentran en <strong>Kafka</strong>.</p>
</li>
<li>
<p>Un <strong>Topic</strong> est√°n dividido en m√∫ltiples particiones. Las particiones se asignan a los distintos <strong>Brokers</strong> para poder distribuir y escalar el sistema (aunque un √∫nico <strong>Broker</strong> puede gestionar tambi√©n varias particiones.</p>
</li>
<li>
<p>Dentro de las particiones se encuentran nuestros mensajes, que es el objeto final de nuestro sistema.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-02.png" alt="kafka topics 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Las particiones son ficheros que se encuentran en el disco.</p>
</li>
<li>
<p>Estos ficheros se denominan <strong>logs</strong>.</p>
</li>
<li>
<p>Cada mensaje dentro de un fichero <strong>log</strong> es identificado por un <strong>offset</strong>. Este <strong>offset</strong> sirve de ordenamiento, y es generado autom√°ticamente por <strong>kafka</strong>.</p>
</li>
<li>
<p>Los consumidores pueden leer los mensajes a partir de un <strong>offset</strong> espec√≠fico, por lo que los consumidores pueden unirse al cl√∫ster en cualquier momento (empezando en el <strong>offset</strong> que consideren).</p>
</li>
<li>
<p>En <strong>Kafka</strong>, un mensaje se identifica de manera un√≠voca mediante su <strong>topic</strong>, su <strong>partici√≥n</strong> y su <strong>offset</strong> (dentro de dicha partici√≥n)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-03.png" alt="kafka topics 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya hemos dicho que internamente, una partici√≥n se guarda en disco como un fichero de tipo <strong>log</strong>. Un productor escribe un mensaje en dicho fichero y los consumidores leen el fichero desde el <strong>offset</strong> que ellos quieran.</p>
</li>
<li>
<p><strong>Kafka</strong> mantiene estos mensajes durante un periodo de tiempo (configurable), y es el consumidor el que debe ajustarse a dicho comportamiento (e.g, si un consumidor est√° ca√≠do durante un tiempo mayor a dicho periodo, perder√° mensajes, pero en caso contrario, podr√° continuar donde lo hab√≠a dejado).</p>
</li>
<li>
<p>Es decir, <strong>Kafka</strong> no guarda informaci√≥n de qu√© ha le√≠do cada consumidor.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-04.png" alt="kafka topics 04" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bueno, ya hemos dicho que podemos particionar un <strong>Topic</strong> para poder distribuirlo a m√°s de un <strong>Broker</strong>.</p>
</li>
<li>
<p>Tened en cuenta que si vuestro sistema est√° saturado, y s√≥lo dispon√©is de un <strong>Broker</strong>, crear m√°s particiones no va a solucinar el problema (ya que el <strong>Broker</strong> tendr√° todas las particiones).</p>
</li>
<li>
<p>Para poder distribuir las particiones a m√∫ltiples nodos, debemos disponer de m√∫ltiples <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-05.png" alt="kafka topics 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, sabemos c√≥mo escalar si m√∫ltiples productores est√°n escribiendo a un ritmo superior al que es capaz de gestionar un √∫nico <strong>Broker</strong>, pero ¬øqu√© sucede en el caso anterior si se cae un nodo?</p>
</li>
<li>
<p>Si en nuestro ejemplo anterior, se cayera el nodo que gestiona el <strong>Broker 0</strong>, dejar√≠amos de tener acceso a tres particiones de dos <strong>topics</strong> distintos, con lo que no ser√≠amos capaz de funcionar correctamente</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-06.png" alt="kafka topics 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para asegurar la alta disponibilidad de nuestro sistema, <strong>Kafka</strong> permite gestionar <strong>r√©plicas</strong> de nuestras particiones.</p>
</li>
<li>
<p>Una <strong>r√©plica</strong> es una copia de una partici√≥n asignada a otro <strong>Broker</strong> y por lo tanto ubicada en otro nodo distinto.</p>
</li>
<li>
<p>Con ello, nos aseguramos de que en caso de ca√≠da de alg√∫n, podemos seguir trabajando ya que la informaci√≥n seguir√° estando disponible.</p>
</li>
<li>
<p>Cada partici√≥n de cada <strong>Topic</strong> tiene un √∫nico <strong>Leader</strong>.</p>
</li>
<li>
<p>Cuando realizamos una escritura, esta se realiza siempre sobre la partici√≥n <strong>Leader</strong>, cuyo <strong>Broker</strong> se encarga de persistir el dato y de sincronizarlo con las otras r√©plicas (los <strong>Brokers</strong> que contienen las otras r√©plicas deben confirmar la escritura).</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-07.png" alt="kafka topics 07" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es importante recordar que <strong>tanto las escrituras como las lecturas</strong> se realizan siempre desde la partici√≥n <strong>Leader</strong></p>
</li>
<li>
<p>Cuando todo funciona correctamente, los datos se replican sin problemas. pero ¬øqu√© sucede cuando cae un nodo?</p>
<div class="ulist">
<ul>
<li>
<p>Si cae un nodo que contiene una de las r√©plicas no l√≠deres, estos quedar√°n <strong>out of sync</strong>, y cuando se recuperen el l√≠der se encargar√° de sincronizarlas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-08.png" alt="kafka topics 08" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si el nodo que cae es el que contiene la r√©plica <strong>Leader</strong>, el controlador de <strong>Kafka</strong> detectar√° la ca√≠da del l√≠der, y elegir√° un nuevo <strong>Leader</strong> de las r√©plicas que est√©n sincronizadas.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-topics-09.png" alt="kafka topics 09" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay varios puntos que tenemos que tener en cuenta</p>
<div class="ulist">
<ul>
<li>
<p>Nunca debemos poner un n√∫mero de <strong>r√©plicas</strong> superior al n√∫mero de <strong>Brokers</strong>, ya que no tiene sentido que un √∫nico <strong>Broker</strong> contenga dos r√©plicas</p>
</li>
<li>
<p>Aumentar las r√©plicas aumentamos la disponibilidad, nuestro sistema es m√°s robusto ante ca√≠das</p>
</li>
<li>
<p>Incrementar las r√©plicas aumenta el consumo de red, ya que el l√≠der debe enviar los datos a las r√©plicas</p>
</li>
<li>
<p>Las r√©plicas disminuyen el rendimiento, porque el l√≠der debe enviar los datos a las r√©plicas y recibir confirmaciones antes de dar la operaci√≥n por buena (se puede configurar para no esperar tantos ack)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por √∫ltimo, vamos a hablar de los mensajes.</p>
</li>
<li>
<p>Los mensajes en <strong>Kafka</strong> est√°n formados por tres partes:</p>
<div class="ulist">
<ul>
<li>
<p>Un Timestamp</p>
</li>
<li>
<p>Una Clave</p>
</li>
<li>
<p>Un valor</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tanto la clave como el valor pueden ser de muchos tipos (ya que son conjuntos de bytes). La Clave puede ser usada para realizar el particionado (env√≠as un mensaje a un <strong>Topic</strong>, pero podemos usar la clave para conseguir que el mensaje acabe en una partici√≥n determinada).</p>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_creaci√≥n_de_topics_y_particionado">4.1. Lab: Creaci√≥n de Topics y particionado</h3>
<div class="ulist">
<ul>
<li>
<p>Para esta pr√°ctica, tenemos que asegurarnos de tener levantado <strong>Zookeeper</strong> y <strong>Kafka</strong> con la configuraci√≥n vista en el apartado anterior.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server bin]$ jps
11409 Jps
10285 QuorumPeerMain
10367 Kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de no ver kafka en la lista, podemos asegurarnos de que est√° conectando desde zookeeper:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
/bin/java
Connecting to localhost:2181
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0]
[zk: localhost:2181(CONNECTED) 1] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://kafka-server.local:9092&quot;],&quot;jmx_port&quot;:-1,&quot;port&quot;:9092,&quot;host&quot;:&quot;kafka-server.local&quot;,&quot;version&quot;:4,&quot;timestamp&quot;:&quot;1604489941572&quot;}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso se puede ver el nodo ef√≠mero del broker con la informaci√≥n de conexi√≥n.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_creaci√≥n_de_topic">4.1.1. Creaci√≥n de topic</h4>
<div class="ulist">
<ul>
<li>
<p>Para crear un <strong>Topic</strong>, disponemos del comando <strong>kafka-topics.sh</strong>. Para lanzarlo hay que especificar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server host:puerto</strong> &#8594; Es necesario indicar d√≥nde est√° el servidor <strong>kafka</strong> (Anteriormente se indicaba zookeeper, pero est√° deprecado)</p>
</li>
<li>
<p><strong>--create</strong> &#8594; Indicamos que vamos a crear un <strong>Topic</strong></p>
</li>
<li>
<p><strong>--topic nombre</strong> &#8594; Damos nombre al <strong>Topic</strong> (cuidado, los guiones bajos y pueden colisionar)</p>
</li>
<li>
<p><strong>--partitions n</strong> &#8594; Indicamos el n√∫mero de particiones que queremos crear para dicho <strong>Topic</strong></p>
</li>
<li>
<p><strong>--replication-factor n</strong> &#8594; Indicamos el n√∫mero de r√©plicas que queremos</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic base-topic --partitions 1 --replication-factor 1
Created topic base-topic.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si usamos ahora el cliente de <strong>Zookeeper</strong>, podemos ver que bajo el <strong>zNode</strong> de <strong>/broker/topics</strong>, ya tenemos nuestro <strong>topic</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
/bin/java
Connecting to localhost:2181
...
[zk: localhost:2181(CONNECTED) 0] ls /brokers/topics
[base-topic]
[zk: localhost:2181(CONNECTED) 1] ls /brokers/topics/base-topic
[partitions]
[zk: localhost:2181(CONNECTED) 2] get /brokers/topics/base-topic
{&quot;version&quot;:2,&quot;partitions&quot;:{&quot;0&quot;:[0]},&quot;adding_replicas&quot;:{},&quot;removing_replicas&quot;:{}}
[zk: localhost:2181(CONNECTED) 3] quit</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si pedimos informaci√≥n de nuestro <strong>Topic</strong>, vemos que nos indica en qu√© <strong>broker</strong> est√° cada partici√≥n</p>
</li>
<li>
<p>Pero el propio <strong>Kafka</strong> a trav√©s de <strong>kafka-topics</strong> permite realizar consultas sobre los <strong>topics</strong></p>
</li>
<li>
<p>Listar los <strong>topics</strong> existentes:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --list
base-topic</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Obtener informaci√≥n de un topic en concreto (Nos muestra informaci√≥n general en la primera l√≠nea, y la relativa a cada partici√≥n en las dem√°s, su l√≠der, las r√©plicas, y los nodos que est√°n en sincron√≠a)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --describe --topic base-topic
Topic: base-topic       PartitionCount: 1       ReplicationFactor: 1    Configs: segment.bytes=1073741824
        Topic: base-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un nuevo <strong>topic</strong> pero esta vez con varias particiones, y consultar sus datos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic base-topic2 --partitions 5 --replication-factor 1
Created topic base-topic2.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como el base-topic2 muestra la informaci√≥n de las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --describe --topic base-topic2
Topic: base-topic2      PartitionCount: 5       ReplicationFactor: 1    Configs: segment.bytes=1073741824
        Topic: base-topic2      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: base-topic2      Partition: 4    Leader: 0       Replicas: 0     Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como s√≥lo disponemos de un <strong>broker</strong>, este posee los l√≠deres y las r√©plicas de todas las particiones.</p>
</li>
<li>
<p>En <strong>Isr</strong> figuran los <strong>broker</strong> que est√°n en sincron√≠a (y evidentemente el l√≠der siempre est√° en sincron√≠a).</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_productores_y_consumidores">5. Productores y consumidores</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Ya hemos hablado de que en <strong>Kafka</strong> existen <strong>Productores</strong> y <strong>Consumidores</strong>.</p>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Productores</strong> son los que crean los mensajes y los mandan a las colas (<strong>topics</strong>)</p>
</li>
<li>
<p>Los <strong>Consumidores</strong> son los que recogen esos mensajes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-01.png" alt="kafka productores consumidores 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>consumidores</strong> pueden funcionar de dos maneras, siguiendo un <strong>modelo de colas</strong> o un <strong>modelo de publicador/suscriptor</strong></p>
</li>
<li>
<p>En el modelo de cola, los mensajes son repartidos entre las instancias del consumidor</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-02.png" alt="kafka productores consumidores 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el modelo de publicador/suscriptor, las instancias de los consumidores recibir√°n todos los mismos mensajes</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-03.png" alt="kafka productores consumidores 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los <strong>Productores</strong> son los encargados de producir los mensajes y enviarlos a los <strong>topics</strong>.</p>
</li>
<li>
<p>Estos mensajes deben ser enviados siempre a la partici√≥n l√≠der, el <strong>productor</strong> conoce cu√°l es el l√≠der de cada partici√≥n, porque al iniciarse, se conecta a uno de los <strong>broker</strong> y le pide el mapa del particionado.</p>
</li>
<li>
<p>Tras obtener este mapa del particionado, ya sabe en qu√© <strong>broker</strong> est√° cada partici√≥n l√≠der</p>
</li>
<li>
<p>Una cosa importante, cada mensaje se va a guardar en una partici√≥n concreta.</p>
</li>
<li>
<p>Esto, a priori, es aleatorio, aunque a veces es interesante que no hagamos un reparto aleatorio, sin conocer (o decidir) de antemano en qu√© partici√≥n acaba cada mensaje (por ejemplo, queremos tener todos los mensajes asociados al id de un cliente en una misma partici√≥n).</p>
</li>
<li>
<p>Para saber en qu√© partici√≥n acaba nuestro mensaje, usaremos su <strong>clave</strong></p>
</li>
<li>
<p>Por temas de rendimiento, los mensajes no se env√≠an de uno en uno, se agrupan en paquetes. Estos paquetes se definen mediante dos condiciones:</p>
<div class="ulist">
<ul>
<li>
<p>Por n√∫mero &#8594; Si llegas a un n√∫mero determinado de mensajes, env√≠a el paquetes</p>
</li>
<li>
<p>Por tiempo &#8594; Si durante un intervalo de tiempo definido, no se llega a acumular el n√∫mero de mensajes indicado, realizamos el env√≠o igualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por su parte, los <strong>consumidores</strong> ser√°n los encargados de leer los mensajes de los distintos <strong>topics</strong> (pero recordad, siempre se leen de las particiones l√≠deres).</p>
</li>
<li>
<p>En versiones antiguas de <strong>Kafka</strong> (0.8 y anteriores), se hac√≠a uso de <strong>Zookeeper</strong> para saber por d√≥nde estaban leyendo, ahora ya no (lo gestiona <strong>kafka</strong> internamente).</p>
</li>
<li>
<p>Para llevar esta gesti√≥n, <strong>Kafka</strong> hace uso de un <strong>topic</strong> especial denominado <strong>__consumer_offsets</strong>.</p>
</li>
<li>
<p>Este <strong>topic</strong> tiene el identificador de cada <strong>grupo de consumidores</strong> y el <strong>offset</strong> por el que va leyendo.</p>
</li>
<li>
<p>Un <strong>grupo de consumidores</strong> es un identificador compartido por varios consumidores. Un <strong>grupo de consumidores</strong> puede tener 1 o varias instancias de consumidores.</p>
</li>
<li>
<p>Si hay m√°s de uno, los consumidores balancean las particiones.</p>
</li>
<li>
<p>Si alg√∫n consumidor se cae, su partici√≥n se asigna a otro consumidor.</p>
</li>
<li>
<p><strong>No se pueden tener m√°s consumidores que particiones</strong>, pero si podemos tener varios <strong>grupos de consumidores</strong> leyendo de una misma partici√≥n (pero s√≥lo un cliente de cada grupo puede leer de una partici√≥n concreta)</p>
</li>
<li>
<p>Un <strong>Grupo de consumidores</strong> puede tener una √∫nica instancia de consumidor, en cuyo caso  procesa los mensajes de todas las particiones del <strong>topic</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-04.png" alt="kafka productores consumidores 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si para el mismo grupo de consumidores, creo una nueva instancia del consumidor, se balancean las particiones</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-05.png" alt="kafka productores consumidores 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con otra instancia adicional, se vuelven balancean las particiones (recordad, no puede haber m√°s consumidores que particiones)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-06.png" alt="kafka productores consumidores 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si alguna instancia cae, la partici√≥n (o particiones) asignadas al consumidor que ha ca√≠do se reasignan a los consumidores existentes.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-05.png" alt="kafka productores consumidores 05" width="400">
</div>
</div>
<div style="page-break-after: always;"></div>
<div class="sect2">
<h3 id="_lab_produciendo_y_consumiendo">5.1. Lab: Produciendo y consumiendo</h3>
<div class="ulist">
<ul>
<li>
<p>Aunque no sea lo habitual, para probar <strong>kafka</strong>, disponemos de dos herramientas de l√≠nea de comandos para poder producir y consumir mensajes:</p>
<div class="ulist">
<ul>
<li>
<p><strong>kafka-console-producer.sh</strong> &#8594; Un productor que nos permite enviar mensajes a un <strong>Topic</strong>, escribiendo directamente desde una shell</p>
</li>
<li>
<p><strong>kafka-console-consumer.sh</strong> &#8594; Un consumidor que nos permite consumir mensajes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Por defecto, el puerto en el que <strong>Kafka</strong> est√° escuchando es el 9092
Para esta prueba, tanto <strong>Zookeeper</strong> como <strong>Kafka</strong> deben estar levantados, y vamos a dar por hecho que existe un <strong>Topic</strong> creado (en nuestro caso <strong>base-topic2</strong>)</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, vamos a lanzar un productor, para ello usaremos <strong>kafka-console-producer.sh</strong>, con las siguientes opciones:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--broker-list</strong> &#8594; lista de los brokers (en nuestro caso s√≥lo hay uno, nuestra m√°quina)</p>
</li>
<li>
<p><strong>--topic</strong> &#8594; El topic sobre el que queremos enviar mensajes</p>
</li>
</ul>
</div>
</li>
<li>
<p>Esto nos deja la shell abierta, cada l√≠nea que escribamos a partir de ah√≠ es un mensaje</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2
&gt;mensaje 1
&gt;mensaje 2
&gt;otro mensaje</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>No cerreis la consola con los mensajes, ya que m√°s adelante escribiremos m√°s mensajes</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a arrancar ahora un consumidor (en otra shell), usando el comando <strong>kafka-console-consumer.sh</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server</strong> &#8594; Servidor al que vamos a atacar</p>
</li>
<li>
<p><strong>--new-consumer</strong> &#8594; Todav√≠a da soporte a versiones antiguas del consumer, con esto indicamos que usamos la nueva</p>
</li>
<li>
<p><strong>--topic</strong> &#8594; el <strong>topic</strong> a consumir</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic base-topic2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ahora escribimos "algo" en el productor, se muestra en nuestro consumidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Shell productor</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2
&gt;mensaje 1
&gt;mensaje 2
&gt;otro mensaje
&gt;mas mensajes</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Shell consumidor tras el evento</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2
mas mensajes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hemos mostrado los nuevos mensajes, pero ¬øy qu√© pasa con los creados antes de arrancar nuestro consumidor?</p>
</li>
<li>
<p>Pues podemos mostrarlos si usamos la opci√≥n <strong>--from-beginning</strong></p>
</li>
<li>
<p>Para ello paramos el consumidor con CTRL+C</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2
mas mensajes
^CProcessed a total of 1 messages</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora lo arrancamos con el nuevo argumento</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning
mensaje 2
mas mensajes
mensaje 1
otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si os acord√°is, hemos dicho que los mensajes viajan con una clave y un valor, pero ¬øqu√© clave hemos proporcionado para  estos mensajes?.</p>
</li>
<li>
<p>Podemos ver la clave usando la opci√≥n <strong>--property print.key=true</strong></p>
</li>
<li>
<p>Para ello volvemos a cerrarlo con CTRL+C y lo abrimos con la nueva directiva</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true
null        mensaje 2
null        mas mensajes
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bueno, tiene sentido. No hemos especificado clave alguna, as√≠ que es normal que est√© a <strong>null</strong>. Paramos el consumidor.</p>
</li>
<li>
<p>Vamos a parar y levantar el productor, pero indicando que vamos a usar una clave, separada por el caracter que indiquemos de su valor. Esto se hace con la propiedades <strong>--property parse.key=true --property key.separator=,</strong> (indicamos que hay que parsear clave, y en este caso usaremos la coma como separador)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2 --property parse.key=true --property key.separator=,
&gt;clave1,valor1
&gt;clave2,valor2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si intento poner una l√≠nea sin clave, da error:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">&gt;otra
org.apache.kafka.common.KafkaException: No key found on line 3: otra
        at kafka.tools.ConsoleProducer$LineMessageReader.readMessage(ConsoleProducer.scala:290)
        at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:51)
        at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Muestra de consumidor tras guardar los valores con clave</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos nuestro consumidor.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Pulsando CTRL+C</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">^CProcessed a total of 6 messages</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos ahora a levantar m√∫ltiples consumidores, para ello les asignaremos un mismo grupo de consumidores.</p>
</li>
<li>
<p>Usaremos el fichero <strong>consumer.properties</strong> que viene distribuido con <strong>Kafka</strong> para levantar los consumidores indicando su grupo</p>
</li>
<li>
<p>Este fichero contiene una propiedad <strong>group.id</strong> que indica cu√°l es el id del grupo de consumidores (en nuestro caso <strong>test-consumer-group</strong>).</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cat /opt/kafka/config/consumer.properties | grep group.id
# consumer group id
group.id=test-consumer-group</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Levantamos ahora un consumidor haciendo uso del fichero de configuraci√≥n que hemos visto (y procesando desde el principio de los tiempos)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ahora levanto un nuevo cliente con exactamente la misma configuraci√≥n, (abrid una nueva terminal), sucede lo siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nada. Como seguimos consumiendo del mismo <strong>topic</strong>, y nuestro grupo de consumidores ya ha procesado esos mensajes (si ejecut√°ramos un nuevo grupo de consumidores, si los volver√≠amos a procesar).</p>
</li>
<li>
<p>Pero nuestro <strong>topic</strong> tiene varias particiones, por lo que una vez se incluye un nuevo consumidor a un grupo, se balancean las particiones.</p>
</li>
<li>
<p>Vamos a probar a crear varios mensajes nuevos en nuestro productor (con distintas claves).</p>
</li>
<li>
<p>Fijaros tambi√©n como la misma clave acaba siempre en la misma partici√≥n*</p>
</li>
<li>
<p>Para probarlo, abrimos una tercera shell y ejecutamos el siguiente productor introduciendo los mensajes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Productor con dos consumidores del mismo grupo</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic base-topic2 --property parse.key=true --property key.separator=,
&gt;1,1
&gt;2,2
&gt;5,5
&gt;3,3
&gt;5,4
&gt;5,9
&gt;5,8</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor 1 de test-consumer-group</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
null        mensaje 2
null        mas mensajes
clave1        valor1
clave2        valor2
null        mensaje 1
null        otro mensaje
5        5
5        4
5        9
5        8</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor 2 de test-consumer-group</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic base-topic2 --from-beginning --property print.key=true --consumer.config ${KAFKA_HOME}/config/consumer.properties
1        1
2        2
3        3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, vamos a ver el directorio donde <strong>Kafka</strong> guarda sus datos (<strong>logs</strong>).</p>
</li>
<li>
<p>El fichero de configuraci√≥n de <strong>kafka</strong> tiene una propiedad <strong>log.dirs</strong>.</p>
</li>
<li>
<p>Esta es la ruta donde guardamos los <strong>logs</strong>.</p>
</li>
<li>
<p>En esta ruta estar√°n todos los <strong>topics</strong> (y los <strong>__consumer_offsets</strong>, que los crea <strong>kafka</strong> autom√°ticamente)</p>
</li>
<li>
<p>Para ver la ruta donde est√°n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cat ${KAFKA_HOME}/config/server.properties | grep kafka-logs
log.dirs=/tmp/kafka-logs</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos su contenido</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tree /tmp/kafka-logs/ -L 1
/tmp/kafka-logs/
‚îú‚îÄ‚îÄ base-topic-0
‚îú‚îÄ‚îÄ base-topic2-0
‚îú‚îÄ‚îÄ base-topic2-1
‚îú‚îÄ‚îÄ base-topic2-2
‚îú‚îÄ‚îÄ base-topic2-3
‚îú‚îÄ‚îÄ base-topic2-4
‚îú‚îÄ‚îÄ cleaner-offset-checkpoint
‚îú‚îÄ‚îÄ __consumer_offsets-0
‚îú‚îÄ‚îÄ __consumer_offsets-1
‚îú‚îÄ‚îÄ __consumer_offsets-10
...
‚îú‚îÄ‚îÄ log-start-offset-checkpoint
‚îú‚îÄ‚îÄ meta.properties
‚îú‚îÄ‚îÄ recovery-point-offset-checkpoint
‚îî‚îÄ‚îÄ replication-offset-checkpoint</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como pod√©is observar, cada <strong>topic</strong> no tiene un √∫nico directorio, si no un √∫nico directorio por partici√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tree /tmp/kafka-logs/base-topic2-0 -L 1
/tmp/kafka-logs/base-topic2-0
‚îú‚îÄ‚îÄ 00000000000000000000.index
‚îú‚îÄ‚îÄ 00000000000000000000.log
‚îú‚îÄ‚îÄ 00000000000000000000.timeindex
‚îî‚îÄ‚îÄ leader-epoch-checkpoint</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El fichero <strong>.log</strong> es el que contiene los mensajes que hemos enviado.</p>
</li>
<li>
<p>Si hacemos un <strong>cat</strong> podemos ver que (entre los datos binarios), est√°n los mensajes que yo he enviado)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-productores-consumidores-lab-01.png" alt="kafka productores consumidores lab 01" width="300">
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_log_compaction">6. Log Compaction</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Log Compaction</strong> es una propiedad que asegura que se almacena el √∫ltimo valor para una clave dada.</p>
<div class="ulist">
<ul>
<li>
<p>Esto es configurable a nivel de <strong>Topic</strong> (puedes tener <strong>topics</strong> que lo usen, y otros que no).</p>
</li>
<li>
<p>Es de especial utilidad cuando hay que recuperar un estado tras un fallo, o restaurar una cach√© que se ha ido creando durante la ejecuci√≥n de un proceso.</p>
</li>
<li>
<p>En sistemas como <strong>Kafka Stream</strong> o <strong>Apache Samza</strong> es de bastante utilidad.</p>
</li>
<li>
<p>En la siguiente imagen vemos el aspecto que tiene un <strong>topic</strong>, que recibe mensajes (clave,valor), y les asigna un <strong>offset</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-01.png" alt="kafka log compaction 01" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>Log Compaction</strong> identifica los mensajes que tienen una misma clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-02.png" alt="kafka log compaction 02" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Despu√©s, se queda con un √∫nico mensaje por clave, siendo este el que mayor <strong>offset</strong> posee</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-03.png" alt="kafka log compaction 03" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Dejando el log con las √∫ltimas versiones de cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-04.png" alt="kafka log compaction 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Un caso de uso de esto ser√≠a una aplicaci√≥n de streaming que guarda una cach√© de los √∫ltimos valores recibidos.</p>
</li>
<li>
<p>Para ello, va leyendo de un <strong>topic</strong> la informaci√≥n, y actualizando su cach√©.</p>
</li>
<li>
<p>Al mismo tiempo, guarda en un <strong>topic</strong> propio con <strong>log compaction</strong> los datos que lee.</p>
</li>
<li>
<p>Si el sistema se cae, vuelve a levantarse leyendo todos los datos del <strong>topic</strong> en cuesti√≥n, regenerando as√≠ su cach√© de forma autom√°tica</p>
</li>
<li>
<p>Los productores escriben en un topic</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-05.png" alt="kafka log compaction 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestra aplicaci√≥n, consume los mensajes de dicho topic</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-06.png" alt="kafka log compaction 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al consumir los mensajes, va creando una cach√© (por clave)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-07.png" alt="kafka log compaction 07" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Todos los mensajes que lee, los guarda en un topic con log compaction. Internamente, actualiza los valores de su cach√© si una clave ya hab√≠a sido le√≠da</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-08.png" alt="kafka log compaction 08" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La cach√© tendr√° un subconjunto de datos, pero el topic con Log Compaction habr√° recibido el total de los mensajes le√≠dos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-09.png" alt="kafka log compaction 09" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al hacer un Log Compaction, el topic se queda con un √∫nico mensaje por cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-10.png" alt="kafka log compaction 10" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestra aplicaci√≥n se cae</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-11.png" alt="kafka log compaction 11" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al levantarse, se conecta a su topic como consumidor</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-12.png" alt="kafka log compaction 12" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El topic, le proporciona todos los mensajes, que contienen s√≥lo la √∫ltima versi√≥n de cada clave</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-13.png" alt="kafka log compaction 13" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con estos mensajes, la cach√© se ha regenerado, y la aplicaci√≥n puede volver a trabajar con normalidad.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-log-compaction-14.png" alt="kafka log compaction 14" width="400">
</div>
</div>
<div class="sect2">
<h3 id="_configuraci√≥n_2">6.1. Configuraci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>La creaci√≥n de un topic con log_compaction implica definir una serie de configuraciones:</p>
<div class="ulist">
<ul>
<li>
<p><strong>cleanup.policy</strong></p>
<div class="ulist">
<ul>
<li>
<p><strong>compact</strong>: Implica que se activa la compactaci√≥n.</p>
</li>
<li>
<p><strong>delete</strong>: Junto con compact, se pueden purgar las entradas m√°s antiguas.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>delete.retention.ms</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Por defecto, en la fase de limpieza, los mensajes duplicados son eliminados, y aquellos que tengan el valor a null tambi√©n. Esos records se les llama tombstones.</p>
</li>
<li>
<p>Si el tiempo es menor al indicado, los tombstones permanecen, sino son eliminados.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>segment.ms</strong>:</p>
<div class="ulist">
<ul>
<li>
<p>Es el tiempo que tarda en realizar un nuevo segmento. Hay que tener en cuenta que no todos los segmentos se compactan, sino que solo se compactan los segmentos que pertenecen a la cola (tail).</p>
</li>
<li>
<p>Estos segmentos se compactan formando uno m√°s grande.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>min.cleanable.dirty.ratio</strong></p>
<div class="ulist">
<ul>
<li>
<p>El broker de kafka crea una serie de hilos para la limpieza <strong>log.cleaner.threads</strong>. Tratar√° de buscar el log que peor est√© y tratar√° de limpiarlo.</p>
</li>
<li>
<p>El calculo se realiza con: bytes_head / (bytes_head + bytes_tail)</p>
</li>
<li>
<p>Si el ratio se cumple, ejecuta la limpieza, sino el hilo es bloqueado. El tiempo de bloqueo se puede elegir con <strong>log.cleaner.backoff.ms</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_tuning">6.2. Tuning</h3>
<div class="sect3">
<h4 id="_log_cleaner_dedupe_buffer_size">6.2.1. log.cleaner.dedupe.buffer.size</h4>
<div class="ulist">
<ul>
<li>
<p>Podemos modificar el tama√±o del buffer asignado para limpieza.</p>
</li>
<li>
<p>Eso permitir√≠a que las compactaciones grandes se hicieran m√°s r√°pido, sin embargo, la cantidad de memoria asignada puede tener un gran impacto.</p>
</li>
<li>
<p>No se debe superar el GB ya que tambi√©n realiza operaciones IO muy costosas en limpieza.</p>
</li>
<li>
<p>Como ejemplo:</p>
<div class="ulist">
<ul>
<li>
<p>Si tenemos m√°s de 1800 millones de mensajes para compactar, en 3 particiones, ser√≠an como 600 millones de mensajes por broker.</p>
</li>
<li>
<p>Con la configuraci√≥n est√°ndar tardar√≠a unas 100 iteraciones del log en limpiarlo.</p>
</li>
<li>
<p>Si ampliamos a <strong>1GB de memoria</strong>, podemos alterarlo a 1GB, lo que implica unos 45 millones de mensajes por iteraci√≥n.</p>
</li>
<li>
<p>Nos dar√≠a un total de 15 iteraciones para poder limpiarlo.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_log_cleaner_threads">6.2.2. log.cleaner.threads</h4>
<div class="ulist">
<ul>
<li>
<p>Si abusamos del uso de log compaction, hay que tener en cuenta los consumos asociados:</p>
</li>
<li>
<p>Estos hilos (por defecto 1), se dedicar√°n a hacer limpieza en vez de servir peticiones a productores y consumidores.</p>
</li>
<li>
<p>Dependiendo de la prioridad podemos ampliar el n√∫mero de hilos</p>
</li>
<li>
<p>Si lo que queremos es seguir dando un √≥ptimo servicio, dejamos a 1 el n√∫mero de hilos optimizando el resto de par√°metros.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_particiones">6.2.3. particiones</h4>
<div class="ulist">
<ul>
<li>
<p>Aqu√≠ est√° el punto cr√≠tico.</p>
</li>
<li>
<p>Podemos calcular el n√∫mero √≥ptimo de particiones para que nuestro cleaner tarde lo menos posible.</p>
</li>
<li>
<p>Para ello, dividimos el total de mensajes por 45 y nos dar√° el n√∫mero de particiones √≥ptima</p>
</li>
<li>
<p>Dividimos los 1800 millones por los 45, lo que nos da 40 particiones.</p>
</li>
<li>
<p>Con 40 particiones tendremos el rendimiento √≥ptimo de un topic con log_compaction.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_min_cleanable_dirty_ratio">6.2.4. min.cleanable.dirty.ratio</h4>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que seg√∫n el n√∫mero de mensajes por segundo que llegan, puede que gran cantidad de mensajes queden en el head y no se procesen.</p>
</li>
<li>
<p>Por eso hay que tener en cuenta que el uso por defecto de 0.5 puede dejar una gran cantidad de mensajes almacenados sin procesar</p>
</li>
<li>
<p>Su procesamiento consume IO, pero su almacenamiento consume IO tambi√©n si los clientes leen desde el principio, algo com√∫n en este tipo de topics, con lo cual compensa reducir este valor.</p>
</li>
<li>
<p>0,25 o 0,2 son valores recomendables.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_log_compaction">6.3. Lab: Log compaction</h3>
<div class="ulist">
<ul>
<li>
<p>Vamos a compactar un topic y a comprobar como el resultado de producir mensajes y de consumirlos respeta las reglas aplicadas.</p>
</li>
<li>
<p>Para ello vamos a definir los siguientes par√°metros</p>
<div class="ulist">
<ul>
<li>
<p>cleanup.policy=compact: Necesitamos definir la pol√≠tica de compactaci√≥n para el topic de forma expl√≠cita</p>
</li>
<li>
<p>delete.retention.ms=100: Indica que el consumidor ver√° los valores eliminados (tombstones) hasta alcanzar la cabeza del log, en menos del tiempo de retention policy. Por defecto son 24 horas.</p>
</li>
<li>
<p>log.cleaner.threads: El n√∫mero de hilos que se dedican a compactar. El hilo de limpieza elige el log con mayor ratio de "suciedad".</p>
<div class="ulist">
<ul>
<li>
<p>ratio = bytes en la cabecera / total de bytes en el log</p>
</li>
</ul>
</div>
</li>
<li>
<p>min.compaction.lag.ms: Garantiza un periodo m√≠nimo de espera antes de compactar un mensaje.</p>
</li>
<li>
<p>log.cleaner.min.compaction.lag.ms: Los registros no se compactan hasta que no tengan este tiempo sobrepasado.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Ahora creamos un nuevo topic con log compaction</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic topic-log-compaction --replication-factor 1 --partitions 1 --config &quot;cleanup.policy=compact&quot; --config &quot;delete.retention.ms=100&quot;  --config &quot;segment.ms=100&quot; --config &quot;min.cleanable.dirty.ratio=0.01&quot;
Created topic topic-log-compaction.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un productor y mandamos los siguientes mensajes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-server.local:9092 --topic topic-log-compaction --property parse.key=true --property key.separator=,
&gt;K1,V1
&gt;K2,V2
&gt;K1,V3
&gt;K3,V4
&gt;K2,V5
&gt;K4,V6
&gt;K5,V7
&gt;K5,V8
&gt;K6,V9</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como se ha quedado solo con los dos ultimos valores de cada clave, el resto ha sido compactado</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-server.local:9092 --topic topic-log-compaction --from-beginning --property print.key=true
K1        V3
K3        V4
K2        V5
K4        V6
K5        V8
K6        V9</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Seg√∫n se vayan agregando nuevos registros, hasta que no se alcanza un hito, no compacta.</p>
</li>
<li>
<p>Tambi√©n hay que tener en cuenta que solo se compacta la cola, con lo cual, los registros del head no se compactan, lo que da a duplicados comunmente</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_configuraci√≥n_de_kafka">7. Configuraci√≥n de kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_configuraci√≥n_del_broker">7.1. Configuraci√≥n del Broker</h3>
<div class="ulist">
<ul>
<li>
<p>En <strong>Kafka</strong>, cada <strong>Broker</strong> tiene una configuraci√≥n le√≠da de un fichero <strong>server.properties</strong>, que tenemos que proporcionar al levantar el <strong>Broker</strong>.</p>
</li>
<li>
<p>Este fichero de configuraci√≥n tiene varias propiedades muy interesantes, que nos conviene conocer para poder trabajar correctamente.</p>
</li>
<li>
<p>En este tema conoceremos las opciones m√°s comunes, aunque si quer√©is conocer en profundidad todas las opciones disponibles, pod√©is consultar la documentaci√≥n oficial (apartado configuraci√≥n) en :</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://kafka.apache.org/documentation/#configuration" class="bare">https://kafka.apache.org/documentation/#configuration</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Un fichero de configuraci√≥n del <strong>Broker</strong>, contiene configuraci√≥n de distintas secciones:</p>
<div class="ulist">
<ul>
<li>
<p>Informaci√≥n b√°sica del servidor</p>
</li>
<li>
<p>Sockets por los que escucha</p>
</li>
<li>
<p>Informaci√≥n de ficheros Log y creaci√≥n autom√°tica de topics</p>
</li>
<li>
<p>Informaci√≥n del servidor Zookeeper</p>
</li>
<li>
<p>Gesti√≥n de espacio y retenci√≥n de ficheros Log</p>
</li>
</ul>
</div>
</li>
<li>
<p>Las configuraciones en kafka desde la versi√≥n 1.1.0+ se pueden modificar desde la utilidad <strong>kafka-configs.sh</strong></p>
</li>
<li>
<p>Sin embargo, algunas de ellas siguen siendo necesario reiniciar la instancia modificando el fichero <strong>server.properties</strong></p>
</li>
<li>
<p>La informaci√≥n m√°s b√°sica para el servidor es el campo <strong>broker.id</strong>.</p>
</li>
<li>
<p>Dicho campo posee el identificador √∫nico de nuestro <strong>Broker</strong>, y no puede ser usado por ning√∫n otro <strong>Broker</strong> del cl√∫ster.</p>
</li>
<li>
<p>No obstante, en ocasiones nos interesa que este identificador sea generado autom√°ticamente (por ejemplo, en entornos cloud como <strong>AWS</strong> o <strong>Google Cloud Computing</strong>).</p>
</li>
<li>
<p>Si queremos que el id de nuestro <strong>broker</strong> se genere autom√°ticamente, debemos borrar la propiedad <strong>broker.id</strong> e incluir las propiedades:</p>
<div class="ulist">
<ul>
<li>
<p><strong>broker.id.generation.enable=true</strong> &#8594; Para activar la asignaci√≥n autom√°tica de ids</p>
</li>
<li>
<p><strong>reserved.broker.max.id=n</strong> &#8594; Empieza a asignar los ids a partir del n√∫mero especificado, reservando los anteriores para aquellos <strong>broker</strong> cuyo id est√© especificado en el fichero de configuraci√≥n.</p>
</li>
</ul>
</div>
</li>
<li>
<p>El siguiente ejemplo (de una subsecci√≥n del fichero server.properties) configurar√≠a un <strong>broker</strong> con <strong>broker.id=3</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Si quisi√©ramos que asignara autom√°ticamente su id, deber√≠amos comentar/borrar esa l√≠nea e incluir por ejemplo la siguiente (genera a partir del id=1000)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#broker.id=3
broker.id.generation.enable=true
reserved.broker.max.id=1000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a los <strong>listeners</strong>, puedes configurar <strong>KAFKA</strong> para que escuche a trav√©s de un interfaz de red. En el ejemplo siguiente configuramos nuestro <strong>Broker</strong> para que est√© escuchando en todas las direcciones de la m√°quina, a trav√©s del puerto <strong>9092</strong>, y en formato de texto plano (sin seguridad o cifrado)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>listeners=PLAINTEXT://0.0.0.0:9092</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ten√©is m√∫ltiples interfaces de red, ten√©is que decir a trav√©s de cu√°l escuch√°is. Si tu nodo recibe informaci√≥n por un interfaz que no es el especificado, <strong>Kafka</strong> no lo recibir√°.</p>
</li>
<li>
<p>Con respecto a la configuraci√≥n de los ficheros de <strong>Log</strong> y los <strong>topics</strong>, lo principal es especificar la ruta donde vamos a almacenar nuestros ficheros. Esto lo especifica la propiedad <strong>log.dirs</strong>.</p>
</li>
<li>
<p>Esta propiedad permite recibir m√∫ltiples directorios (separados por coma).</p>
</li>
<li>
<p><strong>Kafka</strong> balancear√° en estos directorios la escritura de los ficheros, permiti√©ndonos mejorar el rendimiento en caso de disponer de varios discos (al escribir y leer en paralelo desde m√°s de uno gracias a esta configuraci√≥n).</p>
</li>
<li>
<p>Por defecto, esta propiedad apunta a la ruta <strong>/tmp/kafka-logs</strong>. Si borramos el contenido de esta carpeta, dejaremos <strong>Kafka</strong> como reci√©n instalado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.dirs=/tmp/kafka-logs</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Adem√°s de la ruta de escritura en disco, <strong>Kafka</strong> nos permite realizar la creaci√≥n de topics de manera autom√°tica.</p>
</li>
<li>
<p>Cuando un productor quiere escribir en un <strong>topic</strong> que no existe, podemos permitir que <strong>Kafka</strong> lo cree de forma inmediata, usando un n√∫mero de particiones y factor de replicaci√≥n por defecto</p>
<div class="ulist">
<ul>
<li>
<p><strong>num.partitions</strong> &#8594; El n√∫mero de particiones que tendr√°n los <strong>topics</strong> creados de forma autom√°tica</p>
</li>
<li>
<p><strong>default.replication.factor</strong> &#8594; El factor de replicaci√≥n que tendr√°n los <strong>topics</strong> creados de esta forma</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existe una propiedad <strong>auto.create.topics.enable</strong> que por defecto vale <strong>true</strong>, que es la que nos permite la creaci√≥n autom√°tica de <strong>topics</strong>.</p>
</li>
<li>
<p>Si no quisi√©ramos crear autom√°ticamente <strong>topics</strong>, tendr√≠amos que ponerla a <strong>false</strong> espec√≠ficamente (si no, se especifica, se crean autom√°ticamente)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Creaci√≥n autom√°tica</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">num.partitions=1
default.replication.factor=1</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sin creaci√≥n autom√°tica</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">#num.partitions=1
#default.replication.factor=1
auto.create.topics.enable=false</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a la configuraci√≥n de <strong>Zookeeper</strong>, solo tenemos que especificar la ruta al cl√∫ster y especificar un timeout para realizar dicha conexi√≥n.</p>
<div class="ulist">
<ul>
<li>
<p><strong>zookeeper.connect</strong> &#8594; Especificamos los hosts y puertos (separados por coma) de nodos que forman nuestro ensamble de Zookeeper</p>
</li>
<li>
<p><strong>zookeeper.connection.timeout.ms</strong> &#8594; Tiempo m√°ximo que esperamos para conectarnos a un servidor (si falla, pasamos al siguiente de la lista)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">zookeeper.connect=nodo1:2181,nodo2:2181
zookeeper.connection.timeout.ms=6000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nos queda un punto importante para finalizar con la configuraci√≥n del <strong>Broker</strong>, y es referente a la gesti√≥n del espacio en disco.</p>
</li>
<li>
<p>Los sistemas con los que trabajamos tienen un disco duro finito, por lo que puede darse la situaci√≥n de que llenemos nuestro sistema de almacenamiento.</p>
</li>
<li>
<p>Un disco lleno imposibilita el correcto funcionamiento de <strong>Kafka</strong>, ya que en cuanto esto sucede <strong>Zookeeper</strong> ya no es capaz de realizar m√°s escrituras y <strong>kafka</strong> no puede guardar los mensajes recibidos.</p>
</li>
<li>
<p>Para evitar estas situaciones, tenemos que controlar el espacio en disco, y para ello <strong>Kafka</strong> nos proporciona la <strong>Log Retention Policy</strong>, que nos permite establecer l√≠mites al espacio usado en disco o al tiempo que almacenamos los mensajes recibidos.</p>
</li>
<li>
<p>La <strong>Log Retention Policy</strong> permite configurar dos pol√≠ticas de retenci√≥n de datos:</p>
<div class="ulist">
<ul>
<li>
<p>Estableciendo unos l√≠mites al tama√±o de los datos a almacenar.</p>
</li>
<li>
<p>Estableciendo un tiempo m√°ximo en el que almacenaremos la informaci√≥n.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Estas pol√≠ticas no son excluyentes, con lo que podemos configurar ambas, permitiendo que los datos se almacenen un tiempo m√°ximo o bien hasta llegar a un m√°ximo de espacio. Cuando una de las dos cotas se cumplen, se eliminan los datos antiguos.</p>
</li>
<li>
<p>Es por esto que es necesario conocer cu√°l va a ser el uso que vamos a tener de nuestro sistema.</p>
</li>
<li>
<p>Ejemplo:</p>
<div class="ulist">
<ul>
<li>
<p>4 topics</p>
</li>
<li>
<p>20 particiones por topic</p>
</li>
<li>
<p>Un factor de replicaci√≥n 2</p>
</li>
<li>
<p>Contamos con 2 <strong>Brokers</strong> (es el m√≠nimo, para este factor de replicaci√≥n)</p>
</li>
<li>
<p>¬øCu√°ntos <strong>Logs</strong> vamos a tener?</p>
<div class="ulist">
<ul>
<li>
<p>N√∫mero de topics X N√∫mero de particiones X Factor de replicaci√≥n</p>
</li>
<li>
<p>4 X 20 X 2 = 160 Logs</p>
</li>
</ul>
</div>
</li>
<li>
<p>¬øCu√°ntos logs vamos a tener por Broker?</p>
<div class="ulist">
<ul>
<li>
<p>160 Logs / 2 Brokers = 80 Logs por Broker</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a calcular cual es la cuota m√°xima que podemos usar en disco.</p>
<div class="ulist">
<ul>
<li>
<p>Si nuestros Brokers disponen de un disco duro con unos 450 GB libres.</p>
</li>
<li>
<p>Espacio disponible / Logs por Broker = Tama√±o m√°ximo por Log</p>
</li>
<li>
<p>450 / 80 = 5.635 &#8594; redondeamos a 5 GB para tener margen</p>
</li>
<li>
<p>Cada fichero de Log puede llegar a ocupar hasta 5 GB.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Para gestionar el espacio en disco, podemos activar la limpieza de ficheros de Log:</p>
<div class="ulist">
<ul>
<li>
<p><strong>log.cleaner.enable</strong> &#8594; lo pondremos a true para activar la limpieza</p>
</li>
<li>
<p><strong>log.retention.bytes</strong> &#8594; Indicaremos (en bytes) el espacio m√°ximo de cada Log</p>
</li>
<li>
<p><strong>log.segment.bytes</strong> &#8594; un Log puede a su vez estar dividido en distintos ficheros m√°s peque√±os, esto especifica el tama√±o m√°ximo de cada uno. Cuando superemos el m√°ximo total, borraremos el segmento m√°s antiguo.</p>
</li>
<li>
<p><strong>log.retention.check.interval.ms</strong> &#8594; Cada cuanto tiempo revisamos si se ha superado el tama√±o m√°ximo (Por esto debemos dejar cierto margen)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.bytes=5368709120
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A dem√°s de una pol√≠tica de espacios, podemos configurar otra pol√≠tica, especificando un tiempo m√°ximo que vamos a mantener los mensajes. Para ello, usaremos las siguientes propiedades:</p>
<div class="ulist">
<ul>
<li>
<p><strong>log.cleaner.enable</strong> &#8594; lo pondremos a true para activar la limpieza</p>
</li>
<li>
<p><strong>log.retention.hours</strong> &#8594; Indicaremos (en horas) el m√°ximo de tiempo que vamos a almacenar (hay opciones de configurar otras unidades de tiempo)</p>
</li>
<li>
<p><strong>log.segment.bytes</strong> &#8594; un Log puede a su vez estar dividido en distintos ficheros m√°s peque√±os, esto especifica el tama√±o m√°ximo de cada uno. Cuando superemos el m√°ximo total, borraremos el segmento m√°s antiguo.</p>
</li>
<li>
<p><strong>log.retention.check.interval.ms</strong> &#8594; Cada cuanto tiempo revisamos si se ha superado el tiempo m√°ximo</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ambas pol√≠ticas pueden estar conviviendo juntas, que es de especial utilidad para cuando estimamos una carga de datos semanal que no deber√≠a llenar nuestro disco, pero establecemos un l√≠mite por si se llega a saturar el sistema (siempre es mejor perder los datos m√°s antiguos que dejar de dar servicio)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
log.retention.hours=168
log.retention.bytes=5368709120
log.segment.bytes=1073741824
log.retention.check.interval.ms=30000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una √∫ltima directiva de configuraci√≥n que puede resultar interesante, a nivel de <strong>broker</strong> es:</p>
<div class="ulist">
<ul>
<li>
<p><strong>controlled.shutdown.enable=true</strong>: Esta configuraci√≥n asegura un apagado correcto, que evita p√©rdidas de datos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Hay que tener en cuenta que cuando se apaga un <strong>broker</strong>, las particiones l√≠deres que ten√≠a dicho <strong>broker</strong> sufren una indisponibilidad (hasta que son reasignados).</p>
</li>
<li>
<p>Con esta configuraci√≥n, el <strong>broker</strong> al recibir la se√±al de finalizaci√≥n, persiste los mensajes que todav√≠a tuviera en memoria, y luego se asegura que otro <strong>Broker</strong> haya cogido sus particiones l√≠deres antes de apagarse.</p>
</li>
<li>
<p>El apagado tarda ligeramente m√°s, pero las mejoras de disponibilidad del sistema lo compensan con creces.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_optimizaci√≥n">7.2. Optimizaci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>Kafka posee una serie de configuraciones que se pueden cambiar en tres niveles:</p>
<div class="ulist">
<ul>
<li>
<p>read-only: Implica que se debe cambiar en el fichero de configuraci√≥n de kafka server.properties y reiniciar el servicio</p>
</li>
<li>
<p>per-broker: Se cambia desde kafka-configs indicando el id de broker a modificar (entity-name)</p>
</li>
<li>
<p>cluster-wide: Permite indicar el valor por defecto a nivel de todo el cluster.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_message_max_bytes">7.2.1. message.max.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto 1000012 (1MB)</p>
</li>
<li>
<p>El tama√±o comprimido del mensaje de mayor tama√±o.</p>
</li>
<li>
<p>Debe estar en consonancia con los consumidores</p>
<div class="ulist">
<ul>
<li>
<p>La directiva en consumidores es: <strong>fetch.message.max.bytes</strong></p>
</li>
<li>
<p>Debemos asegurarnos de que message.max.bytes es mayor o igual que fetch.message.max.bytes, ya que sino, el consumidor esperar√° un mensaje que el productor no puede enviar.</p>
</li>
<li>
<p>Se puede sobreescribir desde los topics con max.message.bytes</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_replica_fetchers">7.2.2. num.replica.fetchers</h4>
<div class="ulist">
<ul>
<li>
<p>Permite definir el n√∫mero de hilos que se encargan de replicar los datos del lider a los seguidores.</p>
</li>
<li>
<p>Seg√∫n el n√∫mero de particiones del broker y r√©plicas en otros, podemos calcular el n√∫mero de hilos √≥ptimo a utilizar.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_replica_fetch_max_bytes">7.2.3. replica.fetch.max.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Permite indicar el tama√±o del paquete a sincronizar.</p>
</li>
<li>
<p>Si se incrementa, tardar√° menos en sincronizar los followers</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_replica_socket_receive_buffer_bytes">7.2.4. replica.socket.receive.buffer.bytes</h4>
<div class="ulist">
<ul>
<li>
<p>Permite incrementar el buffer y reducir el n√∫mero de hilos para la creaci√≥n de la r√©plicas.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_partitions">7.2.5. num.partitions</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto poseemos un valor, sin embargo se puede especificar en cada topic.</p>
</li>
<li>
<p>Hay que tener en cuenta que un elevado n√∫mero de particiones con pocos brokers pueden producir un cuello de botella en el sistema.</p>
</li>
<li>
<p>Este c√°lculo debe ser proporcional a los recursos que disponemos.</p>
</li>
<li>
<p>Si permitimos la creaci√≥n autom√°tica de topics, es importante que definamos el n√∫mero de particiones seg√∫n nuestras necesidades gen√©ricas.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_io_threads">7.2.6. num.io.threads</h4>
<div class="ulist">
<ul>
<li>
<p>Hilos para lectura/escritura en disco</p>
</li>
<li>
<p>Podemo optimizar el n√∫mero de hilos seg√∫n el n√∫mero de peticiones que recibimos.</p>
</li>
<li>
<p>A m√°s hilos, mas uso de io</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_num_recovery_threads_per_data_dir">7.2.7. num.recovery.threads.per.data.dir</h4>
<div class="ulist">
<ul>
<li>
<p>Por defecto 1.</p>
</li>
<li>
<p>Permite la recuperaci√≥n de particiones tras una caida.</p>
</li>
<li>
<p>Para su recuperaci√≥n, usa estos hilos, uno por cada directorio de datos.</p>
</li>
<li>
<p>Tambien cierra los ficheros de forma normal.</p>
</li>
<li>
<p>Tras fallo, puede retrasar la recuperaci√≥n del servidor mucho tiempo.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_creaci√≥n_de_un_cl√∫ster_multi_broker">7.3. Lab: Creaci√≥n de un Cl√∫ster Multi-Broker</h3>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>El zookeeper debe estar iniciado para continuar la pr√°ctica.</p>
</li>
<li>
<p>Para ello, iniciamos zookeeper si no lo est√° usando el siguiente comando</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para la siguiente pr√°ctica, vamos a crear un cl√∫ster en nuestra m√°quina virtual.</p>
</li>
<li>
<p>Esta misma pr√°ctica se puede (y ser√≠a mucho m√°s provechosa) realizar con m√∫ltiples instancias de m√°quinas virtuales para crear un cl√∫ster de verdad.</p>
</li>
<li>
<p>Para ello tan solo tendr√≠amos que sustituir las ips de bucle local por las ips de las VMs</p>
</li>
<li>
<p>Antes de empezar, vamos a dar de alta en el fichero hosts las ips y nombres de las m√°quinas que van a tener los <strong>brokers</strong> levantados.</p>
</li>
<li>
<p>Para ello editamos el fichero <strong>/etc/hosts/</strong>, y al final del mismo, a√±adimos las siguientes l√≠neas:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>127.0.0.1   host.broker1
127.0.0.2   host.broker2
127.0.0.3   host.broker3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Guardamos y salimos, y confirmamos que el comando <strong>ping</strong> nos responde a las 3 direcciones.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ ping host.broker1
PING host.broker1 (127.0.0.1) 56(84) bytes of data.
64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.026 ms
...
[kafka@kafka-server ~]$ ping host.broker2
PING host.broker2 (127.0.0.2) 56(84) bytes of data.
64 bytes from host.broker2 (127.0.0.2): icmp_seq=1 ttl=64 time=0.036 ms
...
[kafka@kafka-server ~]$ ping host.broker3
PING host.broker3 (127.0.0.3) 56(84) bytes of data.
64 bytes from host.broker3 (127.0.0.3): icmp_seq=1 ttl=64 time=0.039 ms
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora vamos a hacer 3 copias del fichero <strong>server.properties</strong>, para configurar cada <strong>broker</strong> de manera independiente</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Tambi√©n creamos rutas para guardar los logs de los brokers 1 y 2 (el broker 0 seguir√° usando la ruta por defecto)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ mkdir /tmp/kafka-logs{2,3}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Editamos el fichero <strong>$KAFKA_HOME/config/server.propertiesX</strong> y modificamos, descomentamos para que se aplique la directiva y/o comprobamos las siguientes l√≠neas:</p>
<div class="ulist">
<ul>
<li>
<p>broker.id &#8594; Deber√° poseer cada fichero su propio id</p>
</li>
<li>
<p>listeners &#8594; Esta propiedad indica donde conectar</p>
</li>
<li>
<p>log.dirs &#8594; Path de los logs del broker</p>
</li>
<li>
<p>zookeeper.connect &#8594; Ruta de zookeeper</p>
</li>
</ul>
</div>
</li>
<li>
<p>A continuaci√≥n tenemos las l√≠neas para cada uno de los ficheros properties</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">server.properties1</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=0
listeners=PLAINTEXT://host.broker1:9092
log.dirs=/tmp/kafka-logs
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">server.properties2</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=1
listeners=PLAINTEXT://host.broker2:9092
log.dirs=/tmp/kafka-logs2
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">server.properties3</div>
<div class="content">
<pre class="CodeRay highlight"><code>broker.id=2
listeners=PLAINTEXT://host.broker3:9092
log.dirs=/tmp/kafka-logs3
zookeeper.connect=localhost:2181</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Recordad, si existe alg√∫n <strong>Broker</strong>, matarlo antes con <strong>kill -s TERM $PID</strong> o <strong>kafka-server-stop.sh</strong>:</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>OJO, todos van a escribir las trazas en el mismo fichero ($KAFKA_HOME/logs/server.log).</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Vamos a ver qu√© ha sucedido en <strong>Zookeeper</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0, 1, 2]
[zk: localhost:2181(CONNECTED) 1] get /brokers/ids/0
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker1:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker1&quot;,&quot;timestamp&quot;:&quot;1548179115649&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}
[...]
[zk: localhost:2181(CONNECTED) 2] get /brokers/ids/1
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker2:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker2&quot;,&quot;timestamp&quot;:&quot;1548179118553&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}
[...]
[zk: localhost:2181(CONNECTED) 3] get /brokers/ids/2
{&quot;listener_security_protocol_map&quot;:{&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;},&quot;endpoints&quot;:[&quot;PLAINTEXT://host.broker3:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;host.broker3&quot;,&quot;timestamp&quot;:&quot;1548179212478&quot;,&quot;port&quot;:9092,&quot;version&quot;:4}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos que se han dado de alta correctamente.</p>
</li>
<li>
<p>Vamos a crear dos nuevos <strong>Topic</strong>, uno con factor de replicaci√≥n 1 y otro con 3, el m√°ximo definido por el n√∫mero de <strong>brokers</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic-cluster-no-ha --partitions 3 --replication-factor 1
Created topic topic-cluster-no-ha.
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic-cluster-si-ha --partitions 3 --replication-factor 3
Created topic topic-cluster-si-ha.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a confirmar que los <strong>Topics</strong> se han creado correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --list
__consumer_offsets
base-topic
base-topic2
topic-cluster-no-ha
topic-cluster-si-ha</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos la informaci√≥n de los dos <strong>Topics</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-no-ha
Topic:topic-cluster-no-ha        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,2,0
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 2,0,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Este es el aspecto esperado.</p>
</li>
<li>
<p>Nos informa de d√≥nde est√°n las r√©plicas y si est√°n sincronizadas, y vemos que las particiones <strong>Leader</strong> se han balanceado entre los <strong>Brokers</strong>.</p>
</li>
<li>
<p>Ahora tenemos varios <strong>Brokers</strong>, as√≠ que podemos ver el aspecto que tiene mi antiguo <strong>Topic</strong>, que ten√≠a 5 particiones y todas estaban en el mismo <strong>Broker</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero ¬øqu√© ha pasado? ¬øPor qu√© no est√°n las particiones distribuidas entre los distintos <strong>Brokers</strong> ?</p>
</li>
<li>
<p>Por defecto, <strong>no se realiza balanceo de Particiones</strong>, se puede configurar para que se haga cada cierto tiempo o realizarse de manera manual, pero por defecto no est√° as√≠.</p>
</li>
<li>
<p>Algo interesante es ver qu√© pasar√≠a si uno de mis <strong>Brokers</strong> se cae.</p>
</li>
<li>
<p>Vamos a matar alguno de ellos (Obtener con un <strong>ps -edaf|grep -i kafka</strong> o con jps)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ jps
5120 QuorumPeerMain
9206 Kafka
9558 Kafka
13126 Jps
10344 Kafka

[kafka@kafka-server ~]$ kill 10344</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>¬øQu√© ha sucedido ahora con mi <strong>Topic</strong>?</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,0
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como pod√©is ver, el Broker 2 ya no est√° en sincron√≠a (no aparece en la lista de <strong>Isr</strong>).</p>
</li>
<li>
<p>Adem√°s, como est√° ca√≠do, la partici√≥n que ten√≠a asignada se ha reasignado a un nuevo <strong>Broker</strong> (Ahora el <strong>Broker 0</strong> tiene las r√©plicas l√≠deres de la partici√≥n 1 y 2).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Si vuelvo a levantar mi <strong>Broker</strong>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3</code></pre>
</div>
</div>
<div class="paragraph">
<p>Vemos que la situaci√≥n del <strong>Topic</strong> se ha "corregido", ya est√° en sincron√≠a.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic-cluster-si-ha
Topic:topic-cluster-si-ha        PartitionCount:3        ReplicationFactor:3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 1,0,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Sin embargo, no se le ha "devuelto" la r√©plica l√≠der. Tenemos 1 Broker con 1 partici√≥n, 1 Broker con 2 particiones, y 1 Broker con 0. Como ya dijimos anteriormente, las particiones no se balancean autom√°ticamente.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Paramos los brokers</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-stop.sh</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuraci√≥n_del_topic">7.4. Configuraci√≥n del Topic</h3>
<div class="ulist">
<ul>
<li>
<p>Ya hemos visto anteriormente c√≥mo crear un <strong>Topic</strong>, mediante el uso del comando <strong>kafka-topics.sh</strong>, vamos a ver con m√°s detalle c√≥mo funciona el comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic nombre-topic --partitions 4 --replication-factor 2 --config propiedad=valor</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Argumentos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--bootstrap-server host:puerto</strong> &#8594; Es necesario indicar d√≥nde est√° el broker de kafka</p>
</li>
<li>
<p><strong>--create</strong> &#8594; Indicamos que vamos a crear un <strong>Topic</strong></p>
</li>
<li>
<p><strong>--topic nombre</strong> &#8594; Damos nombre al <strong>Topic</strong> (cuidado, los guiones bajos y pueden colisionar)</p>
</li>
<li>
<p><strong>--partitions n</strong> &#8594; Indicamos el n√∫mero de particiones que queremos crear para dicho <strong>Topic</strong></p>
</li>
<li>
<p><strong>--replication-factor n</strong> &#8594; Indicamos el n√∫mero de r√©plicas que queremos</p>
</li>
<li>
<p><strong>--config propiedad=valor</strong> &#8594; permite cambiar los valores de otras propiedades</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los <strong>Topics</strong> se pueden eliminar (aunque para ello, debemos tener activada en el fichero de configuraci√≥n <strong>server.properties</strong> la propiedad <strong>delete.topic.enable=true</strong>, si no, lo ignora).</p>
</li>
<li>
<p>Para borrar un <strong>Topic</strong>, usaremos la opci√≥n <strong>--delete</strong> del comando <strong>kafka-topics.sh</strong>.</p>
</li>
<li>
<p>El siguiente ejemplo muestra c√≥mo se borrar√≠a un <strong>Topic</strong> de nombre <strong>topic-a-borrar</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic topic-a-borrar</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez hemos creado el <strong>Topic</strong>, podemos cambiar su configuraci√≥n mediante la opci√≥n <strong>--alter</strong>, a la que debemos a√±adir el cambio que queramos hacer (con <strong>--config propiedad=valor</strong>)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --config propiedad=valor</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Cuando no hemos especificado el valor de una propiedad, usa los valores por defecto para la misma. Si queremos quitar la configuraci√≥n que hemos a√±adido y dejar sus valores por defecto, podemos usar <strong>--alter</strong> con la opci√≥n <strong>--delete-config propiedad</strong></p>
</li>
</ul>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p>En versiones anteriores a Kafka 0.9, era <strong>--deleteConfig</strong>)</p>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --delete-config propiedad</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para a√±adir particiones, podemos hacer uso de <strong>--alter</strong> con la opci√≥n <strong>--partitions n</strong>, siendo <strong>n</strong> el n√∫mero de particiones que queremos a√±adir.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic un-topic --partitions 20</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Un punto importante es que <strong>No se pueden disminuir particiones</strong>.</p>
</li>
<li>
<p>Disminuir particiones implicar√≠a la p√©rdida de datos, y por lo tanto no se contempla esto.</p>
</li>
<li>
<p>Tambi√©n tenemos que tener en cuenta que ampliar las particiones hace que los mensajes asignados anteriormente, puedan no estar asignados a la partici√≥n correspondientes.</p>
</li>
<li>
<p>Es recomendable crear particiones de m√°s al crear un <strong>Topic</strong>, para evitar estos problemas.</p>
</li>
<li>
<p>Cambiar las r√©plicas de un <strong>Topic</strong> es m√°s complicado.</p>
</li>
<li>
<p>Hay que usar la utilidad <strong>kafka-reassign-partitions.sh</strong> y exige aportar un documento en el que especificamos para cada partici√≥n, en qu√© brokers queremos depositar las r√©plicas.</p>
</li>
<li>
<p>Por ejemplo, para un <strong>Topic</strong> que tuviera dos particiones y factor de replicaci√≥n 1, podr√≠a aumentar las r√©plicas del <strong>topic</strong> para que estuvieran en los brokers 0, 1 y 2 con el siguiente JSON:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicAlgo</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicAlgo</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para aplicar estos cambios (imagninando que nuestro fichero se llama cambio-replicas.json), har√≠amos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file cambio-replicas.json --execute</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos verificar que esto se ha realizado correctamente a trav√©s de la misma utilidad, con la opci√≥n <strong>--verify</strong> en lugar de <strong>--execute</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file cambio-replicas.json --verify</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el tema anterior hablamos del <strong>Log Compaction</strong>.</p>
</li>
<li>
<p>Esto, se debe configurar a nivel de <strong>topic</strong>, pero para poder hacer uso de ello hay que tener activado en el fichero de configuraci√≥n <strong>server.properties</strong> la opci√≥n <strong>log.cleaner.enable=true</strong>.</p>
</li>
<li>
<p>Podemos crear directamente un <strong>topic</strong> con dicha configuraci√≥n mediante el par√°metro <strong>--create</strong> con la opci√≥n <strong>--config cleanup.policy=compact</strong>, o bien alterar uno existente con el par√°metro <strong>--alter</strong> con la opci√≥n <strong>--config cleanup.policy=compact</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicNuevo --config cleanup.policy=compact --partitions 4 --replication-factor 3
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicExistente --config cleanup.policy=compact</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_configurar_particiones_y_r√©plicas">7.5. Lab: Configurar particiones y r√©plicas</h3>
<div class="ulist">
<ul>
<li>
<p>Para este ejercicio necesitamos tener levantado <strong>Zookeeper</strong>, y un <strong>Broker</strong> de <strong>Kafka</strong>.</p>
</li>
<li>
<p>Antes de levantar el <strong>Broker</strong> de <strong>Kafka</strong> vamos a copiar la plantilla de fichero <strong>server.properties</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cp ${KAFKA_HOME}/config/server.properties1 ${KAFKA_HOME}/config/server.properties.topics</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Activamos las opciones de cleaner y delete topic en el fichero server.properties.topics:</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En las √∫ltimas versiones, el log cleaner est√° activado por defecto.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>log.cleaner.enable=true
delete.topic.enable=true</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, levantamos el <strong>Broker</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties.topics</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un <strong>Topic</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicEjemploConf1 --partitions 1 --replication-factor 1
Created topic &quot;topicEjemploConf1&quot;.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos su configuraci√≥n y vemos que se ha creado correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicEjemploConf1
Topic:topicEjemploConf1        PartitionCount:1        ReplicationFactor:1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Incrementamos el n√∫mero de particiones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicEjemploConf1 --partitions 3
WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected
Adding partitions succeeded!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Confirmamos que se han creado correctamente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicEjemploConf1
Topic:topicEjemploConf1        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos ahora a borrar un <strong>Topic</strong>, concretamente el que creamos al principio del curso.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Hemos tenido que a√±adir en el <strong>server.properties</strong> la opci√≥n <strong>delete.topic.enable=true</strong></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic base-topic
Topic base-topic is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como vemos, el borrado no es inmediato, se marca para borrar. Cuando haga un limpiado, borrar√° el <strong>Topic</strong>.</p>
</li>
<li>
<p>El pr√≥ximo ejercicio consta en crear un nuevo topic con la misma configuraci√≥n que topicEjemploConf1 y levantar los brokers 1 y 2 para ampliar las r√©plicas del topic recien creado a 2.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Levantamos los nodos 1 y 2</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topicRecienCreado --partitions 3 --replication-factor 1
Created topic &quot;topicRecienCreado&quot;.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Creamos un fichero <strong>Json</strong> de nombre cambio.json con el siguiente contenido</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
  <span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>,
  <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
    {
      <span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicRecienCreado</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>]
    },{
      <span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicRecienCreado</span><span class="delimiter">&quot;</span></span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>,
      <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">1</span>,<span class="integer">2</span>]
    }]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Aplicamos el cambio (como el nombre del topic va en el json, no se tiene que especificar en el comando):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambio.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicRecienCreado&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicRecienCreado&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicRecienCreado-0,topicRecienCreado-1</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En la mayor√≠a de scripts de administraci√≥n se ha deprecado el uso de la directiva --zookeeper para desacoplar de los metadatos las operaciones, siendo sustituido por el --bootstrap-server apuntando a un broker.</p>
</li>
<li>
<p>Todav√≠a es posible usar la directiva --zookeeper, pero dar√° un aviso de deprecaci√≥n.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Verificamos que est√° todo bien:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topicRecienCreado
Topic:topicRecienCreado        PartitionCount:3        ReplicationFactor:1        Configs:
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 1        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Aqu√≠ ha terminado el laboratorio. A continuaci√≥n se muestran posibilidades de operaciones que podemos realizar.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Las opciones que se pueden configurar est√°n en la documentaci√≥n, aunque tambi√©n pueden obtenerse si llamamos a <strong>kafka-topic.sh</strong> sin par√°metros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh
Create, delete, describe, or change a topic.
Option                                   Description
------                                   -----------
--alter                                  Alter the number of partitions,
                                           replica assignment, and/or
                                           configuration for the topic.
--at-min-isr-partitions                  if set when describing topics, only
                                           show partitions whose isr count is
                                           equal to the configured minimum. Not
                                           supported with the --zookeeper
                                           option.
--bootstrap-server &lt;String: server to    REQUIRED: The Kafka server to connect
  connect to&gt;                              to. In case of providing this, a
                                           direct Zookeeper connection won't be
                                           required.
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos configurar un <strong>Topic</strong> para indicar que el tama√±o m√°ximo de los mensajes que puede albergar es de <strong>128 KB</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicLimitado --config max.message.bytes=128000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si quisi√©ramos eliminar esta configuraaci√≥n que acabamos de aplicar, podemos hacerlo con <strong>--delete-config</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic topicLimitado --delete-config max.message.bytes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Algunas configuraciones interesantes que no hemos revisado pero son bastante comunes son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>cleanup.policy</strong> &#8594; Puede ser <strong>delete</strong> o <strong>compact</strong></p>
</li>
<li>
<p><strong>max.message.bytes</strong> &#8594; La vimos en la transparencia anterior, es el tama√±o m√°ximo de los mensajes de dicho topic</p>
</li>
<li>
<p><strong>retention.bytes</strong> &#8594; Tama√±o m√°ximo que un log puede crecer antes de que se aplique la pol√≠tica de borrado</p>
</li>
<li>
<p><strong>min.insync.replicas</strong> &#8594; El n√∫mero de r√©plicas que deben dar su <strong>ACK</strong> antes de devolver el ok al productor</p>
</li>
<li>
<p><strong>flush.messages</strong> &#8594; Cada cu√°ntos mensajes forzamos un fsync para escribir en disco a un log. Si ponemos 5, cada 5 mensajes forzar√° un fsync (se recomienda dejar esto al sistema operativo)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuraci√≥n_de_producers">7.6. Configuraci√≥n de Producers</h3>
<div class="ulist">
<ul>
<li>
<p>Las configuraciones que vamos a ver para los <strong>Productores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>bootstrap.servers</strong> &#8594; Lista de Brokers</p>
</li>
<li>
<p><strong>key.serializer</strong> &#8594; Clase para serializar la clave</p>
</li>
<li>
<p><strong>value.serializer</strong> &#8594; Clase para serializar el valor</p>
</li>
<li>
<p><strong>retries</strong> &#8594; Reintentos de env√≠o</p>
</li>
<li>
<p><strong>ack</strong> &#8594; N√∫mero de respuestas ack que esperamos</p>
</li>
<li>
<p><strong>compression.type</strong> &#8594; Tipo de compresi√≥n</p>
</li>
<li>
<p><strong>batch.size</strong> &#8594; Mensajes que se acumulan antes del env√≠o</p>
</li>
<li>
<p><strong>linger.ms</strong> &#8594; Tiempo m√°ximo de espera para env√≠o</p>
</li>
<li>
<p><strong>client.id</strong> &#8594; Identificador del cliente</p>
</li>
<li>
<p><strong>partitioner.class</strong> &#8594; Clase para el particionado</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>bootstrap.servers</strong>: La lista de <strong>Brokers</strong>, separados por coma, indicando los puertos en los que est√°n escuchando. Nuestro <strong>productor</strong> se pondr√° en contacto con un <strong>broker</strong> de esta lista para crear el mapa de particionados.</p>
</li>
<li>
<p><strong>key.serializer</strong>: La clase que se debe utilizar por este <strong>productor</strong> para serializar la clave del mensaje. En nuestros ejemplos serializ√°bamos los mensajes directamente como <strong>Strings</strong>. <strong>Kafka</strong> posee varios serializadores ya inclu√≠dos:</p>
<div class="ulist">
<ul>
<li>
<p>String &#8594; org.apache.kafka.common.serialization.StringSerializer</p>
</li>
<li>
<p>Long &#8594; org.apache.kafka.common.serialization.LongSerializer</p>
</li>
<li>
<p>Integer &#8594; org.apache.kafka.common.serialization.IntegerSerializer</p>
</li>
<li>
<p>Double &#8594; org.apache.kafka.common.serialization.DoubleSerializer</p>
</li>
<li>
<p>Bytes &#8594; org.apache.kafka.common.serialization.BytesSerializer</p>
</li>
<li>
<p>ByteArray &#8594; org.apache.kafka.common.serialization.ByteArraySerializer</p>
</li>
<li>
<p>ByteBuffer &#8594; org.apache.kafka.common.serialization.ByteBufferSerializer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Podemos crear nuestro propio serializador, implementando el interfaz <strong>Serializer&lt;T&gt;</strong> (org.apache.kafka.common.serialization.Serializer), si queremos usar nuestros propios tipos en los mensajes.</p>
</li>
<li>
<p><strong>value.serializer</strong>: La clase que se usa para serializar el valor de los mensajes. Al igual que en el caso anterior, podemos hacer uso de una de las clases predefinidas o implementar nuestra propia serializaci√≥n</p>
</li>
<li>
<p><strong>retries</strong>: N√∫mero de intentos que se van a realizar de enviar un mensaje. Cuidado, podemos obtener un fallo y eso no quiere decir que nuestro mensaje no se haya enviado (sencillamente que no se nos ha confirmado), con lo que se podr√≠a dar la situaci√≥n de que envi√°ramos el mismo mensaje (podr√≠amos duplicar mensajes)</p>
</li>
<li>
<p><strong>ack</strong>: Podemos configurar nuestros <strong>productores</strong> para esperar un n√∫mero concreto de respuestas antes de dar por buena la escritura. Algunos valores son:</p>
<div class="ulist">
<ul>
<li>
<p>0 &#8594; "fire and forget", no esperamos confirmaci√≥n. Es el que mayor rendimiento ofrece, pero el m√°s susceptible a errores.</p>
</li>
<li>
<p>1 &#8594; S√≥lo esperamos la respuesta de la partici√≥n l√≠der</p>
</li>
<li>
<p>all &#8594; Esperamos la respuesta de todas las r√©plicas</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>compression.type</strong> &#8594; Podemos realizar compresi√≥n a la hora de enviar nuestros mensajes (aunque por defecto no se realiza). Por cierto, los topics tambi√©n se pueden configurar para que guarden comprimidos los datos</p>
<div class="ulist">
<ul>
<li>
<p>none &#8594; No se realiza compresi√≥n</p>
</li>
<li>
<p>gzip &#8594; Compresi√≥n gzip</p>
</li>
<li>
<p>snappy &#8594; Compresi√≥n snappy</p>
</li>
<li>
<p>lz4 &#8594; Compresi√≥n lz4</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>batch.size</strong>: N√∫mero de mensajes que van a agruparse antes de realizar el env√≠o. Un valor de 1 env√≠a todos los mensajes autom√°ticamente seg√∫n se generen.</p>
</li>
<li>
<p><strong>linger.ms</strong>: Tiempo m√°ximo de espera antes del env√≠o. Si este tiempo se cumple, los mensajes se env√≠en aunque no hayan alcanzado el n√∫mero definido por <strong>batch.size</strong></p>
</li>
<li>
<p><strong>client.id</strong>: Es el identificador de cliente. Aunque existan varios <strong>productores</strong>, si todos comparten el mismo <strong>client.id</strong>, <strong>Kafka</strong> los considera el mismo cliente. Es de especial utilidad para definir cuotas.</p>
</li>
<li>
<p>En el siguiente ejemplo vemos c√≥mo se define una cuota de tasa de producci√≥n para el cliente "clienteAlgo" de 1024 bytes por segundo (si supera esta tasa, <strong>kafka</strong> relentizar√° el cliente para no superarla):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'producer_byte_rate=1024' --entity-name clienteAlgo --entity-type clients</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>partitioner.class</strong>: Por √∫ltimo, indicar que a la hora de enviar mensajes, estos van a acabar en una partici√≥n. Tenemos dos opciones:</p>
<div class="ulist">
<ul>
<li>
<p>Indicar expl√≠citamente para cada mensaje en qu√© partici√≥n queremos que acabe.</p>
</li>
<li>
<p>Usar un sistema de particionado.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> posee un particionador por defecto (basado en la clave hash obtenida mediante murmur3), pero podemos implementar nuestro propio particionador implementando el interfaz <strong>Partitioner</strong> (org.apache.kafka.clients.producer.Partitioner), y por supuesto especificando su uso en <strong>partitioner.class</strong>.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_configuraci√≥n_de_consumers">7.7. Configuraci√≥n de Consumers</h3>
<div class="ulist">
<ul>
<li>
<p>Las configuraciones que vamos a ver para los <strong>Consumidores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>bootstrap.servers</strong> &#8594; Lista de Brokers (an√°logo a la del productor)</p>
</li>
<li>
<p><strong>key.deserializer</strong> &#8594; Clase para deserializar la clave (an√°logo a la del productor)</p>
</li>
<li>
<p><strong>value.deserializer</strong> &#8594; Clase para deserializar el valor (an√°logo a la del productor)</p>
</li>
<li>
<p><strong>group.id</strong> &#8594; Identificador del grupo de consumidores</p>
</li>
<li>
<p><strong>enable.auto.commit</strong> &#8594; Control autom√°tico del offset</p>
</li>
<li>
<p><strong>auto.commit.interval.ms</strong> &#8594; Cada cuantos milisegundos se actualiza el control del offset</p>
</li>
<li>
<p><strong>auto.offset.reset</strong> &#8594; Para indicar d√≥nde empieza un cliente nuevo</p>
</li>
<li>
<p><strong>client.id</strong> &#8594; Identificador del cliente</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>group.id</strong>: Serv√≠a para identificar un grupo de consumidores. Las instancias del consumidor que posean un mismo <strong>group.id</strong>, se reparten las particiones para procesar los mensajes de forma escalable. Los consumidores con distintos <strong>group.id</strong>, leer√°n los mismos mensajes.</p>
</li>
<li>
<p><strong>enable.auto.commit</strong>: Los clientes llevan un control de los mensajes le√≠dos, para ello sencillamente tienen que recordar el √∫ltimo <strong>offset</strong> procesado para continuar (en caso de ca√≠da o parada, cuando vuelven a ejecutarse) donde lo hab√≠an dejado. Este control puede ser manual (hacemos desde la aplicaci√≥n el control y guardamos el <strong>offset</strong> en momentos concretos), pero normalmente se hace de forma autom√°tica. Activando esta opci√≥n, hacemos que cada cierto tiempo, se guarde informaci√≥n del √∫ltimo <strong>offset</strong> le√≠do.</p>
</li>
<li>
<p><strong>auto.commit.interval.ms</strong>: Cada cu√°nto tiempo se actualiza la informaci√≥n de los offsets</p>
</li>
<li>
<p><strong>auto.offset.reset</strong>: Cuando un cliente nuevo empieza a leer mensajes por primera vez, no hay informaci√≥n del √∫ltimo <strong>offset</strong> procesado. Tenemos dos opciones, leer desde el principio de los tiempos, o leer s√≥lo los nuevos mensajes</p>
<div class="ulist">
<ul>
<li>
<p>smallest &#8594; Leemos desde el primer mensaje (como cuando us√°bamos la opci√≥n "--from-beginning" en "kafka-console-consumer.sh")</p>
</li>
<li>
<p>largest &#8594; S√≥lo leemos los mensajes nuevos (desde que mi cliente se levant√≥).</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>client.id</strong>: Es el identificador de cliente. Aunque existan varios <strong>consumidores</strong>, si todos comparten el mismo <strong>client.id</strong>, <strong>Kafka</strong> los considera el mismo cliente. Es de especial utilidad para definir cuotas.</p>
</li>
<li>
<p>En el siguiente ejemplo vemos c√≥mo se define una cuota de tasa de consumo para el cliente "clienteAlgo" de 1024 bytes por segundo (si supera esta tasa, <strong>kafka</strong> relentizar√° el cliente para no superarla):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'consumer_byte_rate=1024' --entity-name clienteAlgo --entity-type clients</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como se puede ver, es an√°logo al ejemplo en el que pon√≠amos una cuota al productor, pero en este caso al cliente le a√±adimos la opci√≥n "consumer_byte_rate"</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_operaciones_con_kafka">8. Operaciones con Kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_utilidades_y_herramientas">8.1. Utilidades y herramientas</h3>
<div class="ulist">
<ul>
<li>
<p>En este apartado vamos a ver 4 herramientas que vienen proporcionadas por <strong>Kafka</strong>, que son bastante √∫tiles en distintos escenarios:</p>
<div class="ulist">
<ul>
<li>
<p><strong>kafka-preferred-replica-election.sh</strong> &#8594; Para balancear las particiones l√≠deres. Deprecado.</p>
</li>
<li>
<p><strong>kafka-leader-election.sh</strong> &#8594; Sustituye al anterior.</p>
</li>
<li>
<p><strong>kafka-mirror-maker.sh</strong> &#8594; Para copiar datos de un cl√∫ster a otro</p>
</li>
<li>
<p><strong>kafka-replay-log-producer.sh</strong> &#8594; Para reproducir los mensajes de un Topic en otro</p>
</li>
<li>
<p><strong>kafka-replica-verification.sh</strong> &#8594; Para verificar la validez de las r√©plicas</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_kafka_preferred_replica_election_sh_deprecada">8.1.1. kafka-preferred-replica-election.sh (deprecada)</h4>
<div class="ulist">
<ul>
<li>
<p>Como ya vimos anteriormente, <strong>Kafka</strong> s√≥lo balancea las particiones l√≠deres en el momento de la creacion.</p>
</li>
<li>
<p>Este balanceo, puede dejar de ser el adecuado al a√±adir nuevos brokers o al retirar o apagarlos.</p>
</li>
<li>
<p>Para solucionar esto, tenemos la utilidad <strong>kafka-preferred-replica-election.sh</strong>, que balancear√° las particiones l√≠deres entre los distintos <strong>brokers</strong>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-preferred-replica-election.sh --zookeeper localhost:2181</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay que tener una cosa en cuenta, balancea las particiones l√≠deres entre los distintos <strong>brokers</strong> siguiendo una definici√≥n de "r√©plica favorita" propia de <strong>kafka</strong>.</p>
</li>
<li>
<p>Tambi√©n tenemos que considerar que, si no hay r√©plicas en otros <strong>brokers</strong>, <strong>NO</strong> se va a usar otro <strong>broker</strong> como partici√≥n <strong>l√≠der</strong>, ya que no tiene r√©plica de dicha partici√≥n.</p>
</li>
<li>
<p>Si queremos que este procedimiento se haga autom√°ticamente (no bajo demanda), debemos agregar la siguiente l√≠nea en el fichero de configuraci√≥n</p>
<div class="ulist">
<ul>
<li>
<p><strong>server.properties</strong> la opci√≥n <strong>auto.leader.rebalance.enable</strong>:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>auto.leader.rebalance.enable=true</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Si lo cambiamos a rebalanceo activo, tendr√≠amos failback, algo no deseable con picos altos de carga.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_leader_election_sh">8.1.2. kafka-leader-election.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Es la herramienta que sustituye a kafka-preferred-replica-election.</p>
</li>
<li>
<p>Posee distintas opciones en las que destacan:</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topic</strong>: Permite definir que topic va a gestionar para la elecci√≥n de r√©plicas l√≠deres.</p>
</li>
<li>
<p><strong>--partition</strong>: Indica que partici√≥n va a modificar</p>
</li>
<li>
<p><strong>--all-topic-partitions</strong>: Para elegir todas las particiones basado en el tipo de elecci√≥n.</p>
</li>
<li>
<p><strong>--election-type</strong>: Indica el tipo de elecci√≥n que se va a realizar:</p>
<div class="ulist">
<ul>
<li>
<p>preferred: La elecci√≥n solo se realiza si el preferido no es el lider</p>
</li>
<li>
<p>unclean: solo si no hay lider en la partici√≥n del topic</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>--path-to-json-file</strong>: Indica un fichero json con la lista de particiones y topics a gestionar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de fichero JSON para modificar del topic 1 la particion 1 y del topic2 la particion 3</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:
    [
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">topic1</span><span class="delimiter">&quot;</span></span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>: <span class="integer">1</span>},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">topic2</span><span class="delimiter">&quot;</span></span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>: <span class="integer">3</span>}
    ]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_mirror_maker_sh">8.1.3. kafka-mirror-maker.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Utilidad que permite copiar datos desde otro cl√∫ster <strong>Kafka</strong>.</p>
</li>
<li>
<p>Puede ser de inter√©s si necesit√°is realizar un backup, o tener una copia de producci√≥n para hacer pruebas.</p>
</li>
<li>
<p>Se invoca con los par√°metros:</p>
<div class="ulist">
<ul>
<li>
<p><strong>consumer.config</strong> &#8594; Se le pasa un fichero con la configuraci√≥n del cl√∫ster destino</p>
</li>
<li>
<p><strong>producer.config</strong> &#8594; Se le pasa un fichero con la configuraci√≥n del cl√∫ster origen</p>
</li>
<li>
<p><strong>whitelist</strong> &#8594; los topics que queremos coger (admite expresiones regulares)</p>
</li>
<li>
<p><strong>num.streams</strong> &#8594; N√∫mero de hilos para los consumidores</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-mirror-maker.sh --consumer.config consumer.properties --producer.config producer.properties --whitelist testTopic</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_replay_log_producer_sh">8.1.4. kafka-replay-log-producer.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Otra herramienta √∫til para realizar pruebas.</p>
</li>
<li>
<p>Permite copiar los mensajes de un <strong>topic</strong> a otro, permiti√©ndonos por ejemplo realizar pruebas de nuestras aplicaciones contra datos reales extra√≠dos de otro <strong>topic</strong>, y reproducir el comportamiento que hubo con los datos de ayer, por ejemplo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-replay-log-producer.sh --broker-list localhost:9092 --inputtopic topic-input --outputtopic topic-output --threads 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como se puede ver, en <strong>inputtopic</strong> se especifica el origen, en <strong>outputtopic</strong> el destino, y podemos configurar el n√∫mero de hilos que se van a dedicar en dicha tarea con <strong>threads</strong></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_replica_verification_sh">8.1.5. kafka-replica-verification.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Nos va a permitir verificar las r√©plicas existentes de un conjunto de topics, para confirmar que todas tienen los mismos datos.</p>
</li>
<li>
<p>En su versi√≥n m√°s simple, lo hace para todos los <strong>topics</strong>, pero el par√°metro <strong>--topic-white-list</strong> permite especificar un conjunto de <strong>topics</strong> mediante una expresi√≥n regular.</p>
</li>
<li>
<p>Otra opci√≥n interesante es <strong>--time</strong>, que permite especificar a partir de qu√© timestamp realizar la verificaci√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-replica-verification.sh --broker-list localhost:9092 --topic-white-list &quot;^to.*a$&quot;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el ejemplo vamos a verificar todos los topic cuyo nombre empiece por 'to', y acabe por la letra 'a'.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_broker_api_versions_sh">8.1.6. kafka-broker-api-versions.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Permite mostrar de un solo vistazo la informaci√≥n de todos los brokers del cluster.</p>
</li>
<li>
<p>La informaci√≥n muestra las instrucciones del api, las versiones existentes y la m√°s moderna soportada por cada broker:</p>
<div class="ulist">
<ul>
<li>
<p>&lt;api(posicion)&gt;: &lt;rango de versiones&gt; [usable: &lt;versi√≥n m√°xima soportada&gt;]</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-node1.local:9092 (id: 1 rack: null) -&gt; (
        Produce(0): 0 to 8 [usable: 8],
        Fetch(1): 0 to 11 [usable: 11],
        ListOffsets(2): 0 to 5 [usable: 5],
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no es soportada, se indica como UNSUPPORTED</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-node1.local:9092 (id: 1 rack: null) -&gt; (
...
        DeleteTopics(20): UNSUPPORTED,
...</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_kafka_consumer_groups_sh">8.1.7. kafka-consumer-groups.sh</h4>
<div class="ulist">
<ul>
<li>
<p>Con esta herramienta podemos listar todos los grupos de consumidores existentes.</p>
</li>
<li>
<p>Permite listarlos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[vagrant<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> kafka-consumer-groups.sh --bootstrap-server localhost:<span class="integer">9092</span> --list
perf-consumer-<span class="integer">59052</span>
perf-consumer-<span class="integer">72644</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite describir los offsets del grupo actual.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">[vagrant<span class="annotation">@kafka</span>-server ~]<span class="error">$</span> kafka-consumer-groups.sh --bootstrap-server localhost:<span class="integer">9092</span> --describe --group test-consumer-group

Consumer group <span class="string"><span class="delimiter">'</span><span class="content">test-consumer-group</span><span class="delimiter">'</span></span> has no active members.

GROUP               TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
test-consumer-group base-topic2     <span class="integer">0</span>          <span class="integer">5</span>               <span class="integer">5</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">4</span>          <span class="integer">3</span>               <span class="integer">3</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">3</span>          <span class="integer">3</span>               <span class="integer">3</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">2</span>          <span class="integer">1</span>               <span class="integer">1</span>               <span class="integer">0</span>               -               -               -
test-consumer-group base-topic2     <span class="integer">1</span>          <span class="integer">1</span>               <span class="integer">1</span>               <span class="integer">0</span>               -               -               -</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite resetear offsets y manipularlos. Existen distintas opciones:</p>
<div class="ulist">
<ul>
<li>
<p>--to-datetime: Permite resetearlo a la fecha indicada</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-consumer-groups.sh --bootstrap-server kafka-server.local:9092
--group test-group --reset-offsets --all-topics --to-datetime 2017-08-04T00:00:00.000</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>--by-duration: Tiempo de regresi√≥n. Formato P&lt;dias&gt;DT&lt;horas&gt;H&lt;minutos&gt;M&lt;segundos&gt;S.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">kafka-consumer-groups.sh --bootstrap-server kafka-server.local:9092
--group test-group --reset-offsets --all-topics --by-duration P30DT3H30M0S</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>--to-earliest: Al principio</p>
</li>
<li>
<p>--to-latest: Al √∫ltimo offset disponible.</p>
</li>
<li>
<p>--shift-by: avanza (positivo) o retrocede (negativo) n veces</p>
</li>
<li>
<p>to-current: A la posici√≥n actual.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_balanceando_las_particiones">8.2. Lab: Balanceando las particiones</h3>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, vamos a volver a levantar los 3 brokers que hab√≠amos dado de alta en ejercicioes anteriores, y probar a balancear la carga de los topics que hab√≠amos creado.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Debe estar levantado <strong>zookeeper</strong></p>
</li>
<li>
<p>En caso de usar la instalaci√≥n nativa:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[kafka@kafka-server ~]$ zkServer.sh status
/bin/java
ZooKeeper JMX enabled by default
Using config: /opt/apache-zookeeper/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: standalone</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Levantamos los 3 brokers (tal como se hizo en el tema de configuraci√≥n, apartado 2)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a ver cu√°l es el contenido de los <strong>Topics</strong> que ten√≠amos con varias particiones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe
Topic: topic-cluster-no-ha        PartitionCount: 3        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
Topic: topicRecienCreado        PartitionCount: 3        ReplicationFactor: 2        Configs: segment.bytes=1073741824
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 2        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 1        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
        Topic: __consumer_offsets        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
...
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 0        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 0        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como podemos ver, casi todas las particiones l√≠der est√°n en el broker 0. Vamos a intentar reparticionar usando la nueva herramienta kafka-leader-election.sh</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 1        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
...
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0
Topic: topic-cluster-no-ha        PartitionCount: 3        ReplicationFactor: 1        Configs:
        Topic: topic-cluster-no-ha        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topic-cluster-no-ha        Partition: 1        Leader: 1        Replicas: 1        Isr: 1
        Topic: topic-cluster-no-ha        Partition: 2        Leader: 2        Replicas: 2        Isr: 2
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs:
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,1,2
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 1        Configs:
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
Topic: topicRecienCreado        PartitionCount: 3        ReplicationFactor: 2        Configs:
        Topic: topicRecienCreado        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: topicRecienCreado        Partition: 1        Leader: 1        Replicas: 1,2        Isr: 2,1
        Topic: topicRecienCreado        Partition: 2        Leader: 2        Replicas: 2        Isr: 2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un fichero json llamado <strong>cambiaTopic.json</strong> para reasignar las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{<span class="key"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">partitions</span><span class="delimiter">&quot;</span></span>:[
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">0</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">1</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]},
        {<span class="key"><span class="delimiter">&quot;</span><span class="content">topic</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemploConf1</span><span class="delimiter">&quot;</span></span>,<span class="key"><span class="delimiter">&quot;</span><span class="content">partition</span><span class="delimiter">&quot;</span></span>:<span class="integer">2</span>, <span class="key"><span class="delimiter">&quot;</span><span class="content">replicas</span><span class="delimiter">&quot;</span></span>:[<span class="integer">0</span>,<span class="integer">1</span>,<span class="integer">2</span>]}
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicamos cambio de configuraci√≥n para el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambiaTopic.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicEjemploConf1-0,topicEjemploConf1-1,topicEjemploConf1-2</code></pre>
</div>
</div>
<div class="paragraph">
<p>Miramos c√≥mo queda el topic, balanceamos, y volvemos a ver el estado del topic:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 1        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 2        Replicas: 0,1,2        Isr: 0,2,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Balanceamos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
Successfully completed leader election (PREFERRED) for partitions topicEjemploConf1-2, topicEjemploConf1-1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y comprobamos como quedan ahora</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero&#8230;&#8203; nos ha cambiado el lider a 0!</p>
</li>
<li>
<p>Bien, <strong>Kafka</strong> tiene el concepto de d√≥nde prefiere el l√≠der.</p>
</li>
<li>
<p>En principio, donde se ubique la primera r√©plica, ser√° donde <strong>kafka</strong> intente situar la primera r√©plica, y esto se hace en la creaci√≥n del <strong>topic</strong>.</p>
</li>
<li>
<p>Es por eso que el <strong>topic-cluster-si-ha</strong> hab√≠a balanceado correctamente, porque sencillamente hab√≠a escogido como r√©plica la primera de la lista, observad:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topic-cluster-si-ha
Topic: topic-cluster-si-ha        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topic-cluster-si-ha        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,1,2
        Topic: topic-cluster-si-ha        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La columna <strong>Leader</strong> y el primer valor de la lista de <strong>Replicas</strong>, coinciden.</p>
</li>
<li>
<p>Si nos fijamos en <strong>__consumer_offsets</strong>, todos est√°n en el broker 0 por el mismo motivo.</p>
</li>
<li>
<p>Vamos a intentar corregir esto, dando una nueva lista de r√©plicas modificando <strong>cambiaTopic.json</strong></p>
</li>
<li>
<p>Si quisi√©ramos cambiarlo en versiones anteriores, habr√≠a que reasignar las particiones con el siguiente comando</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido de cambiaTopic.json</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;partitions&quot;:[
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0, &quot;replicas&quot;:[0,1,2]},
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1, &quot;replicas&quot;:[1,2,0]},
        {&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2, &quot;replicas&quot;:[2,1,0]}
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aplicamos cambio de configuraci√≥n para el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file cambiaTopic.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]},{&quot;topic&quot;:&quot;topicEjemploConf1&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started partition reassignments for topicEjemploConf1-0,topicEjemploConf1-1,topicEjemploConf1-2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y vemos el resultado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-leader-election.sh --bootstrap-server host.broker1:9092 --election-type preferred --all-topic-partitions
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic topicEjemploConf1
Topic: topicEjemploConf1        PartitionCount: 3        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: topicEjemploConf1        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 1        Leader: 1        Replicas: 1,2,0        Isr: 0,2,1
        Topic: topicEjemploConf1        Partition: 2        Leader: 2        Replicas: 2,0,1        Isr: 0,2,1</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_crecimiento_de_un_cl√∫ster">8.3. Crecimiento de un cl√∫ster</h3>
<div class="ulist">
<ul>
<li>
<p>Hemos visto en el punto anterior c√≥mo asigna las particiones l√≠der <strong>kafka</strong>, y hemos podido balancear correctamente las mismas definiendo un fichero con los destinos finales de cada partici√≥n de un <strong>topic</strong>, pero ¬øes as√≠ como vamos a trabajar cada vez que nuestro cl√∫ster quiera escalar a√±adiendo (o incluso) retirando <strong>brokers</strong>?</p>
</li>
<li>
<p>En realidad, <strong>kafka-reassing-partitions.sh</strong> puede facilitarnos la vida m√°s, generando autom√°ticamente un fichero como el que hemos usado en el punto anterior para reasignar las particiones.</p>
</li>
<li>
<p>Si queremos que nos haga este fichero, tan s√≥lo tenemos que indicarle para qu√© <strong>topics</strong> queremos que nos cree un nuevo particionado (entre todos los <strong>brokers</strong> que le indiquemos).</p>
</li>
<li>
<p>De esta forma, cada vez que a√±ada un nuevo <strong>broker</strong>, yo puedo pedir a <strong>kafka</strong> que me genere un nuevo fichero de particionamiento, y posteriormente, aplicarlo.</p>
</li>
<li>
<p>Para ello, hay que llamar a <strong>kafka-reasign-partitions.sh</strong> con un fichero <strong>JSON</strong> que contenga los <strong>topics</strong> que queramos mover, tal como este:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;topics&quot;:[
        {&quot;topic&quot;:&quot;topic1&quot;},
        {&quot;topic&quot;:&quot;topic2&quot;},
        [...]
]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con el fichero <strong>JSON</strong> creado, ya s√≥lo nos queda llamar a <strong>kafka-reasign-partitions</strong> indic√°ndole</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topics-to-move-json-file</strong> &#8594; El fichero origen que contenga los topics a mover</p>
</li>
<li>
<p><strong>--broker-list</strong> &#8594; Los broker destino de dichos topics</p>
</li>
<li>
<p><strong>--generate</strong> &#8594; Para que nos genere el fichero <strong>JSON</strong> con el que hacer luego la reasignaci√≥n (hay que guardarlo)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --topics-to-move-json-file topics_mover.json --broker-list &quot;1,2,3,4&quot; --generate</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto, devolver√° un fichero por salida est√°ndar, que tendremos que capturar.</p>
</li>
<li>
<p>Con ese fichero ya podremos llamar a <strong>kafka-reassign-partitions.sh</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file ficheroGenerado.json --execute</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_crecimiento_del_cluster">8.4. Lab: Crecimiento del cluster</h3>
<div class="ulist">
<ul>
<li>
<p>Para probar esto, vamos a volver a tener la misma configuraci√≥n que en el ejercicio anterior (zookeeper levantado, y los 3 brokers activos).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Tengo un <strong>Topic</strong> que cree al principio llamado <strong>base-topic2</strong>. Est√° por completo en el broker 0, y no tiene r√©plicas.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a pedir que distribuya las particiones de este <strong>Topic</strong>, para ello, creo un fichero <strong>JSON</strong> para pedir un nuevo reparticionado con √©l, de nombre <strong>topicsAMover.json</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1, &quot;topics&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;}]}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Ahora, llamo a <strong>kafka-reassign-partitions.sh</strong> con la opci√≥n <strong>--topics-to-move-json-file</strong>, pidi√©ndolo que lo mueva a los brokers 0 y 1</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0,1&quot; --generate
Current partition replica assignment
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Proposed partition reassignment configuration
{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Copiamos lo que figura debajo de <strong>Proposed partitions reassignment configuration</strong> y lo guardamos con el nombre de <strong>nuevasParticiones.json</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Podemos usar directamente un comando en <strong>UNIX</strong> para generarme el fichero, sabiendo que est√° en la l√≠nea marcada por awk como 5</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0,1&quot; --generate|awk 'NR==5 {print $0}' &gt; nuevasParticiones.json</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora lanzo <strong>kafka-reassign-partitions.sh</strong> con el <strong>JSON</strong> generado:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file nuevasParticiones.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Y verifico el resultado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1        Isr: 1
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1        Isr: 1
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1        Isr: 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>¬øPod√©is volver a dejar el topic como estaba, todo en el broker 0?</p>
</li>
<li>
<p>Soluci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --topics-to-move-json-file topicsAMover.json --broker-list &quot;0&quot; --generate|awk 'NR==5 {print $0}' &gt; nuevasParticiones2.json
[kafka@kafka-server ~]$ kafka-reassign-partitions.sh --bootstrap-server host.broker1:9092 --reassignment-json-file nuevasParticiones2.json --execute
Current partition replica assignment

{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:4,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]},{&quot;topic&quot;:&quot;base-topic2&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:1        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_kafka_tools">8.5. Kafka Tools</h3>
<div class="ulist">
<ul>
<li>
<p><strong>Kafka Tools</strong> es un conjunto de herramientas desarrolladas por <strong>LinkedIn</strong> para facilitar la gesti√≥n de los cl√∫sters <strong>Kafka</strong>. Su finalidad es simplificar gestiones que con los comandos internos de <strong>Kafka</strong> se hacen tediosas o pesados (como cambiar el factor de replicaci√≥n o balancear entre todos los brokers los l√≠deres). Tienen los siguientes m√≥dulos:</p>
<div class="ulist">
<ul>
<li>
<p>clone</p>
</li>
<li>
<p>trim</p>
</li>
<li>
<p>remove</p>
</li>
<li>
<p>elect</p>
</li>
<li>
<p>set-replication-factor</p>
</li>
<li>
<p>reorder</p>
</li>
<li>
<p>balance</p>
</li>
</ul>
</div>
</li>
<li>
<p>Al invocar estas herramientas, hay que proporcionar la ruta a <strong>Zookeeper</strong> (con "-z") y es posible que os pida especificar la ruta a las <strong>kafka tools</strong> (con "--tools-path")</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_clone">8.5.1. Clone</h4>
<div class="ulist">
<ul>
<li>
<p>Clona las particiones de una lista de brokers en un broker destino. Normalmente se usa para probar nuevo hardware, no aporta mucho m√°s.</p>
</li>
<li>
<p>Para invocarlo hay que usar</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a clonar</p>
</li>
<li>
<p><strong>--to_broker</strong> &#8594; broker destino</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_trim">8.5.2. trim</h4>
<div class="ulist">
<ul>
<li>
<p>Borra uno o m√°s brokers del cl√∫ster, reduciendo el factor de replicaci√≥n de las particiones en el proceso.</p>
</li>
<li>
<p>Tambi√©n tiene un uso limitado (orientado al testing), ya que altera las particiones</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a eliminar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_remove">8.5.3. remove</h4>
<div class="ulist">
<ul>
<li>
<p>Elimina un <strong>Broker</strong>, manteniendo el factor de replicaci√≥n.</p>
</li>
<li>
<p>Esta utilidad si es m√°s ventajosa, ya que va a conservar el mismo factor de replicaci√≥n previo a la retirada.</p>
<div class="ulist">
<ul>
<li>
<p><strong>--brokers</strong> &#8594; brokers a eliminar</p>
</li>
<li>
<p><strong>--to_broker</strong> &#8594; broker destino de las r√©plicas que guarda el broker a eliminar (si no se indica nada, lo distribuye entre todos)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e remove --broker 4 --to_brokers 1 2 3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_elect">8.5.4. elect</h4>
<div class="ulist">
<ul>
<li>
<p>ejecuta una reelecci√≥n del cl√∫ster.</p>
</li>
<li>
<p>Es an√°logo a usar <strong>kafka-preferred-replica-election.sh</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e elect</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_set_replication_factor">8.5.5. set-replication-factor</h4>
<div class="ulist">
<ul>
<li>
<p>Nos permite cambiar el factor de replicacion de un <strong>Topic</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><strong>--topic</strong> &#8594; Topic que vamos a alterar</p>
</li>
<li>
<p><strong>--replication-factor</strong> &#8594; Nuevo factor de replicaci√≥n</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic unTopic --replication-factor 3</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reorder">8.5.6. reorder</h4>
<div class="ulist">
<ul>
<li>
<p>La opci√≥n que queremos usar cuando buscamos asegurar que todos los brokers tienen el mismo n√∫mero de particiones l√≠deres.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e reorder</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_balance">8.5.7. balance</h4>
<div class="ulist">
<ul>
<li>
<p>Es el m√≥dulo m√°s complejo de todos, se encarga de balancear las particiones a trav√©s del cl√∫ster.</p>
</li>
<li>
<p>Ofrece distintos modos:</p>
<div class="ulist">
<ul>
<li>
<p>count &#8594; las particiones m√°s peque√±as del cl√∫ster son las movidas</p>
</li>
<li>
<p>size &#8594; las particiones m√°s grandes del cl√∫ster son las movidas</p>
</li>
<li>
<p>even &#8594; Si el n√∫mero de particiones del cl√∫ster es m√∫ltiplo del n√∫mero de brokers, asegura que cada broker tiene el mismo n√∫mero de particiones por topic</p>
</li>
<li>
<p>leader &#8594; Reordena la lista de r√©plicas para obtener un balance ideal de los l√≠deres (an√°logo a usar reorder)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e balance --types size</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_usando_kafka_tools">8.6. Lab: Usando Kafka Tools</h3>
<div class="paragraph">
<p>Antes de empezar, aseg√∫rate de que <strong>Zookeeper</strong> est√° levantado, y que tenemos los 3 brokers de las practicas anteriores en ejecuci√≥n.</p>
</div>
<div class="paragraph">
<p>Vamos a instalar <strong>Kafka tools</strong> (para esta VM hay que instalar tambi√©n el compilador de C++)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo dnf -y install gcc-c++
[kafka@kafka-server ~]$ pip3 install kafka-tools --user</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como dependencia, kafka tools necesita tener declarada la variable JAVA_HOME</p>
</li>
<li>
<p>Para ello lanzamos los siguientes comandos que permiten buscar la versi√≥n de java y crear la variable para el usuario</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo export JAVA_HOME=$(alternatives --list | grep java_sdk | head -n 1 | awk '{print $3}') &gt;&gt; java_path.sh
[kafka@kafka-server ~]$ sudo mv java_path.sh /etc/profile.d/
[kafka@kafka-server ~]$ sudo chmod ugo+x /etc/profile.d/java_path.sh
[kafka@kafka-server ~]$ source /etc/profile.d/java_path.sh</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este apartado, vamos a volver a trabajar con <strong>base-topic2</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 1        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0        Isr: 0
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0        Isr: 0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo primero que vamos a hacer, es cambiar su factor de replicaci√≥n usando las herramientas <strong>kafka tools</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic base-topic2 --replication-factor 3
[INFO] Connecting to zookeeper localhost:2181
[INFO] Getting partition list from Zookeeper
[INFO] Closing connection to zookeeper
[INFO] Partition moves required: 5
[INFO] Number of batches: 1
[INFO] Executing partition reassignment 1/1: {&quot;partitions&quot;: [{&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 2, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 3, &quot;replicas&quot;: [0, 1, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 4, &quot;replicas&quot;: [0, 1, 2]}], &quot;version&quot;: 1}
[INFO] Number of replica elections: 1
[INFO] Executing preferred replica election 1/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Veamos el resultado:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Genial, hemos sido capaces de cambiar el factor de replicaci√≥n sin apenas esfuerzo, pero ¬øNos convence la distribucion de las particiones primarias?</p>
</li>
<li>
<p>Vamos a reordenarlas</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-assigner -z localhost:2181 -e reorder
[INFO] Connecting to zookeeper localhost:2181
[INFO] Getting partition list from Zookeeper
[INFO] Closing connection to zookeeper
[INFO] Partition moves required: 9
[INFO] Number of batches: 1
[INFO] Executing partition reassignment 1/1: {&quot;partitions&quot;: [{&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 2, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 3, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;base-topic2&quot;, &quot;partition&quot;: 4, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;topic-cluster-si-ha&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;topicEjemploConf1&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0, 2]}, {&quot;topic&quot;: &quot;topicEjemploConf1&quot;, &quot;partition&quot;: 1, &quot;replicas&quot;: [2, 1, 0]}, {&quot;topic&quot;: &quot;topicRecienCreado&quot;, &quot;partition&quot;: 0, &quot;replicas&quot;: [1, 0]}], &quot;version&quot;: 1}
[INFO] Number of replica elections: 1
[INFO] Executing preferred replica election 1/1</code></pre>
</div>
</div>
<div class="paragraph">
<p>¬øHabr√° funcionado?</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic:base-topic2        PartitionCount:5        ReplicationFactor:3        Configs:
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si, pero tened en cuenta que hay muchas particiones (correspondientes al topic de los offsets) ya en el broker 0, por lo que se han asignado a los brokers 1 y 2</p>
</li>
<li>
<p>Bueno, veamos qu√© pasa si llamo a balance, con la opci√≥n <strong>leader</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% kafka-assigner -z localhost:2181 -e balance --types leader</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Como no hemos dado de alta con un certificado a nuestro usuario, y <strong>balance</strong> se conecta por ssh, nos pedir√° las claves. Esto puede solucionarse usando <strong>ssh-keygen</strong> y <strong>ssh-copy-id</strong> para permitir la conexi√≥n mediante certificados</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Veamos el aspecto (vamos a ver s√≥lo nuestro topic, pero esto ha distribuido TODOS los topics)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs: segment.bytes=1073741824
        Topic: base-topic2        Partition: 0        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>No ha cambiado. ¬øTal vez deber√≠amos cambiar <strong>__consumer_offsets</strong> para que no sature el broker 0?</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Durante las operaciones de balanceo, puede pedirnos conexi√≥n via SSH a los brokers.</p>
</li>
<li>
<p>Al pedir autorizaci√≥n del fingerprint, decimos yes.</p>
</li>
<li>
<p>Los datos de conexi√≥n para el usuario kafka es password kafka</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e set-replication-factor --topic __consumer_offsets --replication-factor 2
[kafka@kafka-server config]$ kafka-assigner -z localhost:2181 -e balance --types leader
[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic base-topic2
Topic: base-topic2        PartitionCount: 5        ReplicationFactor: 3        Configs:
        Topic: base-topic2        Partition: 0        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 1        Leader: 2        Replicas: 2,1,0        Isr: 0,1,2
        Topic: base-topic2        Partition: 2        Leader: 1        Replicas: 1,0,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 3        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2
        Topic: base-topic2        Partition: 4        Leader: 0        Replicas: 0,1,2        Isr: 0,1,2</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esto ha resuelto nuestros problemas.</p>
</li>
<li>
<p>Si vemos el <strong>--describe</strong> de <strong>__consumer_offsets</strong>, veremos que ha sido distribuido por m√∫ltiples <strong>brokers</strong>, permitiendo as√≠ un balanceo de nuestro cl√∫ster</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server host.broker1:9092 --describe --topic __consumer_offsets
Topic: __consumer_offsets        PartitionCount: 50        ReplicationFactor: 2        Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
        Topic: __consumer_offsets        Partition: 0        Leader: 0        Replicas: 0,1        Isr: 0,1
        Topic: __consumer_offsets        Partition: 1        Leader: 2        Replicas: 2,0        Isr: 0,2
        Topic: __consumer_offsets        Partition: 2        Leader: 1        Replicas: 1,0        Isr: 0,1
...</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_desarrollo_con_kafka">9. Desarrollo con kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Para desarrollar con kafka, hay que tener en cuenta para kafka:</p>
<div class="ulist">
<ul>
<li>
<p>Cual va a ser la implementaci√≥n utilizada de kafka (OpenSource/Confluent)</p>
</li>
<li>
<p>Que versi√≥n vamos a utilizar (2.6.0/6.0.0)</p>
</li>
<li>
<p>Que instalaci√≥n vamos a usar (Entorno centralizado/entorno particular)</p>
</li>
<li>
<p>En caso de uso de un entorno particular, como vamos a instalarlo (Instalaci√≥n com√∫n/Docker)</p>
</li>
<li>
<p>Tenemos memoria suficiente para albergar todo lo que necesitamos en el equipo?</p>
</li>
</ul>
</div>
</li>
<li>
<p>En cuanto al desarrollo hay que tener en cuenta:</p>
<div class="ulist">
<ul>
<li>
<p>Que lenguaje/lenguajes de programaci√≥n vamos a utilizar para comunicarnos con kafka</p>
</li>
<li>
<p>Que IDE vamos a utilizar</p>
</li>
<li>
<p>Que librerias de apoyo vamos a utilizar</p>
</li>
<li>
<p>Que arquitecturas vamos a implementar.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_implementaci√≥n_kafka">9.1. Implementaci√≥n kafka</h3>
<div class="ulist">
<ul>
<li>
<p>En cuanto a la implementaci√≥n de Kafka, en este curso nos centraremos en la versi√≥n OpenSource de Kafka, la versi√≥n 2.6.0</p>
</li>
<li>
<p>Usaremos Docker para crear los siguientes contenedores:</p>
<div class="ulist">
<ul>
<li>
<p>Contenedor de Zookeeper como base de metadatos de los brokers</p>
</li>
<li>
<p>Tres contenedores de Kafka que se usar√°n como brokers</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se usar√° la interfaz host para que se alojen en local y funcione correctamente las comunicaciones entre brokers.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_lenguaje_de_programaci√≥n">9.2. Lenguaje De programaci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>En nuestro caso, usaremos Eclipse o STS seg√∫n lo c√≥modo que est√© cada alumno para usarlos.</p>
</li>
<li>
<p>Como lenguaje de programaci√≥n, usaremos Java</p>
</li>
<li>
<p>Usaremos los frameworks de:</p>
<div class="ulist">
<ul>
<li>
<p>kafka-clients: Para uso de conexiones a kafka</p>
</li>
<li>
<p>kafka-streams: Para el uso de streams en Java</p>
</li>
<li>
<p>io.confluent: como librerias de confluent para uso de ciertos recursos con licencia confluent.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_objetivo">9.3. Objetivo</h3>
<div class="ulist">
<ul>
<li>
<p>El objetivo es poseer un cluster de Kafka suficientemente versatil para poder trabajar con √©l</p>
</li>
<li>
<p>El aspecto final ser√° el siguiente:</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><span class="image"><img src="./images/kafka-entorno-desarrollo-01.png" alt="kafka entorno desarrollo 01" width="600"></span></p>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_lab_instalaci√≥n_del_entorno_de_desarrollo_de_kafka">9.4. Lab: Instalaci√≥n del entorno de desarrollo de Kafka</h3>
<div class="sect3">
<h4 id="_ejecuci√≥n_de_prueba">9.4.1. Ejecuci√≥n de prueba</h4>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En caso de que no est√©n levantados los contenedores, los levantamos como se indica a continuaci√≥n.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para comprobar que todo ha ido correctamente, vamos a iniciar cada uno de los contenedores de forma individual</p>
</li>
<li>
<p>Primero iniciamos el servicio de Zookeeper.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker-compose up -d zookeeper</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esperamos unos segundos e iniciamos ya los contenedores de Kafka</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka1
[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka2
[kafka@kafka-server docker-kafka]$ docker-compose up -d kafka3</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras iniciar los contenedores, deben estar disponibles en el sistema. Lo comprobamos con el siguiente comando.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server docker-kafka]$ docker ps
CONTAINER ID        IMAGE                                   COMMAND                  CREATED             STATUS              PORTS               NAMES
093e9d1c649e        bitnami/kafka:latest                    &quot;/opt/bitnami/script‚Ä¶&quot;   4 seconds ago       Up 3 seconds                               docker-kafka_kafka1_1
551540ef4ce4        bitnami/kafka:latest                    &quot;/opt/bitnami/script‚Ä¶&quot;   3 seconds ago       Up 2 seconds                               docker-kafka_kafka2_1
fbe3387824b3        bitnami/kafka:latest                    &quot;/opt/bitnami/script‚Ä¶&quot;   3 seconds ago       Up 2 seconds                               docker-kafka_kafka3_1
40c2020d1486        bitnami/zookeeper:latest                &quot;/opt/bitnami/script‚Ä¶&quot;   2 minutes ago       Up 2 mintues                               docker-kafka_zookeeper_1</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect3">
<h4 id="_preparaci√≥n_de_proyecto_plantilla">9.4.2. Preparaci√≥n de proyecto plantilla</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un proyecto plantilla el cual utilizaremos como base para los dem√°s proyectos.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Usaremos como workspace /home/kafka/workspace_curso</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Para ello abrimos nuestro IDE favorito y creamos un nuevo proyecto:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-01.png" alt="kafka entornos desarrollo lab 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Elegimos el <strong>Maven Project</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-02.png" alt="kafka entornos desarrollo lab 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Seleccionamos la opci√≥n de crear un proyecto simple</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-03.png" alt="kafka entornos desarrollo lab 03" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Rellenamos los siguientes campos</p>
<div class="ulist">
<ul>
<li>
<p><strong>Group id</strong>: com.curso.kafka</p>
</li>
<li>
<p><strong>Artifact id</strong>: PlantillaKafka</p>
</li>
<li>
<p><strong>Version</strong>: 0.0.1-SNAPSHOT</p>
</li>
<li>
<p><strong>Packaging</strong>: jar</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-04.png" alt="kafka entornos desarrollo lab 04" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pulsamos <strong>finish</strong></p>
</li>
<li>
<p>Ahora editamos el fichero pom.xml agregado las siguientes propiedades que permiten que se compile en Java 11 de forma autom√°tica:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;properties&gt;</span>
    <span class="tag">&lt;maven.compiler.source&gt;</span>11<span class="tag">&lt;/maven.compiler.source&gt;</span>
    <span class="tag">&lt;maven.compiler.target&gt;</span>11<span class="tag">&lt;/maven.compiler.target&gt;</span>
<span class="tag">&lt;/properties&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos las dependencias m√≠nimas para trabajar con kafka. Las Kafka Clients</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="comment">&lt;!-- Librerias Kafka --&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.apache.kafka<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>kafka-clients<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.6.0<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Debajo agregamos la librer√≠a helper de slf4j, ya que no viene ninguna implementaci√≥n en las librer√≠as de kafka, y sino no podr√≠a generar el sistema de log, y fallar√≠a el arranque</p>
</li>
<li>
<p>Y tambi√©n jackson core para tratamiento de xml</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Cuando agreguemos kafka-streams, ya no ser√° necesario, ya que viene incluida como dependencia.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="comment">&lt;!-- Helpers --&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>org.slf4j<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>slf4j-log4j12<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>1.7.5<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span>
<span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>jackson-databind<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>2.11.3<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El resultado final del fichero pom.xml ser√° el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;project</span> <span class="attribute-name">xmlns</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xmlns:xsi</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://www.w3.org/2001/XMLSchema-instance</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xsi:schemaLocation</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd</span><span class="delimiter">&quot;</span></span><span class="tag">&gt;</span>
        <span class="tag">&lt;modelVersion&gt;</span>4.0.0<span class="tag">&lt;/modelVersion&gt;</span>
        <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
        <span class="tag">&lt;artifactId&gt;</span>PlantillaKafka<span class="tag">&lt;/artifactId&gt;</span>
        <span class="tag">&lt;version&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/version&gt;</span>
  <span class="comment">&lt;!-- Java 11 OpenJDK como compilacion de proyecto --&gt;</span>
        <span class="tag">&lt;properties&gt;</span>
                <span class="tag">&lt;maven.compiler.source&gt;</span>11<span class="tag">&lt;/maven.compiler.source&gt;</span>
                <span class="tag">&lt;maven.compiler.target&gt;</span>11<span class="tag">&lt;/maven.compiler.target&gt;</span>
        <span class="tag">&lt;/properties&gt;</span>
        <span class="tag">&lt;dependencies&gt;</span>
                <span class="comment">&lt;!-- Librerias Kafka --&gt;</span>
                <span class="tag">&lt;dependency&gt;</span>
                        <span class="tag">&lt;groupId&gt;</span>org.apache.kafka<span class="tag">&lt;/groupId&gt;</span>
                        <span class="tag">&lt;artifactId&gt;</span>kafka-clients<span class="tag">&lt;/artifactId&gt;</span>
                        <span class="tag">&lt;version&gt;</span>2.6.0<span class="tag">&lt;/version&gt;</span>
                <span class="tag">&lt;/dependency&gt;</span>
                <span class="comment">&lt;!-- Helpers --&gt;</span>
                <span class="tag">&lt;dependency&gt;</span>
                        <span class="tag">&lt;groupId&gt;</span>org.slf4j<span class="tag">&lt;/groupId&gt;</span>
                        <span class="tag">&lt;artifactId&gt;</span>slf4j-log4j12<span class="tag">&lt;/artifactId&gt;</span>
                        <span class="tag">&lt;version&gt;</span>1.7.5<span class="tag">&lt;/version&gt;</span>
                <span class="tag">&lt;/dependency&gt;</span>
        <span class="tag">&lt;/dependencies&gt;</span>
<span class="tag">&lt;/project&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para completar el sistema de log, vamos a agregar tambi√©n el fichero log4j.properties en el directorio src/main/resources</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido de src/main/resources/log4j.properties</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">log4j.rootLogger=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d [%t] %-5p %c - %m%n</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez terminado, debemos de sincronizar el proyecto maven con el proyecto del IDE.</p>
</li>
<li>
<p>Para ello pulsamos bot√≥n derecho en la raiz del proyecto y seleccionamos <strong>Maven</strong> &#8594; <strong>Update Project</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-05.png" alt="kafka entornos desarrollo lab 05" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez que se sincronice y que guarde todas las dependencias, debemos cerciorarnos de que el IDE detecta el proyecto como Java 11</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-entornos-desarrollo-lab-06.png" alt="kafka entornos desarrollo lab 06" width="300">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_java_api">10. Kafka Java API</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_dependencias">10.1. Dependencias</h3>
<div class="ulist">
<ul>
<li>
<p>Necesitamos a√±adir a un nuevo proyecto las dependencias a las librer√≠as <strong>Kafka</strong>.</p>
</li>
<li>
<p>Si usamos <strong>Maven</strong>, con a√±adir dependencias a <strong>kafka-clients</strong> deber√≠a ser suficiente.</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Dependencia m√≠nima a utilizar</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>&lt;dependency&gt;
	&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
	&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
	&lt;version&gt;2.6.0&lt;/version&gt;
&lt;/dependency&gt;</pre>
</div>
</div>
<div class="paragraph">
<p>En nuestro caso, vamos a crear una librear√≠a de usuario con las librer√≠as que hay en <strong>$KAFKA_HOME/lib</strong></p>
</div>
<div class="paragraph">
<p>NOTA: Al crear la librer√≠a inclu√≠mos jackson-databind, esto tendr√≠a que ser a√±adido tambi√©n a las dependencias de <strong>maven</strong></p>
</div>
</div>
<div class="sect2">
<h3 id="_api_para_producer">10.2. API para Producer</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder hacer nuestro propio <strong>productor</strong>, necestaremos conocer las siguientes clases:</p>
<div class="ulist">
<ul>
<li>
<p><strong>KafkaProducer</strong> &#8594; Las instancias de esta clase poseen un m√©todo <strong>send()</strong> que ser√° usado para realizar los env√≠os al <strong>Topic</strong></p>
</li>
<li>
<p><strong>ProducerRecord</strong> &#8594; Las instancias de esta clase son los mensajes que queremos enviar a nuestros <strong>Topics</strong>. Poseen <strong>Clave</strong> y <strong>Valor</strong>, pero tambi√©n debemos especificar el <strong>Topic</strong> destino, y podemos especificar la <strong>partici√≥n</strong> destino (o dejarlo a cargo de un particionador)</p>
</li>
<li>
<p><strong>ProducerConfig</strong> &#8594; Clase que contiene las constantes con las distintas configuraciones aplicables. Es recomendable hacer uso de ellas al crear el fichero <strong>properties</strong>, en lugar de escribirlas manualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a empezar con la clase <strong>KafkaProducer</strong>, que est√° en el paquete <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Esta clase posee un m√©todo <strong>send()</strong>, que nos permite enviar los mensajes a los <strong>Topics</strong> destino de manera as√≠ncrona.</p>
<div class="ulist">
<ul>
<li>
<p><strong>send(ProducerRecord&lt;K,V&gt; record, Callback callback)</strong> &#8594; Ejecutamos el env√≠o del mensaje. Al ser procesado, se ejecutar√° el m√©todo proporcionado en callback. Podemos usar <strong>send(record)</strong> directamente, con lo que no invocar√≠amos un m√©todo al recibir el registro (o tener una excepci√≥n). Devuelve un objeto <strong>Future&lt;RecordMetadata&gt;</strong>.</p>
</li>
<li>
<p><strong>partitionsFor(String topic)</strong> &#8594; Devuelve un <strong>List&lt;PartitionInfo&gt;</strong>, para poder consultar la informaci√≥n de las particiones de un <strong>topic</strong>.</p>
</li>
<li>
<p><strong>close()</strong> &#8594; Cierra el productor.</p>
</li>
<li>
<p><strong>flush()</strong> &#8594; Fuerza el env√≠o de los mensajes pendientes (aunque no lleguemos al linger.ms o batch.size) y bloquea hasta recibir la respuesta de estos.</p>
</li>
<li>
<p><strong>metrics()</strong> &#8594; Devuelve un <strong>Map&lt;MetricName,? extends Metric&gt;</strong>, con las m√©tricas internas mantenidas por el <strong>productor</strong>.</p>
</li>
<li>
<p><strong>initTransactions()</strong> &#8594; Si vamos a usar transacciones debemos invocar este m√©todo antes de cualquier uso de las mismas (y <strong>transactional.id</strong> est√° puesto en la configuraci√≥n)</p>
</li>
<li>
<p><strong>beginTransaction()</strong> &#8594; Para empezar una nueva transacci√≥n</p>
</li>
<li>
<p><strong>commitTransaction()</strong> &#8594; Valida la transacci√≥n actual</p>
</li>
<li>
<p><strong>abortTransaction()</strong> &#8594; Invalida la transacci√≥n actual</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>M√°s informaci√≥n en: <a href="https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html" class="bare">https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya hemos dicho antes, que para enviar mensajes, necesitamos envolverlos en una instancia de <strong>ProducerRecord</strong>, que est√° en <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Las instancias de <strong>ProducerRecord</strong> contienen el mensaje que queremos enviar a nuestros <strong>topics</strong>. La parte m√°s importante de esta clase es su constructor, ya que es donde especificamos tanto el contenido, como el destino.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ProducerRecord(String topic, V value)</strong> &#8594; Enviamos a un topic un valor sin clave</p>
</li>
<li>
<p><strong>ProducerRecord(String topic, K key, V value)</strong> &#8594; Enviamos a un topic un mensaje con clave y valor</p>
</li>
<li>
<p><strong>ProducerRecord(String topic, Integer partition, K key, V value)</strong> &#8594; Enviamos a una partici√≥n concreta de un topic un mensaje con clave y valor</p>
</li>
</ul>
</div>
</li>
<li>
<p>Tambi√©n posee algunos m√©todos √∫tiles para consultar el contenido:</p>
<div class="ulist">
<ul>
<li>
<p><strong>key()</strong> &#8594; Devuelve la clave del mensaje</p>
</li>
<li>
<p><strong>value()</strong> &#8594; Devuelve el valor del mensaje</p>
</li>
<li>
<p><strong>partition()</strong> &#8594; Devuelve la partici√≥n a la que queremos enviar el mensaje (si lo hemos especificado)</p>
</li>
<li>
<p><strong>timestamp()</strong> &#8594; Devuelve el timestamp del momento de creaci√≥n del mensaje</p>
</li>
<li>
<p><strong>topic()</strong> &#8594; Devuelve el topic que hemos especificado como destino</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por √∫ltimo, vamos a ver las opciones de configuraci√≥n.</p>
<div class="ulist">
<ul>
<li>
<p>Para poder instanciar un <strong>KafkaProducer</strong>, necesitamos facilitarle un objeto <strong>Properties</strong>.</p>
</li>
<li>
<p>Sobre √©l, tenemos que definir una serie de configuraciones (vamos a ver ahora las m√°s importantes).</p>
</li>
<li>
<p>Para facilitarnos esto, <strong>Kafka</strong> nos ofrece la clase <strong>ProducerConfig</strong>, del paquete <strong>org.apache.kafka.clients.producer</strong>, que contiene las constantes con los nombres de las propiedades que podemos usar.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ProducerConfig.CLIENT_ID_CONFIG</strong> &#8594; Para especificar el <strong>client.id</strong> del productor.</p>
</li>
<li>
<p><strong>ProducerConfig.COMPRESSION_TYPE_CONFIG</strong> &#8594; Para especificar el <strong>compression.type</strong> (tipo de compresi√≥n).</p>
</li>
<li>
<p><strong>ProducerConfig.ACKS_CONFIG</strong> &#8594; Especifica cu√°ntas respuestas espera, propiedad <strong>acks</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.RETRIES_CONFIG</strong> &#8594; Especifica los reintentos, propiedad <strong>retries</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.BOOTSTRAP_SERVERS_CONFIG</strong> &#8594; Lista de los nodos a los que conectarnos para obtener el esquema, propiedad <strong>bootstrap.servers</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar la clave, propiedad <strong>key.serializer</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar el valor, propiedad <strong>value.serializer</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.BATCH_SIZE_CONFIG</strong> &#8594; Tama√±o de mensajes antes del env√≠o, propiedad <strong>batch.size</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.LINGER_MS_CONFIG</strong> &#8594; Tiempo m√°ximo de almacenamiento de mensajes antes dle env√≠o, propiedad <strong>linger.ms</strong>.</p>
</li>
<li>
<p><strong>ProducerConfig.PARTITIONER_CLASS_CONFIG</strong> &#8594; Clase usada para decidir a qu√© partici√≥n enviar los mensajes, propiedad <strong>partitioner.class</strong>.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Con todo esto en juego, vamos a crear nuestro primer ejemplo, que enviar√° a <strong>topicEjemplo01</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;

<span class="comment">//kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topicEjemplo01 --property print.key=true --from-beginning</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos01</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id));
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos a√±adir un <strong>Callback</strong> a nuestro <strong>send()</strong>, creamos la clase <strong>CallbackSimple</strong> implementando la interfaz <strong>org.apache.kafka.clients.producer.Callback</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Callback</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.RecordMetadata</span>;

<span class="comment">//kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topicEjemplo01 --property print.key=true --from-beginning</span>
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos02</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id),<span class="keyword">new</span> <span class="predefined-type">Callback</span>(){
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> onCompletion(RecordMetadata meta, <span class="exception">Exception</span> arg1) {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje escrito en </span><span class="delimiter">&quot;</span></span>+meta.topic()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> particion </span><span class="delimiter">&quot;</span></span>+meta.partition()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> con offset </span><span class="delimiter">&quot;</span></span>+meta.offset());
                        }});
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo habitual es que mandemos los mensajes con una clave, as√≠ que vamos a modificar un poco nuestro ejemplo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Callback</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.RecordMetadata</span>;
<span class="directive">public</span> <span class="type">class</span> <span class="class">ProducerEjemplos03</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringSerializer</span><span class="delimiter">&quot;</span></span>);

        Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);
        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>,<span class="string"><span class="delimiter">&quot;</span><span class="content">ID_</span><span class="delimiter">&quot;</span></span>+id, <span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje </span><span class="delimiter">&quot;</span></span>+id),<span class="keyword">new</span> <span class="predefined-type">Callback</span>(){
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> onCompletion(RecordMetadata meta, <span class="exception">Exception</span> arg1) {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Mensaje escrito en </span><span class="delimiter">&quot;</span></span>+meta.topic()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> particion </span><span class="delimiter">&quot;</span></span>+meta.partition()+<span class="string"><span class="delimiter">&quot;</span><span class="content"> con offset </span><span class="delimiter">&quot;</span></span>+meta.offset());
                        }});
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }
        producer.flush();
        producer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto al <strong>particionador</strong>, si queremos especificar el nuestro propio, debemos implementar la clase <strong>Partitioner</strong> del paquete <strong>org.apache.kafka.clients.producer</strong>.</p>
</li>
<li>
<p>Quiz√°s lo m√°s interesante sea obtener del objeto <strong>Cluster</strong> informaci√≥n, concretamente <strong>partitionCountForTopic()</strong> que nos dice cu√°ntas particiones existen para un <strong>Topic</strong> en concreto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.producer</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Partitioner</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Cluster</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimplePartitioner</span> <span class="directive">implements</span> Partitioner {

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">int</span> partition(<span class="predefined-type">String</span> topic, <span class="predefined-type">Object</span> key, <span class="type">byte</span><span class="type">[]</span> keyBytes, <span class="predefined-type">Object</span> value, <span class="type">byte</span><span class="type">[]</span> valueBytes, Cluster cluster) {
        <span class="keyword">return</span> <span class="predefined-type">Math</span>.abs(key.hashCode() % cluster.partitionCountForTopic(topic));
    }

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> close() {}

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> configure(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, ?&gt; conf) {}
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>No nos vamos a meter tampoco a estudiar los serializadores y de-serializadores, pero son interfaces que hemos de implementar para serializar o de-serializar nuestras clases en caso de que no nos valga con los que <strong>Kafka</strong> proporciona.</p>
</li>
<li>
<p>La interfaz <strong>org.apache.kafka.common.serialization.Serializer</strong> obliga a implementar la funci√≥n <strong>serialize(topic,map)</strong> debe convertir un <strong>Map&lt;String,Object&gt;</strong> en un array de bytes <strong>byte[]</strong></p>
</li>
<li>
<p>La interfaz <strong>org.apache.kafka.common.serialization.Deserializer</strong> obliga a implementar la funci√≥n <strong>deserialize(topic,data)</strong> debe convertir un array de bytes <strong>byte[]</strong> en un <strong>Map&lt;String,Object&gt;</strong></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_api_para_consumer">10.3. API para Consumer</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder hacer nuestro propio <strong>Consumer</strong>, necestaremos conocer las siguientes clases:</p>
<div class="ulist">
<ul>
<li>
<p><strong>KafkaConsumer</strong> &#8594; Las instancias de esta clase poseen un m√©todo <strong>subscribe()</strong>, que permite suscribirse a unos <strong>Topics</strong>, y hacer <strong>poll()</strong> de sus mensajes.</p>
</li>
<li>
<p><strong>ConsumerRecord</strong> &#8594; Las instancias de esta clase son los mensajes que consumimos de nuestros <strong>Topics</strong>. Poseen <strong>Clave</strong> y <strong>Valor</strong>, pero tambi√©n tienen metainformaci√≥n como <strong>offset</strong>, <strong>partici√≥n</strong>, <strong>topic</strong> o <strong>timestamp</strong></p>
</li>
<li>
<p><strong>ConsumerConfig</strong> &#8594; Clase que contiene las constantes con las distintas configuraciones aplicables. Es recomendable hacer uso de ellas al crear el fichero <strong>properties</strong>, en lugar de escribirlas manualmente.</p>
</li>
</ul>
</div>
</li>
<li>
<p>La clase <strong>KafkaConsumer</strong>, que est√° en el paquete <strong>org.apache.kafka.clients.consumer</strong>, tiene varios m√©todos que debemos conocer:</p>
<div class="ulist">
<ul>
<li>
<p><strong>assign(Collection&lt;TopicPartition&gt; c)</strong> &#8594; Permite asignar una lista de particiones al consumidor</p>
</li>
<li>
<p><strong>commitAsync()/commitSync()</strong> &#8594; Guardado manual del offset le√≠do</p>
</li>
<li>
<p><strong>metrics()</strong> &#8594; M√©tricas internas del consumidor</p>
</li>
<li>
<p><strong>poll(t)</strong> &#8594; Trae los registros de los <strong>topics</strong> suscritos (si no hay, espera t milisegundos)</p>
</li>
<li>
<p><strong>seek(TopicPartition t,long offset)</strong> &#8594; Para especificar a partir de qu√© offset quiero traer datos de un topic y una partici√≥n concretas</p>
</li>
<li>
<p><strong>subscribe(Collection&lt;Sring&gt; topics)</strong> &#8594; Se suscribe a los <strong>topics</strong> especificados (Admite Regex en lugar de coleccion de String)</p>
</li>
<li>
<p><strong>subscription()</strong> &#8594; Nos da la lista de topics a los que est√° suscrito</p>
</li>
<li>
<p><strong>unsubscribe()</strong> &#8594; se retira de los topics (todos) a los que est√° suscrito</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Puedes obtener m√°s informaci√≥n en: <a href="https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html" class="bare">https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>El <strong>KafkaConsumer</strong> se suscribe a una lista de <strong>Topics</strong>, y hace <strong>poll()</strong> sobre ella. Cuando realiza esta acci√≥n, nos devuelva una "colecci√≥n" de mensajes le√≠dos. Esta colecci√≥n es un <strong>ConsumerRecords&lt;K,V&gt;</strong>, objeto sobre el que podemos iterar para tratar cada <strong>ConsumerRecord&lt;K,V&gt;</strong> individualmente.</p>
</li>
<li>
<p>Este objeto proporciona unos m√©todos para poder extrar la clave y el valor, y cualquier otro dato que pueda ser de utilidad:</p>
<div class="ulist">
<ul>
<li>
<p><strong>key()</strong> &#8594; Devuelve la clave del mensaje</p>
</li>
<li>
<p><strong>value()</strong> &#8594; Devuelve el valor del mensaje</p>
</li>
<li>
<p><strong>partition()</strong> &#8594; Devuelve la partici√≥n de la que hemos le√≠do</p>
</li>
<li>
<p><strong>timestamp()</strong> &#8594; Devuelve el timestamp del momento de creaci√≥n del mensaje</p>
</li>
<li>
<p><strong>topic()</strong> &#8594; Devuelve el topic del que hemos le√≠do</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por √∫ltimo, vamos a ver las opciones de configuraci√≥n. Para poder instanciar un <strong>KafkaConsumer</strong>, necesitamos facilitarle un objeto <strong>Properties</strong>. Sobre √©l, tenemos que definir una serie de configuraciones (vamos a ver ahora las m√°s importantes).</p>
</li>
<li>
<p>Para facilitarnos esto, <strong>Kafka</strong> nos ofrece la clase <strong>ConsumerConfig</strong>, del paquete <strong>org.apache.kafka.clients.consumer</strong>, que contiene las constantes con los nombres de las propiedades que podemos usar.</p>
<div class="ulist">
<ul>
<li>
<p><strong>ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG</strong> &#8594; Lista de los nodos a los que conectarnos para obtener el esquema, propiedad <strong>bootstrap.servers</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.GROUP_ID_CONFIG</strong> &#8594; Para especificar el <strong>group.id</strong> del consumidor. Todos los consumidores con este grupo actu√°n como un √∫nico consumidor.</p>
</li>
<li>
<p><strong>ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar la clave, propiedad <strong>key.deserializer</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG</strong> &#8594; Clase para serializar el valor, propiedad <strong>value.deserializer</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG</strong> &#8594; Para que haga un commit manual del √∫ltimo offset le√≠do, propiedad*"enable.auto.commit*.</p>
</li>
<li>
<p><strong>ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG</strong> &#8594; Especifica el tiempo entre commits, propiedad <strong>auto.commit.interval.ms</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG</strong> &#8594; Tiempo m√°ximo de la sesi√≥n, propiedad <strong>session.timeout.ms</strong>.</p>
</li>
<li>
<p><strong>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG</strong> &#8594; Qu√© hacer si este grupo de clientes no tiene offset inicial, propiedad <strong>auto.offset.reset</strong>. Puede tomar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>latest</strong>: El offset se fija en el √∫ltimo registro existente, es decir, s√≥lo mensajes nuevos (por defecto)</p>
</li>
<li>
<p><strong>earliest</strong>: Si no hay offset, se empieza desde el primer registro</p>
</li>
<li>
<p><strong>none</strong>: Si no hay offset, salta una excepci√≥n</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Vamos a hacer nuestro primer consumidor (Fijaros, que s√≥lo procesa a partir de los mensajes nuevos, si queremos que esto cambi hay que usar <strong>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG</strong>):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConsumerEjemplo01</span> {
         <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">consumer_base</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                <span class="predefined-type">String</span> s=ConsumerConfig.AUTO_OFFSET_RESET_CONFIG;
                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>));
                <span class="type">int</span> leidos=<span class="integer">0</span>;
                <span class="keyword">while</span> (<span class="predefined-constant">true</span>) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000</span>);
                        <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
                                <span class="keyword">if</span> (++leidos&gt;<span class="integer">10</span>) { <span class="keyword">break</span>;}
                }
                consumer.close();
         }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Esta configuraci√≥n no es la que buscamos.</p>
</li>
<li>
<p>Normalmente no vamos a parar al leer una serie de mensajes, estaremos hasta que alguien pare la JVM.</p>
</li>
<li>
<p>Para evitar esto, vamos a usar una variable <strong>AtomicBoolean</strong>, que nos permita parar el proceso cuando se reciba una se√±al de parar en la JVM</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.kafka.api.evolucion</span>;

<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ConsumerEjemplo02</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

         <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">host.broker1:9092</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">consumer_base</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
                <span class="predefined-type">String</span> s=ConsumerConfig.AUTO_OFFSET_RESET_CONFIG;
                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(<span class="string"><span class="delimiter">&quot;</span><span class="content">topicEjemplo01</span><span class="delimiter">&quot;</span></span>));
                <span class="type">int</span> leidos=<span class="integer">0</span>;
                <span class="keyword">while</span> (!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="integer">1000</span>);
                        <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
                                <span class="keyword">if</span> (++leidos&gt;<span class="integer">10</span>) { <span class="keyword">break</span>;}
                }
                consumer.close();
         }
}</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_garant√≠a_de_entrega">10.4. Garant√≠a de entrega</h3>
<div class="ulist">
<ul>
<li>
<p>Existen tres configuraciones posibles en kafka para la garant√≠a de entrega</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_at_most_once">10.4.1. At most once</h4>
<div class="ulist">
<ul>
<li>
<p>El mensaje se entregar√° como m√°ximo una vez.</p>
</li>
<li>
<p>Una vez entregado, no se podr√° enviar de nuevo.</p>
</li>
<li>
<p>Si el consumidor no puede tratarlo, el mensaje se perder√°.</p>
</li>
<li>
<p>Esto se debe a que kafka generar√° un commit del √∫ltimo offset leido.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Es posible tener un escenario de tipo "al menos una vez"</p>
</li>
<li>
<p>Si procesamos el mensaje y kafka no tiene tiempo de hacer el autocommit, el consumidor leer√° el mismo mensaje.</p>
</li>
<li>
<p>Debemos estar preparados para duplicados en estos escenarios.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_at_least_once">10.4.2. At least once</h4>
<div class="ulist">
<ul>
<li>
<p>El mensaje se enviar√° al menos una vez.</p>
</li>
<li>
<p>Es facil que el mensaje se duplique.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora debemos controlar manualmente el offset con la instrucci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumer.commitSync()</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Igual que en el anterior, si el consumidor cae antes de lanzar el commitSync, el mensaje o mensajes se duplicar√°n.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_exactly_once">10.4.3. Exactly-once</h4>
<div class="ulist">
<ul>
<li>
<p>Garantizamos que uno y solo un mensaje se leer√°.</p>
</li>
<li>
<p>En versiones anteriores, la implementaci√≥n era manual, y hab√≠a que implementar un ConsumerRebalanceListener que permitiera leer a partir de un offset concreto de una partici√≥n de un topic.</p>
</li>
<li>
<p>Para garantizarlo, ahora podemos usar las transacciones en Kafka.</p>
</li>
<li>
<p>La implementaci√≥n debe ser tanto en el productor como en el consumidor.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_configuraci√≥n_del_productor">10.4.3.1. Configuraci√≥n del productor</h5>
<div class="ulist">
<ul>
<li>
<p>Para una garant√≠a total, debemos definir idempotencia para que no permita duplicaci√≥n de mensajes.</p>
</li>
<li>
<p>Podemos confirmar la escritura en todas las r√©plicas</p>
</li>
<li>
<p>Debemos definir un transactional.id que permita localizar quien es el productor que va a generar las transacciones y que kafka le haga un seguimiento.</p>
</li>
<li>
<p>Si queremos garantizar el orden, definimos que haya una sola petici√≥n por conexi√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// Configuraci√≥n de transacci√≥n.</span>
properties.put(ProducerConfig.ACKS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">all</span><span class="delimiter">&quot;</span></span>);
properties.put(ProducerConfig.CLIENT_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
properties.put(ProducerConfig.RETRIES_CONFIG, <span class="integer">3</span>);
<span class="comment">// Permite garantizar el orden</span>
properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="integer">1</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el productor se debe notificar al broker que vamos a usar transacciones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.initTransactions();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Antes de enviar los ProducerRecords, iniciamos la transacci√≥n</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.beginTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras enviar todos los records que necesitemos enviar en la transacci√≥n, confirmamos por medio de la siguiente instrucci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.commitTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de producir un error, podemos capturar la excepci√≥n y abortar la transacci√≥n</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">producer.abortTransaction();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si el productor cae, y no realiza el commit, los mensajes que no estuvieran en el commit no se leen por parte del consumidor, si est√° configurado adecuadamente.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_configuraci√≥n_del_consumidor">10.4.3.2. Configuraci√≥n del consumidor</h5>
<div class="ulist">
<ul>
<li>
<p>Nuestro consumidor se configurar√° para un nivel de aislamiento "read_committed".</p>
</li>
<li>
<p>Por defecto los consumidores leen "read_uncommitted", lo que les permitir√≠a leer mensajes no confirmados por el productor.</p>
</li>
<li>
<p>Para confirmar la lectura de los mensajes, definimos el autocommit a false para poder gestionarlo manualmente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">read_committed</span><span class="delimiter">&quot;</span></span>);<span class="comment">// default &quot;read_uncommitted&quot;</span>
props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El consumidor debe confirmar los mensajes leidos y procesados.</p>
</li>
<li>
<p>Para ello, almacenamos un mapa con el offset por partici√≥n que queremos leer en caso de que nos tengamos que recurperar de una caida de servicio.</p>
</li>
<li>
<p>El objeto TopicPartition indica la partici√≥n del topic que queremos asignar el offset</p>
</li>
<li>
<p>El objeto OffsetAndMetadata nos permite indicar el offset del siguiente registro que queremos leer.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">HashMap</span>&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
<span class="keyword">for</span> (TopicPartition partition: records.partitions()) {
        <span class="predefined-type">List</span>&lt;ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt;&gt; list = records.records(partition);
        <span class="type">long</span> offset = list.get(list.size() -<span class="integer">1</span>).offset();
        partitionsWithOffset.put(partition, <span class="keyword">new</span> OffsetAndMetadata(offset+<span class="integer">1</span>));
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, confirmamos los mensajes leidos en la transacci√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">consumer.commitSync(partitionsWithOffset);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma kafka est√° notificado de la lectura del consumidor.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_coordinador">10.4.3.3. Coordinador</h5>
<div class="ulist">
<ul>
<li>
<p>Todo broker de kafka tiene un m√≥dulo de coordinador, responsable de gestionar las transacciones.</p>
</li>
<li>
<p>Para ello almacenar√° una marca en la partici√≥n (que ocupar√° un offset) para indicar que la transacci√≥n es correcta.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_invocando_productores_y_consumidores">10.5. Lab: Invocando productores y consumidores</h3>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Para realizar este laboratorio necesitamos tener iniciado tanto zookeeper como los brokers.</p>
</li>
<li>
<p>Comprobamos que nuestros brokers est√°n correctamente registrados:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkCli.sh
Connecting to localhost:2181
2019-01-23 19:34:34,042 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.14-e5259e437540f349646870ea94dc2658c4e44b3b, built on 03/27/2018 03:55 GMT
...
[zk: localhost:2181(CONNECTED) 0] ls /brokers/ids
[0, 1, 2]</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_creaci√≥n_de_topics">10.5.1. Creaci√≥n de topics</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear topics por medio de una clase helper.</p>
</li>
<li>
<p>Para ello, vamos a copiar el proyecto PlantillaKafka y lo llamaremos kafka-utils.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-01.png" alt="kafka java api lab 01" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el pom.xml vamos a modificar el nombre del proyecto para que no haya conflictos, y cambiamos la versi√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">        &lt;groupId&gt;com.curso.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;kafka-utils&lt;/artifactId&gt;
        &lt;version&gt;<span class="float">1.0</span><span class="float">.0</span>&lt;/version&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos una clase en el paquete com.curso.kafka.util llamada TopicCreator.java</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.util</span>;

<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.AdminClient</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.CreateTopicsResult</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.admin.NewTopic</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TopicCreator</span> {
        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> createTopics(<span class="predefined-type">String</span> servers,<span class="predefined-type">String</span>... topics) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">bootstrap.servers</span><span class="delimiter">&quot;</span></span>, servers);
                AdminClient adminClient = AdminClient.create(props);
                <span class="predefined-type">ArrayList</span>&lt;NewTopic&gt; newTopics = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                <span class="keyword">for</span>(<span class="predefined-type">String</span> topicName: topics) {
                        newTopics.add(<span class="keyword">new</span> NewTopic(topicName, <span class="integer">3</span>,<span class="predefined-type">Short</span>.parseShort(<span class="string"><span class="delimiter">&quot;</span><span class="content">1</span><span class="delimiter">&quot;</span></span>)));
                }
                CreateTopicsResult result = adminClient.createTopics(newTopics);

                <span class="keyword">try</span> {
                        result.all().get();
                } <span class="keyword">catch</span> (<span class="exception">InterruptedException</span> e) {
                        <span class="predefined-type">System</span>.out.println(e.getMessage());
                } <span class="keyword">catch</span> (<span class="exception">ExecutionException</span> e) {
                        <span class="predefined-type">System</span>.out.println(e.getMessage());
                }
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>De esta forma, podremos crear topics para el curso con tres particiones cada una.</p>
</li>
<li>
<p>Ahora, para facilitar el uso de la clase, vamos a agregar la dependencia al proyecto PlantillaKafka</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;dependency&gt;</span>
    <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
    <span class="tag">&lt;artifactId&gt;</span>kafka-utils<span class="tag">&lt;/artifactId&gt;</span>
    <span class="tag">&lt;version&gt;</span>1.0.0<span class="tag">&lt;/version&gt;</span>
<span class="tag">&lt;/dependency&gt;</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_creaci√≥n_de_productor">10.5.2. Creaci√≥n de productor</h4>
<div class="ulist">
<ul>
<li>
<p>Para ello vamos a copiar nuestra plantilla y llamamos al proyecto Ejemplo01ProducersConsumers</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Ser√≠a mucho m√°s interesante generar un arquetipo en Maven para tener directamente el esquema del proyecto, pero por agilidad, copiaremos el proyecto</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Primero seleccionamos el proyecto y lo copiamos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-02.png" alt="kafka java api lab 02" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Luego pegamos en el <strong>Package Explorer</strong> el proyecto</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-03.png" alt="kafka java api lab 03" width="300">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Llamamos al proyecto <strong>Ejemplo01ProductoresConsumidores</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-04.png" alt="kafka java api lab 04" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Modificamos el pom del proyecto para que se llame como el proyecto que hemos creado.</p>
</li>
<li>
<p>Solo modificamos el &lt;artifactId&gt;</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="xml"><span class="tag">&lt;project</span> <span class="attribute-name">xmlns</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xmlns:xsi</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://www.w3.org/2001/XMLSchema-instance</span><span class="delimiter">&quot;</span></span>
        <span class="attribute-name">xsi:schemaLocation</span>=<span class="string"><span class="delimiter">&quot;</span><span class="content">http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd</span><span class="delimiter">&quot;</span></span><span class="tag">&gt;</span>
        <span class="tag">&lt;modelVersion&gt;</span>4.0.0<span class="tag">&lt;/modelVersion&gt;</span>
        <span class="tag">&lt;groupId&gt;</span>com.curso.kafka<span class="tag">&lt;/groupId&gt;</span>
        <span class="tag">&lt;artifactId&gt;</span>Ejemplo01ProductoresConsumidores<span class="tag">&lt;/artifactId&gt;</span>
        <span class="tag">&lt;version&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/version&gt;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Agregamos la dependencia</p>
</li>
<li>
<p>Vamos a producir mensajes, para ello creamos un productor:</p>
</li>
<li>
<p>Creamos una nueva clase:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-05.png" alt="kafka java api lab 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La nueva clase se llamar√°:</p>
<div class="ulist">
<ul>
<li>
<p>Package: com.curso.kafka.producersconsumers.simple</p>
</li>
<li>
<p>Name: SimpleProducer</p>
</li>
<li>
<p>Public static void main: true</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-java-api-lab-06.png" alt="kafka java api lab 06" width="400">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El contenido ser√° el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.simple</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Producer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> BROKER_LIST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">public</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">topic-simple</span><span class="delimiter">&quot;</span></span>;

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span>, <span class="exception">ExecutionException</span> {

            TopicCreator.createTopics(BROKER_LIST, TOPIC);

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

            Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);

        <span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
            <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
            <span class="predefined-type">String</span> message = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">message[%d]</span><span class="delimiter">&quot;</span></span>, id);
            <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Sending message with: </span><span class="delimiter">&quot;</span></span> + key);
            producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, message));
            <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
        }

        producer.flush();
        producer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al principio indicamos la creaci√≥n s√≠ncrona de los topics</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TopicCreator.createTopics(BROKER_LIST, TOPIC);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aqu√≠ indicamos la configuraci√≥n del productor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estamos indicando la lista inicial de los brokers de kafka</p>
</li>
<li>
<p>Indicamos los serializadores por defecto para almacenar en el topic</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Producer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Aqu√≠ vemos como se crea el productor indicando la clave y el valor, y asignando las propiedades por defecto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">for</span> (<span class="type">int</span> id = <span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
    <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
    <span class="predefined-type">String</span> message = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">message[%d]</span><span class="delimiter">&quot;</span></span>, id);
    <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Sending message with: </span><span class="delimiter">&quot;</span></span> + key);
    producer.send(<span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, message));
    <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En el bucle, mandamos mensajes de tipo clave/valor al topic elegido</p>
</li>
<li>
<p>Esperamos un segundo por petici√≥n</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>El hecho de enviar no significa explicitamente que envie.</p>
</li>
<li>
<p>Debe cumplir una condici√≥n de n√∫mero de mensajes encolados o un tiempo de terminado, y manda toda la informaci√≥n en paquetes.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    producer.flush();
    producer.close();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Forzamos a enviar los documentos que est√©n encolados con flush y cerramos el canal con close.</p>
</li>
<li>
<p>Ejecutamos la clase para conectarse a nuestro topic y enviar los datos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Sending message with: key[<span class="integer">0</span>]
Sending message with: key[<span class="integer">1</span>]
Sending message with: key[<span class="integer">2</span>]
...</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nuestro <strong>Productor</strong> est√° funcionando!</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_simple_consumer">10.5.3. Simple Consumer</h4>
<div class="ulist">
<ul>
<li>
<p>Veamos ahora con nuestro consumidor. Creamos la clase <strong>com.curso.kafka.api.consumer.simple.SimpleConsumer</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.simple</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleConsumer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> KAFKA_HOST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">simple-consumer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(SimpleProducer.TOPIC));

        <span class="keyword">while</span> (!closed.get()) {
            ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofMillis(<span class="integer">1000</span>));
            <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                        record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
        }

        consumer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Primero definimos el shutdown hook para cerrar el consumidor correctamente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> run() {
        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
        closed.set(<span class="predefined-constant">true</span>);
    }
});</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Configuramos el consumidor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">simple-consumer</span><span class="delimiter">&quot;</span></span>);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Indicamos al menos un servidor para que sea alcanzable y pueda preguntar por el mapa de brokers que necesite para el topic.</p>
</li>
<li>
<p>Activamos el autocommit para que se acuerde cada 100 ms de donde estaba el consumidor</p>
</li>
<li>
<p>Indicamos cuales son los deserializadores para clave y valor.</p>
</li>
<li>
<p>Ahora creamos el consumidor y nos suscribimos al topic. Podr√≠amos suscribirnos a una lista de topics.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
    consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(SimpleProducer.TOPIC));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo, indicamos que mientras no est√© cerrada la vm, vamos a consumir registros:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">while</span> (!closed.get()) {
    ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofMillis(<span class="integer">1000</span>));
    <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
        <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Obtenemos el record y vemos que informaci√≥n relevante posee publicandola directamente en el log</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_prueba_de_ejecuci√≥n">10.5.4. Prueba de ejecuci√≥n</h4>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos el consumidor y confirmamos que consume los mensajes nuevos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">...
partition =  1   offset =     3   key = key[13] timestamp = 1603106530616  value =  message[13]
partition =  1   offset =     4   key = key[14] timestamp = 1603106531617  value =  message[14]
partition =  0   offset =     6   key = key[15] timestamp = 1603106532619  value =  message[15]
partition =  2   offset =     4   key = key[16] timestamp = 1603106533621  value =  message[16]
partition =  1   offset =     5   key = key[17] timestamp = 1603106534622  value =  message[17]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos el consumidor y nos fijamos en que offset estaba trabajando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  1   offset =    15   key = key[37] timestamp = 1603106554646  value =  message[37]
partition =  2   offset =    10   key = key[38] timestamp = 1603106555647  value =  message[38]
partition =  0   offset =    12   key = key[39] timestamp = 1603106556648  value =  message[39]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Volvemos a arrancarlo al cabo de unos segundos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  0   offset =    13   key = key[41] timestamp = 1603106558650  value =  message[41]
partition =  0   offset =    14   key = key[42] timestamp = 1603106559651  value =  message[42]
partition =  0   offset =    15   key = key[48] timestamp = 1603106565658  value =  message[48]
partition =  0   offset =    16   key = key[52] timestamp = 1603106569665  value =  message[52]
partition =  0   offset =    17   key = key[53] timestamp = 1603106570667  value =  message[53]
partition =  0   offset =    18   key = key[54] timestamp = 1603106571668  value =  message[54]
partition =  0   offset =    19   key = key[61] timestamp = 1603106578678  value =  message[61]
partition =  0   offset =    20   key = key[62] timestamp = 1603106579679  value =  message[62]
partition =  0   offset =    21   key = key[63] timestamp = 1603106580681  value =  message[63]
partition =  0   offset =    22   key = key[65] timestamp = 1603106582688  value =  message[65]
partition =  0   offset =    23   key = key[67] timestamp = 1603106584696  value =  message[67]
partition =  0   offset =    24   key = key[68] timestamp = 1603106585698  value =  message[68]
partition =  2   offset =    11   key = key[40] timestamp = 1603106557649  value =  message[40]
partition =  2   offset =    12   key = key[43] timestamp = 1603106560653  value =  message[43]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como sigue trabajando directamente desde donde lo dej√≥.</p>
</li>
<li>
<p>Hay que darse cuenta que el orden no est√° garantizado entre particiones.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_partitionproducer">10.5.5. PartitionProducer</h4>
<div class="ulist">
<ul>
<li>
<p>Si nos damos cuenta, a pesar de tener un topic con tres particiones, toda la informaci√≥n va a la primera partici√≥n.</p>
</li>
<li>
<p>Vamos a crear un nuevo particionador y un productor basado en el anterior para comprobar que podemos decidir a donde van los documentos por medio del mismo.</p>
</li>
<li>
<p>Primero creamos el particionador en com.curso.kafka.producersconsumers.partitioner.SimplePartitioner</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.partitioner</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.Partitioner</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Cluster</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SimplePartitioner</span> <span class="directive">implements</span> Partitioner {

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">int</span> partition(<span class="predefined-type">String</span> topic, <span class="predefined-type">Object</span> key, <span class="type">byte</span><span class="type">[]</span> keyBytes, <span class="predefined-type">Object</span> value, <span class="type">byte</span><span class="type">[]</span> valueBytes, Cluster cluster) {
        <span class="keyword">return</span> <span class="predefined-type">Math</span>.abs(key.hashCode() % cluster.partitionCountForTopic(topic));
    }

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> close() {}

    <span class="annotation">@Override</span>
    <span class="directive">public</span> <span class="type">void</span> configure(<span class="predefined-type">Map</span>&lt;<span class="predefined-type">String</span>, ?&gt; conf) {}
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, usamos el codigo hash y calculamos el modulo con la informaci√≥n  de particiones que nos ofrece el cluster.</p>
</li>
<li>
<p>Ahora vamos a crear un nuevo productor que use el nuevo particionador.</p>
</li>
<li>
<p>Copiamos el productor y lo renombramos a PartitionProducer.</p>
</li>
<li>
<p>Agregamos la informaci√≥n del partitioner en la configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">    props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, SimplePartitioner.class.getName());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La clase resultante es la siguiente.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.partitioner</span>;

<span class="keyword">import</span> <span class="include">java.util.Properties</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">PartitionProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> BROKER_LIST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">partition-producer-topic</span><span class="delimiter">&quot;</span></span>;

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="comment">// Topics creados</span>

                TopicCreator.createTopics(BROKER_LIST, TOPIC);

                <span class="comment">// Config</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BROKER_LIST);
                props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, SimplePartitioner.class.getName());

                KafkaProducer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);

                <span class="keyword">for</span>(<span class="type">int</span> id=<span class="integer">0</span>; id &lt; <span class="integer">5000</span>; id++) {
                        <span class="predefined-type">String</span> key = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">key[%d]</span><span class="delimiter">&quot;</span></span>, id);
                        <span class="predefined-type">String</span> value = <span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">value[%d]</span><span class="delimiter">&quot;</span></span>, id);
                        ProducerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC, key, value);
                        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Enviando mensaje : </span><span class="delimiter">&quot;</span></span> + record.toString());
                        producer.send(record);
                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
                }
                producer.flush();
                producer.close();
        }

}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Realizamos la misma operaci√≥n para el consumidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">package com.curso.kafka.producersconsumers.partitioner;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicBoolean;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;

public class PartitionConsumer {
        private static final AtomicBoolean closed = new AtomicBoolean(false);

        public static void main(String[] args) {
                Runtime.getRuntime().addShutdownHook(new Thread() {
                        @Override
                        public void run() {
                                System.out.println(&quot;Apagando&quot;);
                                closed.set(true);
                        }
                });
                // Configs
                Properties props = new Properties();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;);// __consumer_offsets
                props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;PartitionConsumer&quot;);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);

                List&lt;TopicPartition&gt; particiones = new ArrayList&lt;&gt;();
                particiones.add(new TopicPartition(PartitionProducer.TOPIC, 0));
                particiones.add(new TopicPartition(PartitionProducer.TOPIC, 2));

                //consumer.subscribe(Collections.singletonList(SimpleProducer.TOPIC_BASE));
                consumer.assign(particiones);

                while(!closed.get()) {
                        ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
                        for(ConsumerRecord&lt;String, String&gt; record: records) {
                                System.out.printf(&quot;particion = %2d offset = %5d key = %7s ts = %8s value %12s\n&quot;,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                String.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Iniciamos el productor para que mande los mensajes y luego el consumidor si no lo hemos dejado levantado con anterioridad.</p>
</li>
<li>
<p>Comprobaremos como estamos usando nuestro propio particionador.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  1   offset =    53   key =  key[0] timestamp = 1603106685658  value =   message[0]
partition =  0   offset =    57   key =  key[1] timestamp = 1603106686672  value =   message[1]
partition =  2   offset =    45   key =  key[2] timestamp = 1603106687674  value =   message[2]
partition =  1   offset =    54   key =  key[3] timestamp = 1603106688677  value =   message[3]
partition =  0   offset =    58   key =  key[4] timestamp = 1603106689677  value =   message[4]
partition =  2   offset =    46   key =  key[5] timestamp = 1603106690681  value =   message[5]
partition =  1   offset =    55   key =  key[6] timestamp = 1603106691683  value =   message[6]
partition =  0   offset =    59   key =  key[7] timestamp = 1603106692686  value =   message[7]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_groups">10.5.6. Groups</h4>
<div class="ulist">
<ul>
<li>
<p>Con el productor levantado, vamos iniciar de nuevo el partition consumer, ya que pertenecer√° al mismo grupo.</p>
</li>
<li>
<p>En cuanto lo ejecutemos, veremos como se apodera de todas las particiones y consume todos los registros.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Adding    : [topicSimple-0, topicSimple-1, topicSimple-2]
....
partition =  2   offset =   176   key = key[394]   value = message[394]
partition =  0   offset =   188   key = key[395]   value = message[395]
partition =  1   offset =   185   key = key[396]   value = message[396]
partition =  2   offset =   177   key = key[397]   value = message[397]
partition =  0   offset =   189   key = key[398]   value = message[398]
partition =  1   offset =   186   key = key[399]   value = message[399]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora ejecutamos otra instancia de la misma clase con run as &#8594; Java Application.</p>
</li>
<li>
<p>Comprobaremos como en la instancia inicial aparece el siguiente mensaje</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Removing  : [topicSimple-0, topicSimple-1, topicSimple-2]
Adding    : [topicSimple-0, topicSimple-1]
partition =  0   offset =   190   key = key[401]   value = message[401]
partition =  1   offset =   187   key = key[402]   value = message[402]
partition =  0   offset =   191   key = key[404]   value = message[404]
partition =  1   offset =   188   key = key[405]   value = message[405]
partition =  0   offset =   192   key = key[407]   value = message[407]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y en la nueva instancia aparece la partici√≥n que no est√° asignada, y a partir de ahi, los mensajes solo se leen desde las particiones que posee</p>
</li>
<li>
<p>En cuanto a la segunda instancia:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Adding    : [topicSimple-2]
partition =  2   offset =   179   key = key[403]   value = message[403]
partition =  2   offset =   180   key = key[406]   value = message[406]
partition =  2   offset =   181   key = key[409]   value = message[409]
partition =  2   offset =   182   key = key[412]   value = message[412]
partition =  2   offset =   183   key = key[415]   value = message[415]
partition =  2   offset =   184   key = key[418]   value = message[418]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como se agrupan y obtienen los mensajes de la partici√≥n adicional.</p>
</li>
<li>
<p>Arrancamos una tercera instancia y veremos como cada uno posee el acceso a una sola partici√≥n.</p>
</li>
<li>
<p>As√≠ garantizamos que las instancias leen mensajes distintos.</p>
</li>
<li>
<p>Pero, y si agregamos un cuarto,</p>
</li>
<li>
<p>Veremos como una de las instancias se queda sin recibir mensajes.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">partition =  2   offset =   322   key = key[832]   value = message[832]
Removing  : [topicSimple-2]
Adding    : []</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si paramos cualquier otra instancia, el sistema lo entiende y reasigna las particiones</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Removing  : <span class="type">[]</span>
Adding    : [topicSimple-<span class="integer">2</span>]
partition =  <span class="integer">2</span>   offset =   <span class="integer">345</span>   key = key[<span class="integer">901</span>]   value = message[<span class="integer">901</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Paramos todos los consumidores</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_autocommit">10.5.7. Autocommit</h4>
<div class="ulist">
<ul>
<li>
<p>En este caso vamos a gestionar el commit de forma manual.</p>
</li>
<li>
<p>Para ello creamos una clase llamada ManualCommitConsumer.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.commit</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ManualCommitConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">AutoCommitConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
                consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(PartitionProducer.TOPIC));
                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );

                        }
                        consumer.commitSync();
                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">5000</span>);

                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos el nuevo productor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">470</span>   key = key[<span class="integer">1242</span>]   value = message[<span class="integer">1242</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">471</span>   key = key[<span class="integer">1245</span>]   value = message[<span class="integer">1245</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">472</span>   key = key[<span class="integer">1248</span>]   value = message[<span class="integer">1248</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">473</span>   key = key[<span class="integer">1251</span>]   value = message[<span class="integer">1251</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ejecutamos este consumidor, posteriormente el productor. Vemos como va consumiendo. Hacemos una parada despu√©s de unos 10 segundos y volvemos a levantarlo.</p>
</li>
<li>
<p>Paramos entonces el consumidor y lo dejamos parado 10 segundos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">470</span>   key = key[<span class="integer">1242</span>]   value = message[<span class="integer">1242</span>]
partition =  <span class="integer">0</span>   offset =   <span class="integer">471</span>   key = key[<span class="integer">1245</span>]   value = message[<span class="integer">1245</span>]</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hay registros que ha vuelto a procesar. Como no lleg√≥ a guardar el √∫ltimo offset, no registr√≥ los √∫ltimos mensajes procesados.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_partitionconsumer">10.5.8. PartitionConsumer</h4>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear un consumidor que se conecte a una partici√≥n concreta.</p>
</li>
<li>
<p>Para ello creamos la siguiente clase:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.manualpartition</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">ManualPartitionConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);<span class="comment">// __consumer_offsets</span>
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">SeekConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

                <span class="predefined-type">List</span>&lt;TopicPartition&gt; particiones = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>));

                consumer.assign(particiones);

                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al ejecutarlo, vemos como solo usa las particiones que hemos decidido.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">topic = topicSimple partition =  2   offset =   764   key = key[2132]   value = message[2132]
topic = topicSimple partition =  0   offset =   767   key = key[2133]   value = message[2133]
topic = topicSimple partition =  2   offset =   765   key = key[2135]   value = message[2135]
topic = topicSimple partition =  0   offset =   768   key = key[2136]   value = message[2136]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_seekconsumer">10.5.9. SeekConsumer</h4>
<div class="ulist">
<ul>
<li>
<p>Usando el truco de las particiones, vamos a buscar en este caso un offset concreto.</p>
</li>
<li>
<p>Para ello vamos a crear la siguiente clase</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.manualpartition</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.ArrayList</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">SeekConsumer</span> {
        <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>() {
                        <span class="annotation">@Override</span>
                        <span class="directive">public</span> <span class="type">void</span> run() {
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Apagando</span><span class="delimiter">&quot;</span></span>);
                                closed.set(<span class="predefined-constant">true</span>);
                        }
                });
                <span class="comment">// Configs</span>
                <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);<span class="comment">// __consumer_offsets</span>
                props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">SeekConsumer</span><span class="delimiter">&quot;</span></span>);
                props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
                props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

                KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

                <span class="predefined-type">List</span>&lt;TopicPartition&gt; particiones = <span class="keyword">new</span> <span class="predefined-type">ArrayList</span>&lt;&gt;();
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">1</span>));
                particiones.add(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>));

                <span class="comment">//consumer.subscribe(Collections.singletonList(SimpleProducer.TOPIC_BASE));</span>
                consumer.assign(particiones);
                consumer.seekToBeginning(<span class="predefined-type">Collections</span>.singleton(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">0</span>)));
                consumer.seekToEnd(<span class="predefined-type">Collections</span>.singleton(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC,<span class="integer">1</span>)));
                consumer.seek(<span class="keyword">new</span> TopicPartition(PartitionProducer.TOPIC, <span class="integer">2</span>), <span class="integer">37</span>);
                <span class="keyword">while</span>(!closed.get()) {
                        ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
                        <span class="keyword">for</span>(ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record: records) {
                                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">particion = %2d offset = %5d key = %7s ts = %8s value %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                                                record.partition(),
                                                record.offset(),
                                                record.key(),
                                                <span class="predefined-type">String</span>.valueOf(record.timestamp()),
                                                record.value()
                                                );
                        }
                }
                consumer.close();
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, vamos a ejecutarlo con las siguientes condiciones:</p>
<div class="ulist">
<ul>
<li>
<p>Leemos de la partici√≥n 0 desde el principio.</p>
</li>
<li>
<p>Leemos de la partici√≥n 1 a partir del √∫ltimo registro</p>
</li>
<li>
<p>Leemos de la partici√≥n 2 a partir del offset 600 (Si no tenemos offset 600 no dar√° error y leer√° desde el final).</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">topic = topicSimple partition =  2   offset =   600   key = key[1666]   value = message[1666]
topic = topicSimple partition =  2   offset =   601   key = key[1669]   value = message[1669]
topic = topicSimple partition =  2   offset =   602   key = key[1672]   value = message[1672]
topic = topicSimple partition =  2   offset =   603   key = key[1675]   value = message[1675]
topic = topicSimple partition =  2   offset =   604   key = key[1678]   value = message[1678]
...
topic = topicSimple partition =  0   offset =     0   key =  key[0]   value =   message[0]
topic = topicSimple partition =  0   offset =     1   key =  key[5]   value =   message[5]
topic = topicSimple partition =  0   offset =     2   key =  key[7]   value =   message[7]
topic = topicSimple partition =  0   offset =     3   key =  key[8]   value =   message[8]
...
topic = topicSimple partition =  0   offset =   709   key = key[1959]   value = message[1959]
topic = topicSimple partition =  2   offset =   698   key = key[1960]   value = message[1960]
topic = topicSimple partition =  1   offset =   707   key = key[1961]   value = message[1961]</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_consumer_info">10.5.10. Consumer Info</h4>
<div class="ulist">
<ul>
<li>
<p>Los consumidores poseen informaci√≥n relevante de los topics donde est√°n conectados.</p>
</li>
<li>
<p>Para comprobarlo, creamos la siguiente clase:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.info</span>;

<span class="keyword">import</span> <span class="include">java.util.HashSet</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Map</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.Set</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.Node</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.PartitionInfo</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringDeserializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.simple.SimpleProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">InfoConsumer</span> {
    <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> KAFKA_HOST = <span class="string"><span class="delimiter">&quot;</span><span class="content">localhost:9092</span><span class="delimiter">&quot;</span></span>;
    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });

        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_HOST);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">100</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">info-simple</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);

        <span class="keyword">for</span>(<span class="predefined-type">Map</span>.Entry&lt;<span class="predefined-type">String</span>, <span class="predefined-type">List</span>&lt;PartitionInfo&gt;&gt; entry : consumer.listTopics().entrySet()){
            <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Topic: </span><span class="delimiter">&quot;</span></span> + entry.getKey());
            <span class="keyword">for</span>(PartitionInfo partition : entry.getValue()) {
                <span class="predefined-type">Set</span>&lt;<span class="predefined-type">Integer</span>&gt; replicas = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;();
                <span class="predefined-type">Set</span>&lt;<span class="predefined-type">Integer</span>&gt; inSync = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;&gt;();

                <span class="keyword">for</span>(Node node : partition.replicas()) replicas.add(node.id());
                <span class="keyword">for</span>(Node node : partition.inSyncReplicas()) inSync.add(node.id());

                <span class="predefined-type">System</span>.out.println(<span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">  P: %2s   Leader: %2s   Replicas: %4s   InSync: %4s</span><span class="delimiter">&quot;</span></span>,
                        partition.partition(), partition.leader().id(), replicas, inSync));
            }
        }

        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">---------------------------</span><span class="delimiter">&quot;</span></span>);
        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">---------------------------</span><span class="delimiter">&quot;</span></span>);
        TopicPartition topic = <span class="keyword">new</span> TopicPartition(SimpleProducer.TOPIC, <span class="integer">0</span>);
        <span class="predefined-type">Set</span>&lt;TopicPartition&gt; topics = <span class="keyword">new</span> <span class="predefined-type">HashSet</span>&lt;TopicPartition&gt;();
        topics.add(topic);

        <span class="predefined-type">System</span>.out.println(<span class="predefined-type">String</span>.format(<span class="string"><span class="delimiter">&quot;</span><span class="content">Last offsets for %s : %s</span><span class="delimiter">&quot;</span></span>, topic, consumer.committed(topics)));

        consumer.close();
    }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si ejecutamos, el resultado ser√° el siguiente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Topic: topicSimple
  P:  0   Leader:  2   Replicas:  [2]   InSync:  [2]
  P:  2   Leader:  1   Replicas:  [1]   InSync:  [1]
  P:  1   Leader:  3   Replicas:  [3]   InSync:  [3]
Topic: __consumer_offsets
  P:  0   Leader:  1   Replicas:  [1]   InSync:  [1]
  P: 10   Leader:  2   Replicas:  [2]   InSync:  [2]
  P: 20   Leader:  3   Replicas:  [3]   InSync:  [3]
  ....
---------------------------
---------------------------
Last offsets for topicSimple-0 : {topicSimple-0=null}
Shutting down</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transaccionalidad">10.5.11. Transaccionalidad</h4>
<div class="ulist">
<ul>
<li>
<p>Para comprobar el modelo "exactly-once" de kafka, configuraremos un productor y un consumidor.</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_productor">10.5.11.1. Productor</h5>
<div class="ulist">
<ul>
<li>
<p>Para ello primero creamos un productor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.transactional</span>;

<span class="keyword">import</span> <span class="include">java.io.IOException</span>;
<span class="keyword">import</span> <span class="include">java.util.Arrays</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.Random</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.ExecutionException</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.KafkaProducer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.producer.ProducerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.errors.ProducerFencedException</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.serialization.StringSerializer</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TransactionalProducer</span> {

        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">List</span>&lt;<span class="predefined-type">String</span>&gt; CITIES = <span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">madrid</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">barcelona</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">burgos</span><span class="delimiter">&quot;</span></span>);
        <span class="directive">public</span> <span class="directive">static</span> <span class="predefined-type">String</span> TOPIC = <span class="string"><span class="delimiter">&quot;</span><span class="content">topic-transactions</span><span class="delimiter">&quot;</span></span>;

        <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">IOException</span>, <span class="exception">InterruptedException</span>, <span class="exception">ExecutionException</span> {
                <span class="predefined-type">Properties</span> properties = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
                properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);
                properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
                <span class="comment">// Configuraci√≥n de transacci√≥n.</span>
                properties.put(ProducerConfig.ACKS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">all</span><span class="delimiter">&quot;</span></span>);
                properties.put(ProducerConfig.CLIENT_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
                properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
                properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, TransactionalProducer.class.getName()+TOPIC);
                properties.put(ProducerConfig.RETRIES_CONFIG, <span class="integer">3</span>);
                <span class="comment">// Permite garantizar el orden</span>
                properties.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, <span class="integer">1</span>);
                <span class="comment">//properties.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 600000);</span>

                KafkaProducer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(properties);
                <span class="comment">// Notificaci√≥n de gesti√≥n de transacci√≥nes</span>
                producer.initTransactions();

                <span class="predefined-type">Thread</span> thread = <span class="keyword">new</span> <span class="predefined-type">Thread</span>(producer::close);
                <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(thread);
                <span class="type">int</span> i = <span class="integer">1</span>;
                <span class="predefined-type">Random</span> random = <span class="keyword">new</span> <span class="predefined-type">Random</span>();
                <span class="keyword">while</span> (<span class="predefined-constant">true</span>) {

                        <span class="keyword">try</span> {
                                producer.beginTransaction();
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Inicio de transacci√≥n ...</span><span class="delimiter">&quot;</span></span>);
                                <span class="comment">//HashMap&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = new HashMap&lt;&gt;();</span>
                                <span class="keyword">for</span> (<span class="type">int</span> j = <span class="integer">0</span>; j &lt; <span class="integer">5</span>; j++) {
                                        ProducerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;&gt;(TOPIC,
                                                        CITIES.get(random.nextInt(CITIES.size())), <span class="string"><span class="delimiter">&quot;</span><span class="content">String </span><span class="delimiter">&quot;</span></span> + i++);
                                        <span class="comment">// Garant√≠a s√≠ncrona.</span>
                                        producer.send(record).get();
                                        <span class="comment">//System.out.println(&quot;Metadatos recibidos : &quot; + recordMetadata);</span>
                                        <span class="comment">//partitionsWithOffset.put(new TopicPartition(TOPIC, recordMetadata.partition()), new OffsetAndMetadata(recordMetadata.offset()));</span>
                                        <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Record : </span><span class="delimiter">&quot;</span></span> + record.toString());

                                        <span class="predefined-type">Thread</span>.sleep(<span class="integer">1000</span>);
                                }
                                <span class="comment">//System.out.println(partitionsWithOffset);</span>
                                <span class="comment">//producer.sendOffsetsToTransaction(partitionsWithOffset, &quot;transactionalConsumer&quot;+ TransactionalProducer.TOPIC);</span>
                                producer.commitTransaction();
                                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Transacci√≥n confirmada!</span><span class="delimiter">&quot;</span></span>);
                        } <span class="keyword">catch</span> (ProducerFencedException e) {
                                producer.abortTransaction();
                        }
                }
        }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El productor est√° definido para que envie los mensajes de forma s√≠ncrona con garant√≠a de entrega.</p>
</li>
<li>
<p>Definimos el id de transacci√≥n para que el consumidor pueda usarlo como control de lectura con garant√≠a de entrega.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_consumidor">10.5.11.2. consumidor</h5>
<div class="ulist">
<ul>
<li>
<p>Para el consumidor, necesitamos definir el nivel de aislamiento para que lea solo mensajes confirmados.</p>
</li>
<li>
<p>Para hacer el seguimiento, obtendremos el √∫ltimo offset de cada partici√≥n para confirmar en el pr√≥ximo commit cual es la pr√≥xima posici√≥n a leer</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="keyword">package</span> <span class="namespace">com.curso.kafka.producersconsumers.transactional</span>;

<span class="keyword">import</span> <span class="include">java.time.Duration</span>;
<span class="keyword">import</span> <span class="include">java.util.Collections</span>;
<span class="keyword">import</span> <span class="include">java.util.HashMap</span>;
<span class="keyword">import</span> <span class="include">java.util.List</span>;
<span class="keyword">import</span> <span class="include">java.util.Properties</span>;
<span class="keyword">import</span> <span class="include">java.util.concurrent.atomic.AtomicBoolean</span>;

<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerConfig</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecord</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.ConsumerRecords</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.KafkaConsumer</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.clients.consumer.OffsetAndMetadata</span>;
<span class="keyword">import</span> <span class="include">org.apache.kafka.common.TopicPartition</span>;

<span class="keyword">import</span> <span class="include">com.curso.kafka.producersconsumers.partitioner.PartitionProducer</span>;
<span class="keyword">import</span> <span class="include">com.curso.kafka.util.TopicCreator</span>;

<span class="directive">public</span> <span class="type">class</span> <span class="class">TransactionalConsumer</span> {

    <span class="directive">private</span> <span class="directive">static</span> <span class="directive">final</span> <span class="predefined-type">AtomicBoolean</span> closed = <span class="keyword">new</span> <span class="predefined-type">AtomicBoolean</span>(<span class="predefined-constant">false</span>);<span class="comment">//para cerrar al matar el proceso</span>

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) <span class="directive">throws</span> <span class="exception">InterruptedException</span> {
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(){
            <span class="annotation">@Override</span>
            <span class="directive">public</span> <span class="type">void</span> run() {
                <span class="predefined-type">System</span>.out.println(<span class="string"><span class="delimiter">&quot;</span><span class="content">Shutting down</span><span class="delimiter">&quot;</span></span>);
                closed.set(<span class="predefined-constant">true</span>);
            }
        });
        TopicCreator.createTopics(PartitionProducer.BROKER_LIST, TransactionalProducer.TOPIC);
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, PartitionProducer.BROKER_LIST);

        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">transactionalConsumer</span><span class="delimiter">&quot;</span></span>+ TransactionalProducer.TOPIC);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">org.apache.kafka.common.serialization.StringDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">read_committed</span><span class="delimiter">&quot;</span></span>);<span class="comment">// default &quot;read_uncommitted&quot;</span>
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">false</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">earliest</span><span class="delimiter">&quot;</span></span>);


        KafkaConsumer&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Collections</span>.singletonList(TransactionalProducer.TOPIC));

        <span class="keyword">while</span> (!closed.get()) {
            ConsumerRecords&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; records = consumer.poll(<span class="predefined-type">Duration</span>.ofSeconds(<span class="integer">1</span>));
            <span class="keyword">for</span> (ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; record : records)
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">partition = %2d   offset = %5d   key = %7s timestamp = %8s  value = %12s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>,
                        record.partition(), record.offset(), record.key(), <span class="predefined-type">String</span>.valueOf(record.timestamp()), record.value());
            <span class="predefined-type">HashMap</span>&lt;TopicPartition,OffsetAndMetadata&gt; partitionsWithOffset = <span class="keyword">new</span> <span class="predefined-type">HashMap</span>&lt;&gt;();
            <span class="keyword">for</span> (TopicPartition partition: records.partitions()) {
                    <span class="predefined-type">List</span>&lt;ConsumerRecord&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt;&gt; list = records.records(partition);
                    <span class="type">long</span> offset = list.get(list.size() -<span class="integer">1</span>).offset();
                    partitionsWithOffset.put(partition, <span class="keyword">new</span> OffsetAndMetadata(offset+<span class="integer">1</span>));
            }
            consumer.commitSync(partitionsWithOffset);
        }

        consumer.close();
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_prueba_de_ejecuci√≥n_2">10.5.11.3. Prueba de ejecuci√≥n</h5>
<div class="ulist">
<ul>
<li>
<p>Para ello ejecutaremos el productor y el consumidor (no crearemos particiones en el topic para ver como se mantiene la garant√≠a de entrega y el orden)</p>
</li>
<li>
<p>Veremos como se crear√°n los mensajes de 5 en 5</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Inicio de transacci√≥n ...
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=barcelona, value=<span class="predefined-type">String</span> <span class="integer">2431</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2432</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2433</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=burgos, value=<span class="predefined-type">String</span> <span class="integer">2434</span>, timestamp=<span class="predefined-constant">null</span>)
Record : ProducerRecord(topic=topic-transactions, partition=<span class="predefined-constant">null</span>, headers=RecordHeaders(headers = <span class="type">[]</span>, isReadOnly = <span class="predefined-constant">true</span>), key=barcelona, value=<span class="predefined-type">String</span> <span class="integer">2435</span>, timestamp=<span class="predefined-constant">null</span>)
Transacci√≥n confirmada!</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras la confirmaci√≥n, veremos como el consumidor lee solo los mensajes que se han confirmado, e ignora los dem√°s hasta la pr√≥xima confirmaci√≥n.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">partition =  <span class="integer">0</span>   offset =   <span class="integer">145</span>   key = barcelona timestamp = <span class="integer">1603884353438</span>  value =    <span class="predefined-type">String</span> <span class="integer">52</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">146</span>   key =  madrid timestamp = <span class="integer">1603884354442</span>  value =    <span class="predefined-type">String</span> <span class="integer">53</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">147</span>   key = barcelona timestamp = <span class="integer">1603884355446</span>  value =    <span class="predefined-type">String</span> <span class="integer">54</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">148</span>   key =  madrid timestamp = <span class="integer">1603884356450</span>  value =    <span class="predefined-type">String</span> <span class="integer">55</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">150</span>   key =  burgos timestamp = <span class="integer">1603884357456</span>  value =    <span class="predefined-type">String</span> <span class="integer">56</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">151</span>   key = barcelona timestamp = <span class="integer">1603884358462</span>  value =    <span class="predefined-type">String</span> <span class="integer">57</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">152</span>   key = barcelona timestamp = <span class="integer">1603884359466</span>  value =    <span class="predefined-type">String</span> <span class="integer">58</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">153</span>   key =  burgos timestamp = <span class="integer">1603884360470</span>  value =    <span class="predefined-type">String</span> <span class="integer">59</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">154</span>   key =  madrid timestamp = <span class="integer">1603884361479</span>  value =    <span class="predefined-type">String</span> <span class="integer">60</span>
partition =  <span class="integer">0</span>   offset =   <span class="integer">156</span>   key =  burgos timestamp = <span class="integer">1603884362486</span>  value =    <span class="predefined-type">String</span> <span class="integer">61</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos comprobar en el consumidor como cuando hay un commit desde el controlador, nos saltamos un offset de lectura.</p>
</li>
<li>
<p>Si paramos y levantamos el consumidor, veremos como reinicia en la √∫ltima transacci√≥n no confirmada.</p>
</li>
<li>
<p>Si paramos y levantamos el productor, veremos como aquellos mensajes que no se confirmaron no se podr√°n leer nunca por parte del consumidor, y el productor generar√° nuevas transacciones que el consumidor podr√° leer.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_esquemas_en_kafka">11. Esquemas en Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>La serializaci√≥n es una forma de representar los datos en memoria como conjuntos de bytes para transferencia o almacenamiento en disco</p>
</li>
<li>
<p>La deserializaci√≥n permite realizar la operaci√≥n inversa, convirtiendo los bytes en objetos</p>
</li>
<li>
<p>Kafka posee su propia clase de serializaci√≥n, como hemos visto anteriormente</p>
<div class="ulist">
<ul>
<li>
<p>org.apache.kafka.common.serialization</p>
</li>
</ul>
</div>
</li>
<li>
<p>Sin embargo, el tratamiento de datos de forma simple no es suficiente. La serializaci√≥n en formatos de tipo texto es poco eficinet:</p>
<div class="ulist">
<ul>
<li>
<p>Almacenamiento no eficiente</p>
</li>
<li>
<p>Los datos de tipo no-texto deben pasarse a cadenas</p>
</li>
<li>
<p>Es ineficiente transformar datos de texto a binarios y viceversa</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_tipos_de_serializaci√≥n_en_kafka">11.1. Tipos de serializaci√≥n en kafka</h3>
<div class="ulist">
<ul>
<li>
<p>Existen cuatro tipos de formatos de serializaci√≥n comunes en Apache kafka:</p>
<div class="ulist">
<ul>
<li>
<p>Avro</p>
<div class="ulist">
<ul>
<li>
<p>Es un formato binario, lo que beneficia en tama√±o almacenado la mayor√≠a de las veces</p>
</li>
<li>
<p>No es facilmente entendible, ya que se almacena en binario</p>
</li>
<li>
<p>Posee un esquema conocido.</p>
</li>
<li>
<p>Soporta schema registry y est√° muy integrado con kafka</p>
</li>
</ul>
</div>
</li>
<li>
<p>JSON</p>
<div class="ulist">
<ul>
<li>
<p>No almacena en formato binario</p>
</li>
<li>
<p>Es f√°cil de interpretar</p>
</li>
<li>
<p>No posee un esquema, aunque en los nuevos est√°ndares esto se solucionar√°</p>
</li>
<li>
<p>Sencillo, sin curva de aprendizaje y muy com√∫n</p>
</li>
<li>
<p>No est√° indicado para alto rendimiento.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Protobuf</p>
<div class="ulist">
<ul>
<li>
<p>Almacena en formato binario</p>
</li>
<li>
<p>No es f√°cil de interpretar al ser binario</p>
</li>
<li>
<p>Posee esquema</p>
</li>
<li>
<p>Google Protobuf es altamente eficiente.</p>
</li>
<li>
<p>Uso de gRPC</p>
</li>
</ul>
</div>
</li>
<li>
<p>Thrift</p>
<div class="ulist">
<ul>
<li>
<p>Almacena en formato binario</p>
</li>
<li>
<p>No es f√°cil de interpretar al ser binario</p>
</li>
<li>
<p>Posee esquema</p>
</li>
<li>
<p>Usado por twitter y en las primeras versiones de Apache Cassandra</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Todos ellos son agn√≥sticos a la plataforma y el lenguaje.</p>
</li>
<li>
<p>Sin embargo, aquellos que usan datos binarios permiten compactar los datos, usan esquemas y permiten un alto rendimiento.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_ejemplos_esquemas_idl">11.1.1. Ejemplos Esquemas-IDL</h4>
<div class="listingblock">
<div class="title">Ejemplo JSON - schema.json</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo Proto - schema.proto</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="protobuf">syntax = &quot;proto3&quot;
message UserCommand {
    string command = 1
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo avro - schema.avsc</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="avro">{
    &quot;type&quot;:&quot;string&quot;,
    &quot;name&quot;:&quot;command&quot;
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo thrift schema.thrift</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="thrift">struct UserCommand {
    1: string command
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estos esquemas permiten ce√±irnos a una estructura concreta de datos.</p>
</li>
<li>
<p>Definimos un grano fino de estructuras de datos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_avro">11.2. Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Se trata de un sistema que permite la serializaci√≥n de datos, no es solo un serializador/deserializador</p>
</li>
<li>
<p>Creado por <em>Doug Cutting</em> , el creador de Hadoop</p>
</li>
<li>
<p>Pemite:</p>
<div class="ulist">
<ul>
<li>
<p>Posee estructuras de datos complejas y ricas</p>
</li>
<li>
<p>Uso de datos binarios compactados, ocupando menos espacio en disco y uso menor de red</p>
</li>
<li>
<p>Permite el uso de contenedores, es decir, el fichero contenedor puede almacenar el esquema en la cabecera y el objeto en el resto del mensaje.</p>
</li>
<li>
<p>Permite comunicaci√≥n RPC, puede definir su propio protocolo.</p>
</li>
<li>
<p>Serializaci√≥n de datos</p>
</li>
<li>
<p>Los datos se definen con un esquema</p>
</li>
<li>
<p>Soportado por diversos lenguajes de programaci√≥n</p>
</li>
<li>
<p>Soporta generadores de c√≥digo para los tipos de datos</p>
</li>
<li>
<p>La comprobaci√≥n de tipos se realiza en tiempo de escritura.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_esquemas_de_avro">11.3. Esquemas de Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Los esquemas definen la estructura de datos.</p>
</li>
<li>
<p>Se representan en formato JSON</p>
</li>
<li>
<p>Posee tres formas de creaci√≥n de records</p>
<div class="ulist">
<ul>
<li>
<p><strong>Generic</strong> : Mapeo de cada campo al campo del objeto</p>
</li>
<li>
<p><strong>Reflection</strong> : Generaci√≥n de esquema a partir de una clase java</p>
</li>
<li>
<p><strong>Espec√≠fica</strong> : Generaci√≥n de una clase java para nuestro esquema</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_tipos_de_datos">11.4. Tipos de datos</h3>
<div class="ulist">
<ul>
<li>
<p>Avro soporta dos tipos de datos, primitivos o complejos:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-01.png" alt="kafka esquema 01" width="600">
</div>
<div class="title">Figure 2. Tipos de datos simples</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-02.png" alt="kafka esquema 02" width="600">
</div>
<div class="title">Figure 3. Tipos de datos complejos</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos destacar el tipo de datos fixed que permite almacenar una cadena fija de caracteres, lo que viene muy bien para almacenar hashes en avro.</p>
</li>
<li>
<p>M√°s informaci√≥n de los tipos de datos en:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://avro.apache.org/docs/1.10.0/spec.html" class="bare">https://avro.apache.org/docs/1.10.0/spec.html</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_compactaci√≥n">11.4.1. Compactaci√≥n</h4>
<div class="ulist">
<ul>
<li>
<p>Avro utiliza un sistema de compactaci√≥n para cada tipo de datos primitivo.</p>
</li>
<li>
<p>Para ello usa los siguientes criterios:</p>
<div class="ulist">
<ul>
<li>
<p>null: No almacena datos</p>
</li>
<li>
<p>boolean: bit 0 o 1</p>
</li>
<li>
<p>int/long: Uso de variable-length zig-zag encoding. Lo que le permite no distinguir entre int y long y no reservar ese espacio concreto para cada uno.</p>
</li>
<li>
<p>float/double: Almacenan 32bit IEEE 754 para float y 64bit IEEE 754 para double</p>
</li>
<li>
<p>Binary: En la cabecera almacena el tama√±o como long con zig-zag encoding, y luego los bytes.</p>
</li>
<li>
<p>String: En la cabecera almacena el tama√±o como long con zig-zag encoding, y luego almacena el texto en una cadena codificada en UTF-8</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_integraci√≥n">11.4.2. Integraci√≥n</h4>
<div class="ulist">
<ul>
<li>
<p>Este es un ejemplo de un esquema en Avro.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de esquema en Avro:</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">model</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">SimpleCard</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">fields</span><span class="delimiter">&quot;</span></span>: [
        {
            <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">suit</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The suit of the card</span><span class="delimiter">&quot;</span></span>
        }, {
            <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">card</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>,
            <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The card number</span><span class="delimiter">&quot;</span></span>
        }
    ]
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por defecto, los esquemas se almacenan con extensi√≥n <strong>.avsc</strong> en el directorio src/main/avro</p>
</li>
<li>
<p>El namespace es el paquete java</p>
</li>
<li>
<p>Docs permite indicar comentarios del campo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo con un array y un map</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">cards_list</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">array</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">items</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The cards played</span><span class="delimiter">&quot;</span></span>
},{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">cards_map</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">map</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">values</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The cards played</span><span class="delimiter">&quot;</span></span>
},{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">suit_type</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : {
        <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">enum</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">Suit</span><span class="delimiter">&quot;</span></span>,
        <span class="key"><span class="delimiter">&quot;</span><span class="content">symbols</span><span class="delimiter">&quot;</span></span> : [<span class="string"><span class="delimiter">&quot;</span><span class="content">SPADES</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">HEARTS</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">DIAMONDS</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">CLUBS</span><span class="delimiter">&quot;</span></span>]
    },
    <span class="key"><span class="delimiter">&quot;</span><span class="content">doc</span><span class="delimiter">&quot;</span></span> : <span class="string"><span class="delimiter">&quot;</span><span class="content">The suit of the card</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los esquemas de Avro se pueden actualizar.</p>
</li>
<li>
<p>Permite tambi√©n la compatibilidad mediante esquemas</p>
<div class="ulist">
<ul>
<li>
<p>Retrocompatibilidad:</p>
<div class="ulist">
<ul>
<li>
<p>El c√≥digo con una nueva versi√≥n de esquema puede leer la versi√≥n vieja</p>
</li>
<li>
<p>Los campos no existentes los deja con valores por defecto</p>
</li>
</ul>
</div>
</li>
<li>
<p>Compatibilidad a futuro</p>
<div class="ulist">
<ul>
<li>
<p>Si el c√≥digo recibe nuevos esquemas, los campos nuevos son ingnorados</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_esquemas_en_avro">11.5. Esquemas en Avro</h3>
<div class="ulist">
<ul>
<li>
<p>Si lo que queremos es un tipo primitivo, el esquema que habr√≠a que generar es el siguiente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">string</span><span class="delimiter">&quot;</span></span>
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Como normalmente no es el caso, lo com√∫n es que queramos tipos complejos.</p>
</li>
<li>
<p>Para ello generamos un esquema similar al siguiente</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">E</span><span class="error">s</span><span class="error">q</span><span class="error">u</span><span class="error">e</span><span class="error">m</span><span class="error">a</span><span class="error">C</span><span class="error">o</span><span class="error">m</span><span class="error">p</span><span class="error">l</span><span class="error">e</span><span class="error">j</span><span class="error">o</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">r</span><span class="error">e</span><span class="error">c</span><span class="error">o</span><span class="error">r</span><span class="error">d</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">f</span><span class="error">i</span><span class="error">e</span><span class="error">l</span><span class="error">d</span><span class="error">s</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [ ... ]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>La representaci√≥n del <strong>name</strong> ser√° el nombre de la clase</p>
</li>
<li>
<p>El <strong>namespace</strong> representa el paquete donde se crear√°</p>
</li>
<li>
<p>El <strong>type</strong> indica el tipo de dato a almacenar, en este caso record, que es un tipo complejo.</p>
</li>
<li>
<p>Los <strong>fields</strong> indican los campos, que pueden ser simples o complejos como en el ejemplo.</p>
</li>
<li>
<p>Algunos tipos de datos permiten solucionar problemas b√°sicos como tipos de datos cerrados (Colores, dias de la semana, meses del a√±o, etc)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">d</span><span class="error">i</span><span class="error">a</span><span class="error">s</span><span class="error">D</span><span class="error">e</span><span class="error">L</span><span class="error">a</span><span class="error">S</span><span class="error">e</span><span class="error">m</span><span class="error">a</span><span class="error">n</span><span class="error">a</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">e</span><span class="error">n</span><span class="error">u</span><span class="error">m</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">y</span><span class="error">m</span><span class="error">b</span><span class="error">o</span><span class="error">l</span><span class="error">s</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [</span><span class="delimiter">&quot;</span></span><span class="error">L</span><span class="error">U</span><span class="error">N</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">M</span><span class="error">A</span><span class="error">R</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">M</span><span class="error">I</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">J</span><span class="error">U</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">V</span><span class="error">I</span><span class="error">E</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">S</span><span class="error">A</span><span class="error">B</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">D</span><span class="error">O</span><span class="error">M</span><span class="string"><span class="delimiter">&quot;</span><span class="content">]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Estos campos declarados son obligatorios, sin embargo, es necesario crear campos opcionales, para ello, declaramos el doble tipo:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">c</span><span class="error">a</span><span class="error">m</span><span class="error">p</span><span class="error">o</span><span class="error">O</span><span class="error">p</span><span class="error">c</span><span class="error">i</span><span class="error">o</span><span class="error">n</span><span class="error">a</span><span class="error">l</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: [</span><span class="delimiter">&quot;</span></span><span class="value">null</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,</span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">t</span><span class="error">r</span><span class="error">i</span><span class="error">n</span><span class="error">g</span><span class="string"><span class="delimiter">&quot;</span><span class="content">]
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En este caso, el campo puede ser o no declarados</p>
</li>
<li>
<p>Si queremos por ejemplo, crear un campo con un tama√±o concreto para un campo, como un hash md5, usamos fixed</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json">{
    <span class="key"><span class="delimiter">&quot;</span><span class="content">name</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">Esquema</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">namespace</span><span class="delimiter">&quot;</span></span>:<span class="string"><span class="delimiter">&quot;</span><span class="content">com.curso.kafkaapp.model.avro</span><span class="delimiter">&quot;</span></span>,
    <span class="key"><span class="delimiter">&quot;</span><span class="content">type</span><span class="delimiter">&quot;</span></span>: <span class="string"><span class="delimiter">&quot;</span><span class="content">record</span><span class="delimiter">&quot;</span></span>,
    <span class="string"><span class="delimiter">&quot;</span><span class="content">fields: [
        {
            </span><span class="delimiter">&quot;</span></span><span class="error">n</span><span class="error">a</span><span class="error">m</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">:</span><span class="delimiter">&quot;</span></span><span class="error">c</span><span class="error">a</span><span class="error">m</span><span class="error">p</span><span class="error">o</span><span class="error">F</span><span class="error">i</span><span class="error">x</span><span class="error">e</span><span class="error">d</span><span class="error">P</span><span class="error">a</span><span class="error">r</span><span class="error">a</span><span class="error">M</span><span class="error">d</span><span class="integer">5</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">t</span><span class="error">y</span><span class="error">p</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: </span><span class="delimiter">&quot;</span></span><span class="error">f</span><span class="error">i</span><span class="error">x</span><span class="error">e</span><span class="error">d</span><span class="string"><span class="delimiter">&quot;</span><span class="content">,
            </span><span class="delimiter">&quot;</span></span><span class="error">s</span><span class="error">i</span><span class="error">z</span><span class="error">e</span><span class="string"><span class="delimiter">&quot;</span><span class="content">: 16
        },
        ...
    ]
}</span></span></code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_schema_registry">12. Schema Registry</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Si analizamos los anteriores laboratorios, podemos ver como tenemos un acoplamiento entre el productor y el consumidor.</p>
</li>
<li>
<p>Este acomplamiento en ecosistemas m√°s complejos no es adecuado, lo que impide un correcto desacomplamiento.</p>
</li>
<li>
<p>Para solucionar ese problema tenemos el <strong>Schema Registry</strong></p>
</li>
<li>
<p>Este registro permite:</p>
<div class="ulist">
<ul>
<li>
<p>Reforzar los contratos</p>
</li>
<li>
<p>Permite gestionar la evoluci√≥n de los contratos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Este producto no es totalmente p√∫blico ya que pertenece a Confluent.</p>
</li>
<li>
<p>La licencia de uso indica que se puede acceder al c√≥digo fuente, modificar y distribuir mientras no se haga competencia de los servicios SaaS que ofrece Confluent.</p>
</li>
<li>
<p>Todo esto pasa de forma transparente. Lo √∫nico que hay que hacer es publicar el serializador y deserializador usando:</p>
<div class="ulist">
<ul>
<li>
<p>KakaAvroSerializer</p>
</li>
<li>
<p>KafkaAvroDeserializer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Por otro lado, el registro necesita almacenar la informaci√≥n en un topic como persistencia.</p>
</li>
<li>
<p>El Schema Registry tiene un productor que envia los esquemas y un consumidor para obtener los que ten√≠a previamente.</p>
</li>
<li>
<p>Se llama __schemas</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_integraci√≥n_de_datos">12.1. Integraci√≥n de datos</h3>
<div class="ulist">
<ul>
<li>
<p>Para integrar los datos, avro usa un esquema.</p>
</li>
<li>
<p>En Kafka debemos pensar que cientos de productores se conectan a kafka con un esquema propio y cientos de consumidores lo usan para deserializar los datos.</p>
</li>
<li>
<p>En resumen, al menos un esquema es usado por un productor y un consumidor.</p>
</li>
<li>
<p>Para solucionar el problema, usamos un repositorio de esquemas centralizado.</p>
</li>
<li>
<p>Propietario de Confluent</p>
</li>
<li>
<p>Provee de un sistema centralizado de gesti√≥n de esquemas</p>
</li>
<li>
<p>Posee una interfaz RESTful para almacenamiento y obtenci√≥n de esquemas Avro</p>
</li>
<li>
<p>Comprobaci√≥n de esquemas y lanzamiento de excepciones si los datos no cumplen el esquema</p>
</li>
<li>
<p>Permite la mejora de los esquemas seg√∫n su configuraci√≥n de compatibilidad.</p>
</li>
<li>
<p>Permite evitar mandar el esquema en cada mensaje</p>
</li>
<li>
<p>El registro almacena la informaci√≥n en un topic de Kafka</p>
</li>
<li>
<p>Es posible acceder al registro via API Rest o API Java.</p>
</li>
<li>
<p>Posee herramientas de l√≠nea de comandos</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_flujo_de_trabajo">12.2. Flujo de trabajo</h3>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-esquema-03.png" alt="kafka esquema 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Los mensajes clave y valor se serializan de forma independiente</p>
</li>
<li>
<p>Los productores serializan los datos y usan preferentemente el ID de esquema</p>
</li>
<li>
<p>Los consumidores usan el id de esquema para deserializar los datos</p>
</li>
<li>
<p>Los esquemas son cacheados en productores y consumidores y solo mandan el id del esquema</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_ejemplos_2">12.3. Ejemplos</h3>
<div class="ulist">
<ul>
<li>
<p>Soporte de los clientes para el <em>Schema Registry</em></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(KafkaAvroSerializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Productor Avro</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Configuraci√≥n de clases de serializaci√≥n</span>
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
    io.confluent.kafka.serializers.KafkaAvroSerializer.class);
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
    io.confluent.kafka.serializers.KafkaAvroSerializer.class);
<span class="comment">// Ruta al Schema Registry</span>
props.put(KafkaAvroSerializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Creando productor</span>
KafkaProducer&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt; avroProducer = <span class="keyword">new</span> KafkaProducer&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt;(props);
<span class="comment">// Creando objetos Avro</span>
CardSuit suit = <span class="keyword">new</span> CardSuit(<span class="string"><span class="delimiter">&quot;</span><span class="content">spades</span><span class="delimiter">&quot;</span></span>);
SimpleCard card = <span class="keyword">new</span> SimpleCard(<span class="string"><span class="delimiter">&quot;</span><span class="content">spades</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">ace</span><span class="delimiter">&quot;</span></span>);
<span class="comment">// Creando el ProducerRecord con objetos Avro</span>
ProducerRecord&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt; record = <span class="keyword">new</span> ProducerRecord&lt;<span class="predefined-type">Object</span>, <span class="predefined-type">Object</span>&gt;(<span class="string"><span class="delimiter">&quot;</span><span class="content">my_avro_topic</span><span class="delimiter">&quot;</span></span>, suit, card);
avroProducer.send(record);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Consumidor Avro</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">CardConsumer</span> {
    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args){
        <span class="predefined-type">Properties</span> props = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">testgroup</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,<span class="string"><span class="delimiter">&quot;</span><span class="content">io.confluent.kafka.serializers.KafkaAvroDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,<span class="string"><span class="delimiter">&quot;</span><span class="content">io.confluent.kafka.serializers.KafkaAvroDeserializer</span><span class="delimiter">&quot;</span></span>);
        props.put(KafkaAvroDeserializerConfig.SCHEMA_REGISTRY_URL_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">http://localhost:8081</span><span class="delimiter">&quot;</span></span>);
                props.put(KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">true</span><span class="delimiter">&quot;</span></span>);
        KafkaConsumer&lt;CardSuit, SimpleCard&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);
        consumer.subscribe(<span class="predefined-type">Arrays</span>.asList(<span class="string"><span class="delimiter">&quot;</span><span class="content">my_avro_topic</span><span class="delimiter">&quot;</span></span>));
        <span class="keyword">while</span>(<span class="predefined-constant">true</span>){
            ConsumerRecords&lt;CardSuit, SimpleCard&gt; records = consumer.poll(<span class="integer">100</span>);
            <span class="keyword">for</span> (ConsumerRecord&lt;CardSuit, SimpleCard&gt; record : records) {
                <span class="predefined-type">System</span>.out.printf(<span class="string"><span class="delimiter">&quot;</span><span class="content">offset = %d, key = %s, value = %s</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>, record.offset(), record.key().getSuit(), record.value().getCard());
            }
        }
    }
}</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_estrategias_de_nombres">12.4. Estrategias de nombres.</h3>
<div class="ulist">
<ul>
<li>
<p>Cuando un productor almacena un nuevo esquema, por defecto utiliza la estrategia de indicar en que campo disponible del topic se puede almacenar.</p>
</li>
<li>
<p>Entre ellos est√°:</p>
<div class="ulist">
<ul>
<li>
<p>key</p>
</li>
<li>
<p>value</p>
</li>
</ul>
</div>
</li>
<li>
<p>En el caso de que se almacene en el value, el nombre ser√≠a:</p>
<div class="ulist">
<ul>
<li>
<p>&lt;topic&gt;-value</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existen tres tipos:</p>
<div class="ulist">
<ul>
<li>
<p><strong>Topic Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>&lt;topic_name&gt;-key</p>
</li>
<li>
<p>&lt;topic_name&gt;-value</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Record Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>Se utiliza el nombre completo del esquema (Fully Qualified Schema Name), namespace+name</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Topic Record Name Strategy</strong></p>
<div class="ulist">
<ul>
<li>
<p>Es una mezcla de los dos, donde se usa el &lt;topic_name&gt; seguido del nombre completo del esquema</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Por defecto se usa el Topic Name Strategy</p>
</li>
<li>
<p>Sin embargo, para casos de un solo topic, podemos usar tambi√©n el <strong>Record Name Strategy</strong></p>
</li>
<li>
<p>En el caso de que tengamos distintos tipos de records, podemos usar Record Name Strategy o Topic Record Name Stategy, la cual es m√°s compleja de usar que las dem√°s.</p>
</li>
<li>
<p>En este √∫ltimo caso, no se podr√≠a usar el Topic Name Strategy</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_streams_api">13. Kafka Streams API</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Permite transformar y enriquecer los datos</p>
<div class="ulist">
<ul>
<li>
<p>Soporte de procesado de streams con latencias de milisegundos sin estado.</p>
</li>
<li>
<p>Soporte de procesado de streams por ventana con estado.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Posee tolerancia a fallos y soporte de procesamiento distribuido</p>
</li>
<li>
<p>Posee su propio DSL</p>
<div class="ulist">
<ul>
<li>
<p>Con operaciones comunes como map, flatMap, count, etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Existen implementaciones en diversos lenguajes.</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_caracter√≠sticas">13.1. Caracter√≠sticas</h3>
<div class="ulist">
<ul>
<li>
<p>Posee capacidades de streaming</p>
</li>
<li>
<p>No requiere su propio cluster, se trata de una librer√≠a</p>
</li>
<li>
<p>Puede ejecutarse en una o m√∫ltiples m√°quinas</p>
</li>
<li>
<p>Se trata de una implementaci√≥n concreta de Productor/Consumidor</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_streams">13.2. Streams</h3>
<div class="ulist">
<ul>
<li>
<p>Un stream es un flujo de registros cont√≠nuo</p>
<div class="ulist">
<ul>
<li>
<p>No pedimos registros, sino que nos llegan</p>
</li>
</ul>
</div>
</li>
<li>
<p>Los registros son de tipo clave&#8594;valor</p>
</li>
<li>
<p>Un procesador de streams transforma los datos en streams</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_kstreams_y_ktables">13.3. KStreams y KTables</h3>
<div class="sect3">
<h4 id="_kstream">13.3.1. KStream</h4>
<div class="ulist">
<ul>
<li>
<p>Un KStream es una abstracci√≥n de un stream de record</p>
</li>
<li>
<p>Se pueden interpretar como inserts continuos.</p>
</li>
<li>
<p>Ningun record reemplaza el anterior.</p>
</li>
<li>
<p>Puede ser util para operaciones de tipo serverLog.</p>
<div class="ulist">
<ul>
<li>
<p>Cada record representa un trozo de datos autocontenido</p>
</li>
<li>
<p>Ejemplo, (1,1) (1,2) &#8594; Como KStream su resultado podr√≠a ser 3 para id 1, ya que se tienen en cuenta todos los datos.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_ktable">13.3.2. KTable</h4>
<div class="ulist">
<ul>
<li>
<p>Un KTable es una abstracci√≥n de un stream changelog.</p>
</li>
<li>
<p>Se puede interpretar como un Upsert. (Si no existe, es Insert, si existe es Update)</p>
<div class="ulist">
<ul>
<li>
<p>Cada record representa una actualizaci√≥n</p>
</li>
<li>
<p>Ejemplo, (1,1) (1,2) &#8594; Como KTable, se trata de una actualizaci√≥n del primero, luego para el id 1, su valor es el √∫ltimo, 2.</p>
</li>
<li>
<p>Para KTables es l√≥gico activar el <em>Log Compaction</em> en el topic asociado, ya que solo importa el √∫ltimo valor por caada key.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_gobalktable">13.3.3. GobalKTable</h4>
<div class="ulist">
<ul>
<li>
<p>Representa una abstracci√≥n de un stream de changelog.</p>
</li>
<li>
<p>Permite compartir la informaci√≥n del global KTable con hilos.</p>
</li>
<li>
<p>Si usaramos KTable, cada instancia tendr√≠a su propio KTable.</p>
</li>
<li>
<p>Con GlobalKTable garantizamos que la informaci√≥n es compartida por todos los hilos.</p>
</li>
<li>
<p>Muy util para uso de joins, ya que podemos buscar tanto por claves como por valores, y adem√°s no tiene porqu√© estar co-particionados.</p>
</li>
<li>
<p>Incrementa el consumo de almacenamiento local comparado con el particionado.</p>
</li>
<li>
<p>Incrementa el consumo de red y de los brokers de kafka, ya que lee el topic completo.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ventanas_windows">13.4. Ventanas (Windows)</h3>
<div class="ulist">
<ul>
<li>
<p>Hay que tener en cuenta que el API de streams de Kafka se basa en ventanes de tiempo.</p>
</li>
<li>
<p>Los datos se dividen en buckets temporales</p>
</li>
<li>
<p>Podemos realizar agregaciones en lo records, como sum o count.</p>
</li>
<li>
<p>Podemos realizar join, merge para distintos sources.</p>
</li>
<li>
<p>Existen distintos tipos de windows:</p>
<div class="ulist">
<ul>
<li>
<p>Tumbling: Es de tama√±o fijo, no se solapan las ventanas de tiempo, no genera espacios entre ventanas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).advanceBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hopping: Tama√±o fijo, Las ventanas se solapan</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).advanceBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">1</span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Sliding: Tama√±o fijo, ventanas solapadas que trabaja con diferencias entre los timestamps de los records. Solo se usan en operaciones de tipo Join, por medio de la clase JoinWindows.</p>
</li>
<li>
<p>Session: Tama√±o din√°mico. Sin solapamiento, ventana gestionada por datos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>));</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_transformaciones">13.5. Transformaciones</h3>
<div class="ulist">
<ul>
<li>
<p>Los datos pueden transformarse usando distintos operadores</p>
</li>
<li>
<p>Algunos operadores devuelven un objeto KStream, como filter o map</p>
</li>
<li>
<p>Otros devuelven KTables, como agregaciones</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_transformaciones_sin_estado">13.5.1. Transformaciones sin estado</h4>
<div class="ulist">
<ul>
<li>
<p><strong>branch</strong>: Permite dividir un KStream en varios KStreams seg√∫n un predicado definido. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt;<span class="type">[]</span> branches = stream.branch(
    (key, value) -&gt; key.equals(<span class="string"><span class="delimiter">&quot;</span><span class="content">MADRID</span><span class="delimiter">&quot;</span></span>), <span class="comment">// KStream con los datos de clave madrid</span>
    (key, value) -&gt; key.equals(<span class="string"><span class="delimiter">&quot;</span><span class="content">BURGOS</span><span class="delimiter">&quot;</span></span>), <span class="comment">// KStream con los datos de burgos</span>
    (key, value) -&gt; <span class="predefined-constant">true</span>                <span class="comment">// KStream con todo lo dem√°s</span>
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>filter</strong>: Creaci√≥n de un KStream con records que cumplan criterios concretos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; masDe30 = stream.filter((key, value) -&gt; value.getDatos().getTemp() &gt; <span class="integer">30</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Todos los datos con temperatura mayor de 30¬∫</p>
</li>
<li>
<p><strong>inverseFilter</strong>: Funci√≥n booleana que rechaza todos los datos que devuelvan true</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; menosOIgualA30 = stream.filterNot((key, value) -&gt; value.getDatos().getTemp() &gt; <span class="integer">30</span>);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>flatMap</strong>:  Creaci√≥n de un KStream transformando cada elemento en 0, 1 o m√°s elementos en el nuevo stream. Se permite la modificaci√≥n de las claves y valores incluidos sus tipos de datos. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Integer</span>&gt; transformed = stream.flatMap(
    (key, value) -&gt; {
      <span class="predefined-type">List</span>&lt;KeyValue&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Integer</span>&gt;&gt; result = <span class="keyword">new</span> <span class="predefined-type">LinkedList</span>&lt;&gt;();
      result.add(KeyValue.pair(value.getDatos().getName()+<span class="string"><span class="delimiter">&quot;</span><span class="content">Max</span><span class="delimiter">&quot;</span></span>, value.getDatos().getTempMax()));
      result.add(KeyValue.pair(value.getDatos().getName()+<span class="string"><span class="delimiter">&quot;</span><span class="content">Min</span><span class="delimiter">&quot;</span></span>), value.getDatos().getTempMin()));
      <span class="keyword">return</span> result;
    }
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>flatMapValues</strong>:  Creaci√≥n de un KStream transformando cada valor de cada elemento en 0 o 1 elemento distintos en el stream nuevo. Solo modifica el valor, manteniendo la clave. Solo para KStreams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">datos.flatMapValues(value -&gt; value.getDatos());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Foreach</strong>: Permite una operaci√≥n sin estado en cada record. Es una operaci√≥n final, es decir, no devuelve un kstream o un ktable.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.foreach((key, value) -&gt; <span class="predefined-type">System</span>.out.println(key + <span class="string"><span class="delimiter">&quot;</span><span class="content"> =&gt; temp: </span><span class="delimiter">&quot;</span></span> + value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>GroupByKey</strong>: Agrupa records por claves (Para KStreams y KGroupedStreams)</p>
<div class="ulist">
<ul>
<li>
<p>Es un prerrequisito para agregaciones. Permite reparticionar si se marca explicitamente para ello.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KGroupedStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; streamGrouped = stream.groupByKey();
KGroupedStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; groupedStream = stream.groupByKey(
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>GroupBy</strong>: Permite agrupar records por una nueva clave que puede ser de un tipo distinto.</p>
<div class="ulist">
<ul>
<li>
<p>Al agrupar una tabla, se debe especificar el valor y el tipo</p>
</li>
<li>
<p>Equivalente a selectKey().groupByKey()</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KGroupedStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; groupedStream = stream.groupBy(
    (key, value) -&gt; value,
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );

KGroupedTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Float</span>&gt; groupedTable = table.groupBy(
    (key, value) -&gt; KeyValue.pair(value, value.getDatos().getTemp()),
    Serialized.with(
      Serdes.String(),
      Serdes.Float())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>map</strong>: Creaci√≥n de un KStream transformando cada elemento en otro distinto en el nuevo stream</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; transformed = stream.map(
    (key, value) -&gt; KeyValue.pair(value.getName().toUpperCase(), value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>mapValues</strong>:  Creaci√≥n de un KStream transformando el valor de cada elemento en otro elemento distinto, pero solo modifica el valor</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>stream.mapValues(value &#8594; value.getDatos());</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Peek</strong>: Realiza una acci√≥n sin estado por cada record y devuelve un stream intacto. Similar a forEachm pero no finaliza.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; noModificado = stream.peek((key, value) -&gt; <span class="predefined-type">System</span>.out.println(key + <span class="string"><span class="delimiter">&quot;</span><span class="content"> =&gt; temp: </span><span class="delimiter">&quot;</span></span> + value.getDatos().getTemp()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Print</strong>: Operaci√≥n terminal. Permite mostrar los records por la salida est√°ndar. √ötil para desarrollo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.print(Printed.toFile(<span class="string"><span class="delimiter">&quot;</span><span class="content">salida.txt</span><span class="delimiter">&quot;</span></span>).withLabel(<span class="string"><span class="delimiter">&quot;</span><span class="content">a-topic-nuevo</span><span class="delimiter">&quot;</span></span>));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>SelectKey: Asigna una nueva key</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.selectKey((key, value) -&gt; value.getName())</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de Stateless Processing</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="directive">public</span> <span class="type">class</span> <span class="class">SimpleStreamsExample</span> {

    <span class="directive">public</span> <span class="directive">static</span> <span class="type">void</span> main(<span class="predefined-type">String</span><span class="type">[]</span> args) throwsException {
        <span class="predefined-type">Properties</span> streamsConfiguration = <span class="keyword">new</span> <span class="predefined-type">Properties</span>();
        <span class="comment">// Aplicaci√≥n con nombre √∫nico obligatorio para el cluster de Kafka</span>
        streamsConfiguration.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">ejemplo-sencillo</span><span class="delimiter">&quot;</span></span>);
        streamsConfiguration.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">broker1:9092</span><span class="delimiter">&quot;</span></span>);
        streamsConfiguration.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string"><span class="delimiter">&quot;</span><span class="content">earliest</span><span class="delimiter">&quot;</span></span>);
        <span class="comment">// Serializadores y deserializadores</span>
        streamsConfiguration.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.ByteArray().getClass());
        streamsConfiguration.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        <span class="comment">// Transformaci√≥n de datos y ejecuci√≥n</span>
        StreamsBuilder builder = <span class="keyword">new</span> StreamsBuilder();

        <span class="comment">// KStream desde el topic mi-topic-a-stream</span>
        KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; textLines = builder.stream(<span class="string"><span class="delimiter">&quot;</span><span class="content">mi-topic-a-stream</span><span class="delimiter">&quot;</span></span>);

        <span class="comment">// UpperCase del KStream</span>
        KStream&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">String</span>&gt; uppercasedWithMapValues = textLines.mapValues(<span class="predefined-type">String</span>::toUpperCase);

        <span class="comment">// envio a un nuevo topic &quot;mi-stream-a-topic&quot;</span>
        uppercasedWithMapValues.to(<span class="string"><span class="delimiter">&quot;</span><span class="content">mi-stream-a-topic</span><span class="delimiter">&quot;</span></span>);

        <span class="comment">// Inicio de la aplicaci√≥n</span>
        KafkaStreams streams = <span class="keyword">new</span> KafkaStreams(builder.build(), streamsConfiguration);
        streams.start();

        <span class="comment">//Apagado suave</span>
        <span class="predefined-type">Runtime</span>.getRuntime().addShutdownHook(<span class="keyword">new</span> <span class="predefined-type">Thread</span>(streams::close));
    }
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_transformaciones_con_estado">13.5.2. Transformaciones con estado</h4>
<div class="ulist">
<ul>
<li>
<p>Las transformaciones con estado dependen del estado para procesar entradas y producir saldas.</p>
</li>
<li>
<p>Debe poseer un state store asociado al procesador de stream.</p>
</li>
<li>
<p>Estos almacenes permiten ser tolerantes a fallos</p>
</li>
<li>
<p>Las transformaciones disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>agregaciones</p>
</li>
<li>
<p>joins</p>
</li>
<li>
<p>windows</p>
</li>
<li>
<p>transformaciones personalizadas</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para saber como se pueden utilizar cada uno de los objetos, podemos ver el siguiente diagrama</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-streams-01.png" alt="kafka streams 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>aggregate</strong>: Permite agregar los valores de records por medio de la clave agrupada. Es una generalizaci√≥n del Reduce y permite tener diferentes tipos a los valores de entrada.</p>
<div class="ulist">
<ul>
<li>
<p>Se usa con KGroupedStream y KGroupedTable devolviendo un KTable</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">Long</span>&gt; streamAgregado = groupedStream.aggregate(
    () -&gt; <span class="integer">0L</span>,
    (aggKey, newValue, aggValue) -&gt; aggValue + newValue.length(),
    Materialized.as(<span class="string"><span class="delimiter">&quot;</span><span class="content">aggregated-stream-store</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long());

KTable&lt;<span class="type">byte</span><span class="type">[]</span>, <span class="predefined-type">Long</span>&gt; TablaAgregada = groupedTable.aggregate(
    () -&gt; <span class="integer">0L</span>,
    (aggKey, newValue, aggValue) -&gt; aggValue + newValue.length(),
    (aggKey, oldValue, aggValue) -&gt; aggValue - oldValue.length(),
    Materialized.as(<span class="string"><span class="delimiter">&quot;</span><span class="content">aggregated-table-store</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long())</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Las claves nulas son ignoradas</p>
</li>
<li>
<p>Al recibir el primer record, se inicializa el valor de agregaci√≥n en el caso de KStreams, en KTables se ejecuta luego la funci√≥n</p>
</li>
<li>
<p>Al recibir un record con valor, se llama a la funci√≥n lambda declarada.</p>
<div class="ulist">
<ul>
<li>
<p><strong>Agregaci√≥n (Windowed)</strong></p>
<div class="ulist">
<ul>
<li>
<p>Agrega los valores de los records por window, por la clave de grupo.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; StreamWindowed = groupedStream.windowedBy(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>))
    .aggregate(
        () -&gt; <span class="integer">0L</span>,
        (aggKey, newValue, aggValue) -&gt; aggValue + newValue,
        Materialized.&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>, WindowStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(<span class="string"><span class="delimiter">&quot;</span><span class="content">miStoreWindow</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long()));
KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; sessionizedAggregatedStream = groupedStream.windowedBy(SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)).
    aggregate(
            () -&gt; <span class="integer">0L</span>,
            (aggKey, newValue, aggValue) -&gt; aggValue + newValue,
        (aggKey, leftAggValue, rightAggValue) -&gt; leftAggValue + rightAggValue,
        Materialized.&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>, SessionStore&lt;Bytes, <span class="type">byte</span><span class="type">[]</span>&gt;&gt;as(<span class="string"><span class="delimiter">&quot;</span><span class="content">MiStoreSession</span><span class="delimiter">&quot;</span></span>)
        .withValueSerde(Serdes.Long()));</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Count</strong>: Cuenta el n√∫mero de records por clave agrupada. Necesita un KGroupedStream o un KGroupedTable</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.count();

KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedTable = groupedTable.count();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Count (Windowed)</strong>: Realiza la misma operaci√≥n en una ventana de tiempo.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.windowedBy(
    TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
    .count();

KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.windowedBy(
    SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
    .count();</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Reduce</strong>: Combina los valores de los records por una clave agregada.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedStream = groupedStream.reduce(
    (aggValue, newValue) -&gt; aggValue + newValue);
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; aggregatedTable = groupedTable.reduce(
    (aggValue, newValue) -&gt; aggValue + newValue,
    (aggValue, oldValue) -&gt; aggValue - oldValue);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Reduce (Windowed)</strong>: Combina los valores de los records por windows y por clave agrupada.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; timeWindowedAggregatedStream = groupedStream.windowedBy(
  TimeWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
  .reduce(
    (aggValue, newValue) -&gt; aggValue + newValue
  );

KTable&lt;Windowed&lt;<span class="predefined-type">String</span>&gt;, <span class="predefined-type">Long</span>&gt; sessionzedAggregatedStream = groupedStream.windowedBy(
  SessionWindows.with(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)))
  .reduce(
    (aggValue, newValue) -&gt; aggValue + newValue
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Join:</p>
</li>
<li>
<p>Los streams y las tablas pueden realizar las operaciones de Join.</p>
</li>
<li>
<p>* Las operaciones que se pueden realizar son:</p>
<div class="ulist">
<ul>
<li>
<p>KStream-KStream</p>
</li>
<li>
<p>KStream-KTable</p>
</li>
<li>
<p>KStream-GlobalKTable</p>
</li>
<li>
<p>KTable-GlobalKTable</p>
</li>
</ul>
</div>
</li>
<li>
<p>Como condici√≥n, los joins deben estar co-particionados, es decir, que poseen la misma partici√≥n para poder hacer el join.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KeyValue&lt;K, JV&gt; joinOutputRecord = KeyValue.pair(
    leftRecord.key,
    joiner.apply(leftRecord.value, rightRecord.value)
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Inner join: Permite obtener solo los datos cuyas claves coincidan en ambos streams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(), <span class="comment">/* key */</span>
      Serdes.Long(),   <span class="comment">/* left value */</span>
      Serdes.Double())  <span class="comment">/* right value */</span>
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );
<span class="comment">// KStream + KTable</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.join(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue, /
    Joined.keySerde(Serdes.String())
      .withValueSerde(Serdes.Long())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Left Join: Permite mantener las claves del primer stream y unir solo con las claves del segundo stream, ignorando las claves del segundo stream que no coincidan.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(),
      Serdes.Long(),
      Serdes.Double())
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );
<span class="comment">// KStream + KTable</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.leftJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    Joined.keySerde(Serdes.String())
      .withValueSerde(Serdes.Long())
  );</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>OuterJoin: Permite mantenre las claves de ambos streams</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">// KStream + KStream</span>
KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.outerJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue,
    JoinWindows.of(<span class="predefined-type">TimeUnit</span>.MINUTES.toMillis(<span class="integer">5</span>)),
    Joined.with(
      Serdes.String(),
      Serdes.Long(),
      Serdes.Double())
  );
<span class="comment">// KTable + KTable</span>
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; joined = left.outerJoin(right,
    (leftValue, rightValue) -&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">left=</span><span class="delimiter">&quot;</span></span> + leftValue + <span class="string"><span class="delimiter">&quot;</span><span class="content">, right=</span><span class="delimiter">&quot;</span></span> + rightValue
  );</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_salida_de_datos">13.6. Salida de datos</h3>
<div class="ulist">
<ul>
<li>
<p>En kafka, el resultado de un KStream o un KTable se envia a Kafka de nuevo.</p>
</li>
<li>
<p>Para ello usamos los siguientes m√©todos:</p>
<div class="ulist">
<ul>
<li>
<p>To: Operaci√≥n terminal. Devuelve a un topic los registros. Se puede implementar como se producen los mensajes:</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">stream.to(<span class="string"><span class="delimiter">&quot;</span><span class="content">topic-salida</span><span class="delimiter">&quot;</span></span>, Produced.with(Serdes.String(), Serdes.Long());</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Through: Permite enviar los datos a un topic y continuar con un stream.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">KStream&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; newStream = stream.through(<span class="string"><span class="delimiter">&quot;</span><span class="content">mitopic</span><span class="delimiter">&quot;</span></span>).map(...);
KTable&lt;<span class="predefined-type">String</span>, <span class="predefined-type">Long</span>&gt; newTable = table.through(<span class="string"><span class="delimiter">&quot;</span><span class="content">mitopic</span><span class="delimiter">&quot;</span></span>).map(...);</code></pre>
</div>
</div>
<div style="page-break-after: always;"></div>
</div>
<div class="sect2">
<h3 id="_estado_en_streams">13.7. Estado en Streams</h3>
<div class="ulist">
<ul>
<li>
<p>Hasta ahora hemos estado trabajando en desarrollos sin estado</p>
</li>
<li>
<p>Sin embargo, una de las grandes utilidades en kafka es el uso con estado.</p>
</li>
<li>
<p>Permite mejorar la informaci√≥n recolectada por la aplicaci√≥n</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_transform_processor">13.7.1. Transform Processor</h4>
<div class="ulist">
<ul>
<li>
<p>Se trata de la funci√≥n m√°s simple con estado de los KStreams</p>
</li>
<li>
<p><strong>KStream.transformValues()</strong></p>
</li>
<li>
<p>Es el mismo que mapValues() pero, en este caso, accede al <strong>StateStore</strong> para completar la tarea.</p>
</li>
<li>
<p>Permite tambi√©n programar tareas pare que se ejecuten a intervalos por medio del m√©todo <strong>punctuate()</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-streams-state-01.png" alt="kafka streams state 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por medio del almacenamiento local podemos actualizar la informaci√≥n de los records.</p>
</li>
<li>
<p>Como ejemplo, podr√≠amos acumular la informaci√≥n de un cliente para ver cuanto se ha gastado.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kafka_connect">14. Kafka Connect</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>Se trata de un framework para envio de flujos de datos entre Kafka y otros sistemas</p>
</li>
<li>
<p>Open Source y forma parte de la distribuci√≥n de Apacha Kafka</p>
</li>
<li>
<p>Simple, escalable y seguro</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-connect-01.png" alt="kafka connect 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Permite streams de bases de datos SQL en kafka</p>
</li>
<li>
<p>Permite streams de kafka topics en HDFS para procesado en streams</p>
</li>
<li>
<p>Permite streams de topics en ElasticSearch para indexados</p>
</li>
<li>
<p>B√°sicamente, usa la misma filosof√≠a de productor y consumidor para los clientes de Kafka Connect.</p>
</li>
<li>
<p>Se trata de clientes preconstruidos para realizar conexiones sencillas</p>
</li>
<li>
<p>Pueden ser extendidas por programadores</p>
</li>
<li>
<p>Los conectores son Jobs l√≥gicos que gestionan la ingesta de datos entre kafka y otro sistema</p>
<div class="ulist">
<ul>
<li>
<p><strong>Connector sources</strong>: Leen datos de una fuente externa y lo inyectan en kafka (Productor)</p>
</li>
<li>
<p><strong>Connector Sinks</strong>: Escriben datso de kafka en un sistema de datos externo (Consumidor)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_tipos">14.1. Tipos</h3>
<div class="ulist">
<ul>
<li>
<p>La versi√≥n Opensource de Confluent provee de los siguientes conectores:</p>
<div class="ulist">
<ul>
<li>
<p>JDBC: Envio de filas nuevas o modificadas en mensajes kafka</p>
</li>
<li>
<p>HDFS: Envio de kafka a Hadoop Distributed File System. Integrado con Hive, y soporte de particiones</p>
</li>
<li>
<p>Elasticsearch</p>
</li>
<li>
<p>AWS S3</p>
</li>
<li>
<p>FileStream: Obtenci√≥n del fin de fichero como un kafka message (logs), o viceversa, mensajes kafka a un fichero</p>
</li>
</ul>
</div>
</li>
<li>
<p>La versi√≥n enterprise</p>
<div class="ulist">
<ul>
<li>
<p>Replicator</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_modos_de_ejecuci√≥n">14.2. Modos de ejecuci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>Kafka Connect posee dos modos de ejecuci√≥n</p>
<div class="ulist">
<ul>
<li>
<p>Standalone:</p>
<div class="ulist">
<ul>
<li>
<p>Proceso como un solo worker en una m√°quina</p>
</li>
<li>
<p>Uso para pruebas o procesos que no se van a distribuir</p>
</li>
</ul>
</div>
</li>
<li>
<p>Distribuido:</p>
<div class="ulist">
<ul>
<li>
<p>Multiples procesos worker en una o m√°s m√°quinas</p>
</li>
<li>
<p>Uso para tolerancia a fallos y escalabilidad</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_replicator">14.3. Replicator</h3>
<div class="ulist">
<ul>
<li>
<p>Permite replicar topics entre clusters de Apache Kafka</p>
</li>
<li>
<p>Crea los topics exactamente igual que se crearon en el cluster original</p>
</li>
<li>
<p>Incluye tambi√©n las modificaciones particulares del topic.</p>
</li>
<li>
<p>Mantiene el factor de replicaci√≥n y las particiones por igual.</p>
</li>
<li>
<p>Soporta distintas versiones de replicaci√≥n</p>
<div class="ulist">
<ul>
<li>
<p>Despliegue de Arquitecturas Multi-DC</p>
</li>
<li>
<p>Configuraciones Multi-Datacenter</p>
</li>
<li>
<p>Esquemas de migraci√≥n</p>
</li>
<li>
<p>Redes en el Cloud de Confluent y otras soluciones Cloud o h√≠bridas.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_caracter√≠sticas_2">14.3.1. Caracter√≠sticas</h4>
<div class="ulist">
<ul>
<li>
<p>Permite listas blancas y negras, y expresiones regulares</p>
</li>
<li>
<p>Creaci√≥n de topics din√°micos en destino</p>
</li>
<li>
<p>Modificaci√≥n de particiones en destino si lo han hecho en origen</p>
</li>
<li>
<p>Reconfiguraci√≥n de topics si cambian en origen</p>
</li>
<li>
<p>Soporta la preservaci√≥n de Timestamps, la prevenci√≥n de repeticiones de mensajes c√≠clicos, y la traducci√≥n de los offsets de consumidores.</p>
</li>
<li>
<p>Se puede migrar de MirrorMaker a Replicator. No se puede migrar de forma inversa.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_monitorizaci√≥n_de_kafka">15. Monitorizaci√≥n de Kafka</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_m√©tricas_de_los_brokers">15.1. M√©tricas de los Brokers</h3>
<div class="ulist">
<ul>
<li>
<p>A la hora de monitorizar nuestro cl√∫ster, es importante llevar un control de m√∫ltiples elementos, y los puntos de presi√≥n de cada pieza software son distintos en funci√≥n de su naturaleza.</p>
</li>
<li>
<p>Los <strong>Brokers</strong> son el punto central de <strong>Kafka</strong>, por eso vamos a empezar por ellos.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sistemas">15.1.1. Sistemas</h4>
<div class="ulist">
<ul>
<li>
<p>Los puntos que debemos controlar para ellos son:</p>
<div class="ulist">
<ul>
<li>
<p>El espacio disponible en disco (la falta de espacio es tremendamente peligrosa)</p>
</li>
<li>
<p>El uso de lectura y escritura de disco. Podemos tener cuellos de botella si hacemos un uso muy intenso del mismo</p>
</li>
<li>
<p>Cu√°ntas p√°ginas de logs est√°n cacheadas</p>
</li>
<li>
<p>Cu√°l es el ratio de hits en esa cach√©</p>
</li>
</ul>
</div>
</li>
<li>
<p>Ya hablamos anteriormente del uso de disco, y c√≥mo calcular con cierto margen de holgura lo que √≠bamos a necesitar.</p>
</li>
<li>
<p>Si tenemos correctamente configurada la rotaci√≥n de los logs, y hemos calculado correctamente la carga de nuestro sistema, no deber√≠amos tener problemas.</p>
</li>
<li>
<p>Si lo monitorizamos veremos que tiene forma de sierra (va creciendo, y posteriormente la rotaci√≥n de los logs libera espacio), as√≠ constantemente</p>
</li>
<li>
<p>Si nos estamos quedando sin espacio, vamos a tener que solucionarlo.</p>
<div class="ulist">
<ul>
<li>
<p>Modificando (si es posible) la pol√≠tica de rotaci√≥n de los logs</p>
</li>
<li>
<p>A√±adiendo m√°s discos al nodo</p>
</li>
<li>
<p>Escalando, a√±adiendo m√°s nodos (y brokers) al sistema</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>du</strong>: disk usage (opci√≥n -h para human readable, y --max-depth=0 para no ver el uso de subdirectorios)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% du -h /tmp/kafka-logs --max-depth=0</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>df</strong>: Disk free, nos indica el espacio disponible en disco (de nuevo, -h para verlo m√°s c√≥modo):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% df -h</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>El uso de disco es otra m√©trica importante para nuestros <strong>Brokers</strong>.</p>
</li>
<li>
<p>Un uso elevado puede producir una ca√≠da de rendimiento, aunque no tengamos un problema de espacio. Si esto sucede:</p>
<div class="ulist">
<ul>
<li>
<p>Revisar que el balanceo sea correcto (puede que tengamos m√°l indicados los l√≠deres)</p>
</li>
<li>
<p>Si no mejora, valora la opci√≥n de a√±adir m√°s nodos, para repartirse el trabajo</p>
</li>
<li>
<p>Otra opci√≥n es hacer uso de discos de estado s√≥lido, SSD.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Herramientas que pueden ayudarnos a monitorizar el uso de disco para lecturas/escrituras son:</p>
<div class="ulist">
<ul>
<li>
<p><strong>iostat</strong>: del paquete <strong>sysstat</strong>, que nos monitoriza el uso por cada disco (lecturas por segundo, escrituras&#8230;&#8203;)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% iostat -x 1</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>sar</strong>: Tambi√©n de <strong>sysstat</strong>, nos muestra datos agrupados, para saber el tiempo que ha estado ocioso el disco durante unos intervalos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% sar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tambi√©n era interesante conocer las p√°ginas que estaban cacheadas y el ratio de aciertos.</p>
</li>
<li>
<p>Evidentemente, cuanto m√°s logs pueda tener en memoria, m√°s eficiente va a ser mi sistema.</p>
</li>
<li>
<p>Si no puedo mantener todas en memoria, mantendr√© s√≥lo los m√°s recientes.</p>
</li>
<li>
<p>Si tenemos pocos logs cacheados, podemos intentar solucionarlo de la siguiente manera:</p>
<div class="ulist">
<ul>
<li>
<p>Verificando el tama√±o de los logs, tal vez ficheros de tama√±o m√°s peque√±o me permitan cachearlos con mayor facilidad</p>
</li>
<li>
<p>A√±adir m√°s RAM, esto permitir√° tener m√°s cach√©</p>
</li>
<li>
<p>A√±adir Brokers, con nuevos nodos (bien balanceados), se podr√° tener m√°s cach√© de logs</p>
</li>
</ul>
</div>
</li>
<li>
<p>Podemos consultar la memoria virtual con el comando <strong>vmstat</strong>.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% vmstat</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Existe una utilidad que puede ayudaros llamada <strong>cachestat</strong>, desarrollada por <strong>Brendan Gregg</strong> que puede sernos de utilidad (muestra cada x segundos el total de hits de la cach√©)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ wget https://raw.githubusercontent.com/brendangregg/perf-t/master/fs/cachestat
...
100%[======================================&gt;] 5,435       --.-K/s   in 0s

2019-01-23 20:01:41 (22.0 MB/s) - ‚Äòcachestat‚Äô saved [5435/5435]
[kafka@kafka-server ~]$ chmod +x cachestat
[kafka@kafka-server ~]$ sudo ./cachestat 10
Counting cache functions... Output every 10 seconds.
    HITS   MISSES  DIRTIES    RATIO   BUFFERS_MB   CACHE_MB
    1934        0       12   100.0%            2       2183
     346        0        6   100.0%            2       2183
    2711        0       20   100.0%            2       2183</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_m√©tricas_de_los_consumidores_y_productores">15.2. M√©tricas de los Consumidores y Productores</h3>
<div class="ulist">
<ul>
<li>
<p>Los consumidores son procesos <strong>Java</strong>, y como tal vamos a analizarlos con m√°s detalle cuando veamos las herramientas de monitorizaci√≥n <strong>Java</strong>.</p>
</li>
<li>
<p>Los puntos que m√°s nos pueden interesar son:</p>
<div class="ulist">
<ul>
<li>
<p>El uso de RAM</p>
</li>
<li>
<p>El LAG que puedan estar experimentando (retraso entre la escritura del mensaje por un productor y la lectura por parte de un consumidor)..</p>
</li>
</ul>
</div>
</li>
<li>
<p>Un uso inadecuado de la RAM puede penalizar nuestro programa (o incluso acabar con √©l). La forma de uso de la RAM suele tener aspecto de dientes de sierra (debido a la naturaleza del GC de la JVM).</p>
</li>
<li>
<p>Si un Consumidor tiene problemas, recordar que podemos escalar facilmente a√±adiendo m√°s consumidores con su mismo <strong>group.id</strong>.</p>
</li>
<li>
<p>Con respecto al LAG, el punto determinante es ver si va aumentando. Si cada vez estamos m√°s lejos de los mensajes que se escriben, quiere decir que no podemos procesar tanto como desear√≠amos.</p>
</li>
<li>
<p>Soluciones para esto son:</p>
<div class="ulist">
<ul>
<li>
<p>Verificar que el Broker responde correctamente, puede que no est√© cacheando los logs y por ello retrase al consumer</p>
</li>
<li>
<p>Aumentar el n√∫mero de particiones, y por supuesto, a√±adir m√°s consumidores. A ver si entre varios pueden estar al d√≠a</p>
</li>
<li>
<p>Incrementar la RAM de los consumidores. Puede que vayan lento porque no pueden almacenar en memoria muchos mensajes.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Kafka</strong> ofrece una herramienta para monitorizar los grupos de consumidores actuales y ver su LAG, <strong>kafka-consumer-groups.sh</strong>.</p>
</li>
<li>
<p>Lo primero se debe pedir una lista de los consumidores</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --list</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Despu√©s, se pide la informaci√≥n de un grupo de consumidores concretos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-consumer-groups.sh --new-consumer --bootstrap-server localhost:9092 --describe --group consumer_base</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_herramientas_java_para_monitorizar">15.3. Herramientas JAVA para monitorizar</h3>
<div class="ulist">
<ul>
<li>
<p>La monitorizaci√≥n propia de la <strong>JVM</strong> es un tema vital a la hora de trabajar con <strong>Kafka</strong>.</p>
</li>
<li>
<p>En este tema vamos a hablar un poco de las herramientas que tenemos disponibles para poder monitorizar este apartado, poniendo especial √©nfasis en los <strong>Managed beans</strong> publicados por <strong>Kafka</strong> para  obtener informaci√≥n de especial inter√©s.</p>
</li>
<li>
<p>Las herramientas que vamos a ver son:</p>
<div class="ulist">
<ul>
<li>
<p>GC Viewer</p>
</li>
<li>
<p>Visual GC</p>
</li>
<li>
<p>JVisualVM</p>
</li>
<li>
<p>JCMD</p>
</li>
<li>
<p>JMC</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_gcviewer">15.3.1. GCViewer</h4>
<div class="ulist">
<ul>
<li>
<p>Es una peque√±a herramienta que visualiza los datos de recogida de basura detallada generados por las m√°quinas virtuales de Sun e IBM Java (JVM).</p>
</li>
<li>
<p>El an√°lisis de estos datos puede ser √∫til en aplicaciones con el fin de ajustar y maximizar el rendimiento del colector de basura y por lo tanto la propia aplicaci√≥n.</p>
</li>
<li>
<p><a href="https://github.com/chewiebug/GCViewer">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-01.png" alt="kafka monitorizacion 01" width="600">
</div>
<div class="title">Figure 4. Captura de gcviewer</div>
</div>
</div>
<div class="sect3">
<h4 id="_visualgc">15.3.2. visualgc</h4>
<div class="ulist">
<ul>
<li>
<p>Visual Garbage Collection Monitoring Tool.</p>
</li>
<li>
<p>Se asigna a un HotSpot JVM instrumentado y recoge y muestra gr√°ficamente la recolecci√≥n de basura, cargador de clases, y los datos de rendimiento del compilador HotSpot.</p>
</li>
<li>
<p>La JVM de destino se identifica por su identificador de la m√°quina virtual, o <strong>VMID</strong>.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.oracle.com/technetwork/java/visualgc-136680.html">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-02.png" alt="kafka monitorizacion 02" width="600">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>A partir de Java 8 ya no funciona (pues no hay √°rea PermGen), pero usaremos un plugin de <strong>JVisualVM</strong> que es ex√°ctamente igual</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_jconsole">15.3.3. JConsole</h4>
<div class="ulist">
<ul>
<li>
<p>Esta herramienta de interfaz gr√°fica de usuario JConsole permite monitorizar cualquier aplicaci√≥n que cumpla con la especificaci√≥n Java Management Extensions (JMX).</p>
</li>
<li>
<p>JConsole utiliza JMX de la JVM para proporcionar informaci√≥n sobre el rendimiento y el consumo de recursos de las aplicaciones que se ejecutan en la plataforma Java.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-03.png" alt="kafka monitorizacion 03" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jvisualvm">15.3.4. JVisualVM</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Virtual Machine Monitoring, Troubleshooting, and Profiling Tool</strong></p>
</li>
<li>
<p>Es una herramienta con interfaz gr√°fica de usuario que proporciona informaci√≥n detallada acerca de las aplicaciones basadas en la tecnolog√≠a Java.</p>
</li>
<li>
<p>Java VisualVM combina la supervisi√≥n, la soluci√≥n de problemas, y los servicios de perfilado en una sola herramienta.</p>
</li>
<li>
<p>Por ejemplo, la mayor√≠a de la funcionalidad ofrecida por las herramientas independientes jmap, jinfo, jstat y jstack se han integrado en Java VisualVM.</p>
</li>
<li>
<p>Otras funcionalidades, como algunas de las que ofrece la herramienta JConsole, se pueden a√±adir como plug-ins opcionales.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/6/docs/technotes/tools/share/jvisualvm.html">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-04.png" alt="kafka monitorizacion 04" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jcmd">15.3.5. JCMD</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Command</strong></p>
</li>
<li>
<p>El comando jcmd es nuevo en JDK 7 y ofrece muchas de las caracter√≠sticas de  JPS, adem√°s de alguna informaci√≥n adicional.</p>
</li>
<li>
<p>El comando jcmd le permite consultar diversos aspectos de las m√°quinas virtuales espec√≠ficas.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jcmd.html">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-05.png" alt="kafka monitorizacion 05" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_jmc">15.3.6. JMC</h4>
<div class="ulist">
<ul>
<li>
<p><strong>Java Mision Control</strong></p>
</li>
<li>
<p>Permite a los administradores y desarrolladores de Java recopilar informaci√≥n detallada de bajo nivel acerca de c√≥mo la M√°quina Virtual Java (JVM) y la aplicaci√≥n Java se est√°n comportando.</p>
</li>
<li>
<p>JMC es un avanzado conjunto de herramientas que permite el an√°lisis eficiente y detallada de los datos recogidos por Java Fligh Recorder.</p>
</li>
<li>
<p>A partir de la versi√≥n de Oracle JDK 7 Actualizaci√≥n 40 (7u40), Java Misi√≥n de Control se incluye con el HotSpot JVM.</p>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.oracle.com/technetwork/java/javaseproducts/mission-control/java-mission-control-1998576.html">M√°s informaci√≥n</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-06.png" alt="kafka monitorizacion 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Con respecto a los valores publicados por <strong>Kafka</strong> a trav√©s de sus <strong>Managed Beans</strong>, podemos agrupar los m√°s importantes seg√∫n a lo que hacen referencia:</p>
<div class="ulist">
<ul>
<li>
<p>Estad√≠sticas de los <strong>Brokers</strong></p>
</li>
<li>
<p>Estad√≠sticas de los clientes <strong>Productores</strong></p>
</li>
<li>
<p>Estad√≠sticas de los clientes <strong>Consumidores</strong></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_brokers">15.4. JMX - Brokers</h3>
<div class="ulist">
<ul>
<li>
<p>Las estad√≠sticas m√°s destacables de los <strong>Brokers</strong>, podr√≠amos destacar:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_underreplicatedpartitions">15.4.1. JMX MBean: kafka.server:type=ReplicaManager.UnderReplicatedPartitions</h4>
<div class="ulist">
<ul>
<li>
<p>N√∫mero de particiones que no est√°n replicadas tantas veces como deber√≠an (deber√≠a ser 0 si no hay problemas)</p>
</li>
<li>
<p>Cualquier valor distinto de 0 significa que es posible una p√©rdida de datos al no tener todas las r√©plicas.</p>
</li>
<li>
<p>Existen varias soluciones</p>
<div class="ulist">
<ul>
<li>
<p>auto.leader.rebalance.enable = false &#8594; si lo tenemos as√≠, tendremos que lanzar el script kafka-leader-election.sh para recolocar y sincronizar los datos a todas las r√©plicas.</p>
</li>
<li>
<p>Si seguimos con un valor constante distinto a 0, posiblemente sea por un broker caido.</p>
</li>
<li>
<p>Si est√°n todos los brokers activos, el problema ser√° de rendimiento</p>
</li>
<li>
<p>En este caso, hay que localizar si se trata de un broker concreto o del cluster.</p>
</li>
<li>
<p>Podemos conectarnos a cada broker y lanzar el comando <strong>kafka-topics.sh --describe --under-replicated</strong> donde nos indicar√° el broker afectado.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypekafkacontroller_offlinepartitionscount">15.4.2. JMX MBean: kafka.controller:type=KafkaController.OfflinePartitionsCount</h4>
<div class="ulist">
<ul>
<li>
<p>S√≥lo consultable desde el controlador</p>
</li>
<li>
<p>Son las particiones que no tienen una partici√≥n l√≠der accesible (por lo que no se puede ni leer ni escribir)</p>
</li>
<li>
<p>Significa que debe ser tambi√©n 0</p>
</li>
<li>
<p>Es indicativo de caida de un broker</p>
</li>
<li>
<p>En caso de que los brokers est√©n bien, es indicativo de un lider "sucio" que no puede sincronizar con los seguidores.</p>
</li>
<li>
<p>Significa que el lider no est√° sincronizado y los clientes no pueden conectarse a √©l.</p>
</li>
<li>
<p>Hay que asegurarse de que no puede elegirse una partici√≥n no sincronizada.</p>
<div class="ulist">
<ul>
<li>
<p>unclean.leader.election.enable = false</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypekafkacontroller_activecontrollercount">15.4.3. JMX MBean: kafka.controller:type=KafkaController.ActiveControllerCount*</h4>
<div class="ulist">
<ul>
<li>
<p>Nos indica si el broker actual ejerce de controlador, con valor 0 o 1</p>
</li>
<li>
<p>En caso de que haya m√°s de uno con valor 1 (por que haya un broker atascado) la soluci√≥n es reiniciar ambos nodos y esperar a la reelecci√≥n</p>
</li>
<li>
<p>En el caso de que haya 0, hay que revisar que zookeeper est√© correctamente, ya que si tienen problemas de comunicaci√≥n con zookeeper, habr√° que solucionar el problema y comprobar que se vuelve a elegir controlador</p>
</li>
<li>
<p>Si zookeeper est√° correctamente, habr√° que reiniciar todo el cluster para que vuelvan a realizar la elecci√≥n de controlador.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypebrokertopicmetrics_bytesinoutpersec">15.4.4. JMX MBean: kafka.server:type=BrokerTopicMetrics.Bytes[In,Out]PerSec</h4>
<div class="ulist">
<ul>
<li>
<p>BytesIn es una buena m√©trica para comprobar el trabajo por broker</p>
</li>
<li>
<p>Podemos comprobar como trabajan los brokers a la hora de recibir datos, y si hay alg√∫n broker que trabaje m√°s que los dem√°s.</p>
</li>
<li>
<p>BytesOut Suele ser m√∫ltiples veces m√°s que BytesIn ya que tiene que ver con las ordenes de replicaci√≥n.</p>
</li>
<li>
<p>Posee varios atributos interesantes:</p>
<div class="ulist">
<ul>
<li>
<p>OneMinuteRate &#8594; no es muy util ya que suele fluctuar demasiado.</p>
</li>
<li>
<p>FiveMinuteRate</p>
</li>
<li>
<p>FifteenMinuteRate</p>
</li>
<li>
<p>MeanRate</p>
</li>
<li>
<p>Count</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypebrokertopicmetrics_messagesinpersec">15.4.5. JMX MBean: kafka.server:type=BrokerTopicMetrics.MessagesInPerSec</h4>
<div class="ulist">
<ul>
<li>
<p>El n√∫mero de mensajes recibidos.</p>
</li>
<li>
<p>Sin embargo, no tenemos m√©trica de mensajes enviados.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_partitionscount">15.4.6. JMX MBean: kafka.server:type=ReplicaManager.PartitionsCount</h4>
<div class="ulist">
<ul>
<li>
<p>Si tenemos la opci√≥n auto.create.topics.enable = true</p>
</li>
<li>
<p>Es una m√©trica que nos indica el n√∫mero de particiones que disponemos.</p>
</li>
<li>
<p>Si la opci√≥n est√° desactivada, no es necesario monitorizarla ya que se hace de forma manual.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_servertypereplicamanager_leadercount">15.4.7. JMX MBean: kafka.server:type=ReplicaManager.LeaderCount</h4>
<div class="ulist">
<ul>
<li>
<p>Indica el n√∫mero de particiones lider por cada broker</p>
</li>
<li>
<p>En caso de caida y si tenemos la opci√≥n auto.leader.rebalance.enable = false</p>
</li>
<li>
<p>Si se cae una instancia, el cluster se desequilibrar√°, y el n√∫mero de particiones l√≠deres se repartir√° entre el resto de brokers.</p>
</li>
<li>
<p>Se deben realizar peri√≥dicamente kafka-leader-election.sh para que se reequilibre de nuevo.</p>
</li>
<li>
<p>Es preferible hacerlo manualmente para evitar hacerlo en medio de los picos de carga.</p>
</li>
<li>
<p>El valor recomendado debe ser:</p>
<div class="ulist">
<ul>
<li>
<p>LeaderCount/PartitionCount = 1/ReplicationFactor</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_networktyperequestmetrics_tipo_nombre">15.4.8. JMX MBean: kafka.network:type=RequestMetrics.[tipo].[nombre]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar todas las m√©tricas de kafka disponibles.</p>
</li>
<li>
<p>Se divide en varias categor√≠as. Se elige una de cada categoria.</p>
<div class="ulist">
<ul>
<li>
<p>Metric Type:</p>
<div class="ulist">
<ul>
<li>
<p>TotalTimMs</p>
</li>
<li>
<p>RequestQueueTimeMs</p>
</li>
<li>
<p>LocalTimeMs</p>
</li>
<li>
<p>RemoteTimeMs</p>
</li>
<li>
<p>ThrottleTimeMs</p>
</li>
<li>
<p>ResponseQueueTimeMs</p>
</li>
<li>
<p>ResponseSendTimeMs</p>
</li>
<li>
<p>RequestsPerSec</p>
</li>
</ul>
</div>
</li>
<li>
<p>Request Name:</p>
<div class="ulist">
<ul>
<li>
<p>ApiVersion</p>
</li>
<li>
<p>ControlledShutdown</p>
</li>
<li>
<p>CreateTopics</p>
</li>
<li>
<p>DeleteTopics</p>
</li>
<li>
<p>DescribeGroups</p>
</li>
<li>
<p>Produce</p>
</li>
<li>
<p>SaslHandshake</p>
</li>
<li>
<p>StopReplica</p>
</li>
<li>
<p>SyncGroup</p>
</li>
<li>
<p>UpdateMetadata</p>
</li>
<li>
<p>etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Attributes</p>
<div class="ulist">
<ul>
<li>
<p>50thPercentile</p>
</li>
<li>
<p>75thPercentile</p>
</li>
<li>
<p>99thPercentile</p>
</li>
<li>
<p>999thPercentile</p>
</li>
<li>
<p>Count</p>
</li>
<li>
<p>Min</p>
</li>
<li>
<p>Max</p>
</li>
<li>
<p>Mean</p>
</li>
<li>
<p>StdDev</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>De todas ellas, es interesante el percentil 99, ya que nos dejar√° m√°s claro los casos de picos de los valores comunes, indicando problemas de rendimiento.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_topicnombre_topicpartitionparticion">15.4.9. &#8230;&#8203;,topic=[nombre_topic],partition=[particion]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar las m√©tricas a nivel de partici√≥n de un topic.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbean_kafka_controllertypecontrollerstats_uncleanleaderelectionspersec">15.4.10. JMX MBean: kafka.controller:type=ControllerStats.UncleanLeaderElectionsPerSec</h4>
<div class="ulist">
<ul>
<li>
<p>Si perdemos un broker con una partici√≥n l√≠der y el resto de r√©plicas no hab√≠an copiado esa informaci√≥n, y se elije un l√≠der nuevo, pero claro, se pueden haber perdido datos.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_productores">15.5. JMX - Productores</h3>
<div class="ulist">
<ul>
<li>
<p>Las estad√≠sticas m√°s interesantes de los clientes <strong>Productores</strong> son:</p>
<div class="ulist">
<ul>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id]</p>
</li>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id],node-id=node-[broker_id]</p>
</li>
<li>
<p>JMX MBean: kafka.producer:type=producer-metrics,client-id=[client-id],topic=[topic]</p>
</li>
</ul>
</div>
</li>
<li>
<p>Se recomienda que los clientes usen de client-id una indicaci√≥n que favorezca la monitorizaci√≥n, como por ejemplo, ip o nombre del servidor origen. Sino se genera un id</p>
</li>
<li>
<p>Los atributos son:</p>
<div class="ulist">
<ul>
<li>
<p>record-error-rate: Indica la cantidad de mensajes que se han producido y han dado error. Solo indica aquellos que han fallado incluidos los reintentos.</p>
</li>
<li>
<p>request-latency-avg: Es interesante comprobar la media en uso normal, y si se incrementa, el rendimiento del cluster est√° cayendo, y suele acompa√±ar con una caida de producci√≥n de mensajes.</p>
</li>
<li>
<p>record-send-rate: Tasa de envio de mensajes por segundo del broker.</p>
</li>
<li>
<p>request-rate: Media de peticiones recibidas por segundo por el broker</p>
</li>
<li>
<p>outgoing-byte-rate: Tasa de producci√≥n de datos</p>
</li>
<li>
<p>record-queue-time-avg: Trata el tiempo que tarda kafka desde la petici√≥n de mensaje hasta su envio</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_jmx_consumidores">15.6. JMX - Consumidores</h3>
<div class="ulist">
<ul>
<li>
<p>Las estad√≠sticas m√°s interesantes de los clientes <strong>Consumidores</strong> son:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_jmx_mbeankafka_consumertypeconsumer_fetch_manager_metricsclient_idclient_idtopictopic_name">15.6.1. JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id][,topic=&lt;topic_name]</h4>
<div class="ulist">
<ul>
<li>
<p>fetch-latency-avg: Permite indicar la latencia fetch.-.bytes fetch.max.wait.ms para optimizar esta variable</p>
</li>
<li>
<p>bytes-consumed-rate: Tasa de consumo de bytes.</p>
</li>
<li>
<p>records-consumed-rate: Tasa de consumo de mensajes</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_jmx_mbeankafka_consumertypeconsumer_coordinator_metricsclient_idclient_idtopictopic_name">15.6.2. JMX MBean:kafka.consumer:type=consumer-coordinator-metrics,client-id=[client_id][,topic=&lt;topic_name]</h4>
<div class="ulist">
<ul>
<li>
<p>Permite monitorizar la sincronizaci√≥n de los grupos de clientes, cuando el n√∫mero de clientes consumidores en un mismo grupo cambia</p>
<div class="ulist">
<ul>
<li>
<p>sync-time-avg: Indica en ms lo que tarda en realizar la operaci√≥n.</p>
</li>
<li>
<p>sync-rate: Sincronizaciones de grupo por segundo. Mas √∫til que la anterior. Debe ser 0 para grupos de consumidores estables.</p>
</li>
<li>
<p>commit-latency-avg: La velocidad de confirmaci√≥n de los offsets. Debe cambiar poco, y si se incrementa, comprobar la caida de rendimiento.</p>
</li>
<li>
<p>assigned-partitions: Permite comprobar el consumo de particiones en los grupos.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_lag">15.6.3. Lag</h4>
<div class="ulist">
<ul>
<li>
<p>Existen m√©tricas de an√°lisis de lag.</p>
</li>
<li>
<p>Sin embargo son bastante complejas de entender.</p>
</li>
<li>
<p>Para solucionar este problema, existe un proyecto llamado Burrow de LinkedIn que permite monitorizar el lag de los consumidores de Kafka.</p>
</li>
<li>
<p>El proyecto se encuentra en:</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/linkedin/Burrow">Github Burrow</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Permite hacer un seguimiento del lag de los consumidores.</p>
</li>
<li>
<p>Permite definir endpoints HTTP que permite mostrar la informaci√≥n del cluster de kafka y de los grupos de consumidores.</p>
</li>
<li>
<p>Permite tambi√©n notificar si alg√∫n grupo cumple un criterio concreto.</p>
</li>
<li>
<p>Existen una serie de subsistemas:</p>
<div class="ulist">
<ul>
<li>
<p>Clusters: Permite actualizar peri√≥dicamente la lista de topics y el √∫ltimo offset por partici√≥n.</p>
</li>
<li>
<p>Consumers: Permite mostrar la informaci√≥n de los grupos de consumidores como su lag.</p>
</li>
<li>
<p>Storage: Permite almacenar toda la informaci√≥n en el sistema</p>
</li>
<li>
<p>Evaluator: Obtiene la informaci√≥n del m√≥dulo Storage y comprueba el status de un grupo de consumidores. Usa reglas de evaluaci√≥n para comprobaciones de consumidores.</p>
</li>
<li>
<p>Notifier: Consulta el estado de un grupo de consumidores y envia una notificaci√≥n si cierto criterio se ha cumplido.</p>
</li>
<li>
<p>HTTP Server: Provee de un servidor HTTP para mostrar la informaci√≥n del cluster y sus consumidores.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_cuotas">15.6.4. Cuotas</h4>
<div class="ulist">
<ul>
<li>
<p>Tanto para productores como para consumidores, podemos definir cuotas.</p>
</li>
<li>
<p>Kafka ofrece los siguientes mbeans</p>
<div class="ulist">
<ul>
<li>
<p>JMX MBean:kafka.producer:type=producer-metrics,client-id=[client_id]</p>
<div class="ulist">
<ul>
<li>
<p>produce-throttle-time-avg: media de producci√≥n</p>
</li>
</ul>
</div>
</li>
<li>
<p>JMX MBean:kafka.consumer:type=consumer-fetch-manager-metrics,client-id=[client_id]</p>
<div class="ulist">
<ul>
<li>
<p>fetch-throttle-time-avg: media de consumo</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Permite definir cuotas por id de cliente, frenando tanto productores como consumidores con ese id de cliente.</p>
</li>
<li>
<p>Por defecto est√° deshabilitado.</p>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_monitorizacion">15.7. Lab: Monitorizacion</h3>
<div class="ulist">
<ul>
<li>
<p>Vamos a probar a monitorizar las aplicaciones a trav√©s de <strong>JMX</strong>, y para esto tenemos que arrancar habiendo configurado la variable de entorno <strong>JMX_PORT</strong>.</p>
</li>
<li>
<p>Como nuestra configuraci√≥n es un poco especial, vamos a levantar todos los brokers en distintos puertos (para que no se solapen).</p>
</li>
<li>
<p>As√≠ que paramos todo el cl√∫ster y arrancamos con la siguiente configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /usr/local/zookeeper-3.4.14/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[kafka@kafka-server ~]$ export JMX_PORT=9595
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties1
[kafka@kafka-server ~]$ export JMX_PORT=9596
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties2
[kafka@kafka-server ~]$ export JMX_PORT=9597
[kafka@kafka-server ~]$ kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties3</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>para publicarlo externamente, debemos editar <strong>kafka-run-class.sh</strong> para a√±adir las opciones propies de la <strong>JVM</strong> para publicar el acceso <strong>JMX</strong> remoto, por ejemplo esta configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">-Dcom.sun.management.jmxremote.port=4433 -Dcom.sun.management.jmxremote.ssl=false  -Dcom.sun.management.jmxremote.authenticate=false</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Lo que hemos mostrado basicamente ya viene a√±adido (dentro de la variable <strong>KAFKA_JMX_OPTS</strong> de dicho script), pero evidentemente, si queremos cifrar la comunicaci√≥n o a√±adir autenticaci√≥n, debemos hacerlo de manera espec√≠fica.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A trav√©s de <strong>JConsole</strong> o <strong>JMC</strong>, podemos consultar informaci√≥n de los <strong>Managed Beans</strong>, como se muestra en el ejemplo</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-07.png" alt="kafka monitorizacion 07" width="600">
</div>
</div>
<div class="sect3">
<h4 id="_cmak">15.7.1. CMAK</h4>
<div class="ulist">
<ul>
<li>
<p>Es el antiguo <em>Yahoo Kafka Manager</em>
Lo primero que tenemos que hacer es descargar los fuentes del <strong>CMAK</strong> de su repositorio de <strong>github</strong>. Podemos hacerlo directamente desde nuestra VM con el comando <strong>wget</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$  wget https://github.com/yahoo/CMAK/releases/download/3.0.0.5/cmak-3.0.0.5.zip</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez descargado tenemos que descomprimirlo</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ unzip cmak-3.0.0.5.zip</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Nos vamos a la ruta en la que ha desempaquetado los binarios y le indicamos el zookeeper para que pueda almacenar metadatos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd cmak-3.0.0.5/conf</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Editamos el fichero application.conf y modificamos en el fichero las entradas del zookeeper</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code># Settings prefixed with 'kafka-manager.' will be deprecated, use 'cmak.' instead.
# https://github.com/yahoo/CMAK/issues/713
kafka-manager.zkhosts=&quot;kafka-server.local:2181&quot;
kafka-manager.zkhosts=${?ZK_HOSTS}
cmak.zkhosts=&quot;kafka-server.local:2181&quot;
cmak.zkhosts=${?ZK_HOSTS}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Tambi√©n podr√≠amos exportar la variable ZK_HOSTS con la ruta a los servidores de zookeeper y conseguir√≠amos el mismo efecto.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ export ZK_HOSTS=kafka-server.local:2181</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya estamos listos para trabajar. Vamos a arrancar nuestro programa</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server cmak-3.0.0.5]$ ./bin/cmak</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para hacer uso del programa, nos vamos a conectar v√≠a web, ya que levanta un servidor en el puerto 9000.</p>
</li>
<li>
<p>Podemos ir directamente desde nuestra m√°quina virtual a la URL: <a href="http://kafka-server.local:9000" class="bare">http://kafka-server.local:9000</a></p>
</li>
<li>
<p>Al entrar en la ruta donde publica el <strong>CMAK</strong>, no vemos nada todav√≠a</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-01.png" alt="kafka monitorizacion laboratorio 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tenemos que crear un cl√∫ster para monitorizarlo.</p>
</li>
<li>
<p>Para ello vamos a "cluster"  y "Add Cluster"</p>
</li>
<li>
<p>Damos de alta nuestro cl√∫ster con una configuraci√≥n b√°sica</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-02.png" alt="kafka monitorizacion laboratorio 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora vemos un resumen del cl√∫ster al que nos hemos conectado</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-03.png" alt="kafka monitorizacion laboratorio 03" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si vamos a <strong>Topics</strong>, tenemos un resumen de los mismos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-04.png" alt="kafka monitorizacion laboratorio 04" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y tambi√©n podemos consultar la informaci√≥n de los <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-05.png" alt="kafka monitorizacion laboratorio 05" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos crear nuevos <strong>Topics</strong> a trav√©s de esta herramienta</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-06.png" alt="kafka monitorizacion laboratorio 06" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y hasta podemos consultar informaci√≥n de los <strong>Consumers</strong> que hay actualmente trabajando en el cl√∫ster.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-07.png" alt="kafka monitorizacion laboratorio 07" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y si queremos ver qu√© est√° haciendo el <strong>consumer group</strong>, podemos pinchar sobre √©l y veremos d√≥nde est√° trabajando</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-08.png" alt="kafka monitorizacion laboratorio 08" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>O conocer m√°s informaci√≥n del <strong>Topic</strong> en cuesti√≥n sobre el que trabajamos</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-09.png" alt="kafka monitorizacion laboratorio 09" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Pero podemos obtener m√°s, vamos a obtener estad√≠sticas a trav√©s de <strong>JMX</strong>.</p>
</li>
<li>
<p>Para ello vamos a parar todo el cl√∫ster, y arrancar habiendo definido la variable <strong>JMX_PORT</strong>.</p>
</li>
<li>
<p>Como mis 3 brokers est√°n en el mismo nodo, voy a tener que hacer alg√∫n cambio adicional (poner varias veces esta variable para que no se pisen entre ellos).</p>
</li>
<li>
<p>Arrancar√≠a de la siguiente forma:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server cmak-3.0.0.5]$ zkServer.sh start
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9595
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties1
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9596
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties2
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9597
[kafka@kafka-server cmak-3.0.0.5]$ kafka-server-start.sh -daemon $KAFKA_HOME/config/server.properties3
[kafka@kafka-server cmak-3.0.0.5]$ export JMX_PORT=9595
[kafka@kafka-server cmak-3.0.0.5]$ ./bin/cmak</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, vuelvo a conectarme al <strong>CMAK</strong>, y edito la configuraci√≥n de mi cl√∫ster para a√±adir soporte <strong>JMX</strong> (NOTA: si hemos habilitado usuario y contrase√±a, tambi√©n debemos especificarlo aqu√≠)</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-10.png" alt="kafka monitorizacion laboratorio 10" width="600">
</div>
</div>
<div class="paragraph">
<p>Ahora, si nos vamos a <strong>Broker</strong>, veremos que somos capaces de obtener informaci√≥n relevante gracias a los Managed Beans accesibles a trav√©s del <strong>JMX</strong></p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-monitorizacion-laboratorio-11.png" alt="kafka monitorizacion laboratorio 11" width="600">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_burrow">15.7.2. Burrow</h4>
<div class="ulist">
<ul>
<li>
<p>Las monitorizaciones de lag por medio de las m√©tricas nativas llamadas MaxLag:</p>
<div class="ulist">
<ul>
<li>
<p>Sin embargo, se deben recolectar por consumidor, y se deben interpretar por separado</p>
</li>
<li>
<p>Solo es v√°lido mientras el consumidor est√° activo, sin consumidor no hay m√©tricas</p>
</li>
<li>
<p>No es objetivo al ser el propio consumidor quien emite la m√©trica. Podr√≠a dar valores erroneos.</p>
</li>
<li>
<p>Solo est√° disponible en java, mientras que podemos tener otros clientes en otros lenguajes.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para eso est√° burrow.</p>
</li>
<li>
<p>Para instalar Burrow, hay que tener instalado el lenguaje GO que es el lenguaje de programaci√≥n utilizado.</p>
</li>
<li>
<p>Instalamos golang por medio del siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo dnf -y install golang-bin</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras su instalaci√≥n, vamos a bajar el proyecto:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ go get github.com/linkedin/Burrow</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora nos colocamos en el directorio go/src/github.com/linkedin/Burrow</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ cd go/src/github.com/linkedin/Burrow</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>y ejecutamos el comando de resoluci√≥n de dependencias</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ go mod tidy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Por √∫ltimo lo instalamos</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ go install</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_configuraci√≥n_3">15.7.2.1. Configuraci√≥n</h5>
<div class="ulist">
<ul>
<li>
<p>La configuraci√≥n de Burrow se realiza en distintos formatos.</p>
</li>
<li>
<p>Admite TOML, JSON y YAML</p>
</li>
<li>
<p>Vamos a modificar el fichero toml alojado en <strong>./config/burrow.toml</strong></p>
</li>
<li>
<p>Para ello creamos un fichero llamado burrow.toml y agregamos la siguiente informaci√≥n:</p>
</li>
<li>
<p>Se divide en distintos apartados:</p>
</li>
</ul>
</div>
<div class="sect5">
<h6 id="_general">15.7.2.1.1. General</h6>
<div class="ulist">
<ul>
<li>
<p>Permite indicar la localizaci√≥n de los ficheros PID e indica las salidas STDOUT y STDERR</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[general]
pidfile=&quot;burrow.pid&quot;  # fichero PID
stdout-logfile=&quot;burrow.out&quot; # Redirecci√≥n de STDOUT y STDERR
access-control-allow-origin=&quot;*&quot; # Permisos de control de acceso http</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_logging">15.7.2.1.2. Logging</h6>
<div class="ulist">
<ul>
<li>
<p>Permite indicar como generar los ficheros de log del burrow.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[logging]
filename=&quot;logs/burrow.log&quot; # Ruta y nombre de fichero del log
level=&quot;info&quot; # Nivel de log
maxsize=100 # Tama√±o m√°ximo en MB de un fichero de log MB
maxbackups=30 # M√°ximo n√∫mero de iteraciones del fichero de log
maxage=10 # Tiempo m√°ximo de mantenimiento de ficheros de log
use-localtime=false  # tipo de fecha a la hora de generar el log
use-compression=true # Compresi√≥n de los ficheros rotados</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_zookeeper_2">15.7.2.1.3. Zookeeper</h6>
<div class="ulist">
<ul>
<li>
<p>Especifica la localizaci√≥n del servicio Zookeeper usado para el m√≥dulo de almacenamiento y la sincronizaci√≥n de m√∫ltiples copias de ficheros.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[zookeeper]
servers=[&quot;kafka-server.local:2181&quot;, &quot;kafka-node1.local:2181&quot;, &quot;kafka-node2.local:2181&quot; ]
timeout=6 # Tiempo de expiraci√≥n de sesiones zookeeper.
root-path=&quot;/kafka-monitor/burrow&quot; # Ruta completa de nodos para que escriba Burrow dentro del zookeeper.</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_perfil_de_cliente">15.7.2.1.4. Perfil de cliente</h6>
<div class="ulist">
<ul>
<li>
<p>Los perfiles se usan para agrupar configuraciones. Permite indicar por medio de un nombre distintas configuraciones a aplicar</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[client-profile.burrow-client] # Nombre de la configuraci√≥n
kafka-version=&quot;2.6.0&quot;    #kafka server version
client-id=&quot;burrow-client&quot; # Indicamos el id de cliente a utilizar</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_servidor_http">15.7.2.1.5. Servidor HTTP</h6>
<div class="ulist">
<ul>
<li>
<p>Configuraci√≥n del servidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[httpserver.mylistener]
address=&quot;:8082&quot;
timeout=300</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_almacenamiento">15.7.2.1.6. Almacenamiento</h6>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[storage.mystorage]
class-name=&quot;inmemory&quot;
intervals=10  # Offsets a almacenar por partici√≥n
expire-group=604800 # Segundos que deben pasar antes de que un grupo sea purgado si no tiene un offset confirmado (commited offset)</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_clusters">15.7.2.1.7. Clusters</h6>
<div class="ulist">
<ul>
<li>
<p>Permite configurar la lista de nodos del cluster de kafka para obtener la informaci√≥n del cluster, los topics y los Offsets</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[cluster.kafka-cluster]
class-name=&quot;kafka&quot;
servers=[ &quot;kafka-server.local:9092&quot;, &quot;kafka-node1.local:9092&quot;, &quot;kafka-node2.local:9092&quot; ]
client-profile=&quot;burrow-client&quot;
topic-refresh=10
offset-refresh=10</code></pre>
</div>
</div>
</div>
<div class="sect5">
<h6 id="_consumidores">15.7.2.1.8. Consumidores</h6>
<div class="ulist">
<ul>
<li>
<p>Pemite configurar como extraer la configuraci√≥n de los offsets.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>[consumer.myconsumers]
class-name=&quot;kafka&quot;
cluster=&quot;kafka-cluster&quot;  # Nombre de la configuraci√≥n del cluster de kafka
servers=[ &quot;kafka-server.local:9092&quot;, &quot;kafka-node1.local:9092&quot;, &quot;kafka-node2.local:9092&quot; ]
client-profile=&quot;burrow-client&quot;
offsets-topic=&quot;__consumer_offsets&quot;
start-latest=true</code></pre>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_ejecuci√≥n_3">15.7.2.2. Ejecuci√≥n</h5>
<div class="ulist">
<ul>
<li>
<p>Para ejecutarlo, vamos a lanzar el servicio por medio del comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ /home/kafka/go/bin/Burrow --config-dir .
Reading configuration from .</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez iniciado, podemos realizar peticiones contra el servicio.</p>
</li>
<li>
<p>Para verlo con mas facilidad, instalamos el comando jq que permite formatear json en la shell</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ sudo dnf install jq</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora vamos a ejecutar el status para comprobar que el servicio est√° correcto:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/burrow/admin
GOOD</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Listamos los Clusters</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   136  100   136    0     0   132k      0 --:--:-- --:--:-- --:--:--  132k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;cluster list returned&quot;,
  &quot;clusters&quot;: [
    &quot;kafka-cluster&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Mostramos la informaci√≥n del cluster</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   406  100   406    0     0   396k      0 --:--:-- --:--:-- --:--:--  396k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;cluster module detail returned&quot;,
  &quot;module&quot;: {
    &quot;class-name&quot;: &quot;kafka&quot;,
    &quot;servers&quot;: [
      &quot;kafka-server.local:9092&quot;,
      &quot;kafka-node1.local:9092&quot;,
      &quot;kafka-node2.local:9092&quot;
    ],
    &quot;client-profile&quot;: {
      &quot;name&quot;: &quot;burrow-client&quot;,
      &quot;client-id&quot;: &quot;burrow-client&quot;,
      &quot;kafka-version&quot;: &quot;2.6.0&quot;,
      &quot;tls&quot;: null,
      &quot;sasl&quot;: null
    },
    &quot;topic-refresh&quot;: 10,
    &quot;offset-refresh&quot;: 10
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Listamos los consumidores actuales</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   146  100   146    0     0   142k      0 --:--:-- --:--:-- --:--:--  142k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer list returned&quot;,
  &quot;consumers&quot;: [],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos la lista de topics</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/topic | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   276  100   276    0     0   134k      0 --:--:-- --:--:-- --:--:--  134k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;topic list returned&quot;,
  &quot;topics&quot;: [
    &quot;base-topic&quot;,
    &quot;base-topic2&quot;,
    &quot;topic-log-compaction&quot;,
    &quot;my_topic&quot;,
    &quot;topic-log-compaction2&quot;,
    &quot;test&quot;,
    &quot;topic-kafka-mirror-maker&quot;,
    &quot;__consumer_offsets&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/topic&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un nuevo topic:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9092 --create --topic burrow-topic --partitions 3
Created topic burrow-topic.</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a agregar un productor de pruebas que nos muestre informaci√≥n de lo que est√° haciendo.</p>
</li>
<li>
<p>Para eso vamos a usar kafka-verifiable-producer.sh</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-producer.sh --broker-list localhost:9092 --max-messages 10000000 --repeating-keys 5 --value-prefix 100 --throughput 5 --topic burrow-topic</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos ahora dos consumidores del mismo grupo de consumidores llamado burrow-group</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejecuci√≥n en shell 1</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-consumer.sh --broker-list localhost:9092 --max-messages 10000 --topic burrow-topic --group-id burrow-group</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejecuci√≥n en shell 2</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[vagrant@kafka-server ~]$ kafka-verifiable-consumer.sh --broker-list localhost:9092 --max-messages 10000 --topic burrow-topic --group-id burrow-group</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>En los consumidores podremos comprobar como cada uno obtiene una partici√≥n distinta.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Volvemos a listar los consumidores y comprobamos como aparece el consumidor de burrow y nuestro grupo de consumidores</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   181  100   181    0     0   176k      0 --:--:-- --:--:-- --:--:--  176k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer list returned&quot;,
  &quot;consumers&quot;: [
    &quot;burrow-group&quot;,
    &quot;burrow-myconsumers&quot;
  ],
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Comprobamos como nos indica de forma sencilla que un grupo est√° funcionando correctamente:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer/burrow-group/status | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   608  100   608    0     0   593k      0 --:--:-- --:--:-- --:--:--  593k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer status returned&quot;,
  &quot;status&quot;: {
    &quot;cluster&quot;: &quot;kafka-cluster&quot;,
    &quot;group&quot;: &quot;burrow-group&quot;,
    &quot;status&quot;: &quot;OK&quot;,
    &quot;complete&quot;: 1,
    &quot;partitions&quot;: [],
    &quot;partition_count&quot;: 3,
    &quot;maxlag&quot;: {
      &quot;topic&quot;: &quot;burrow-topic&quot;,
      &quot;partition&quot;: 0,
      &quot;owner&quot;: &quot;/192.168.15.100&quot;,
      &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
      &quot;status&quot;: &quot;OK&quot;,
      &quot;start&quot;: {
        &quot;offset&quot;: 28,
        &quot;timestamp&quot;: 1604851337376,
        &quot;observedAt&quot;: 1604851337000,
        &quot;lag&quot;: 0
      },
      &quot;end&quot;: {
        &quot;offset&quot;: 37,
        &quot;timestamp&quot;: 1604851346471,
        &quot;observedAt&quot;: 1604851346000,
        &quot;lag&quot;: 0
      },
      &quot;current_lag&quot;: 0,
      &quot;complete&quot;: 1
    },
    &quot;totallag&quot;: 0
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer/burrow-group/status&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>En caso de no funcionar correctamente mostrar√≠a algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">...
&quot;status&quot;:&quot;WARN&quot;
...
&quot;lag&quot;:113441213</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Consultamos expl√≠citamene el lag</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server Burrow]$ curl localhost:8083/v3/kafka/kafka-cluster/consumer/burrow-group/lag | jq
% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100  1536  100  1536    0     0   750k      0 --:--:-- --:--:-- --:--:--  750k
{
  &quot;error&quot;: false,
  &quot;message&quot;: &quot;consumer status returned&quot;,
  &quot;status&quot;: {
    &quot;cluster&quot;: &quot;kafka-cluster&quot;,
    &quot;group&quot;: &quot;burrow-group&quot;,
    &quot;status&quot;: &quot;OK&quot;,
    &quot;complete&quot;: 1,
    &quot;partitions&quot;: [
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 0,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 47,
          &quot;timestamp&quot;: 1604851356381,
          &quot;observedAt&quot;: 1604851356000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 56,
          &quot;timestamp&quot;: 1604851365429,
          &quot;observedAt&quot;: 1604851365000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      },
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 1,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 47,
          &quot;timestamp&quot;: 1604851356989,
          &quot;observedAt&quot;: 1604851356000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 56,
          &quot;timestamp&quot;: 1604851366031,
          &quot;observedAt&quot;: 1604851366000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      },
      {
        &quot;topic&quot;: &quot;burrow-topic&quot;,
        &quot;partition&quot;: 2,
        &quot;owner&quot;: &quot;/192.168.15.100&quot;,
        &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
        &quot;status&quot;: &quot;OK&quot;,
        &quot;start&quot;: {
          &quot;offset&quot;: 160,
          &quot;timestamp&quot;: 1604851363214,
          &quot;observedAt&quot;: 1604851363000,
          &quot;lag&quot;: 0
        },
        &quot;end&quot;: {
          &quot;offset&quot;: 169,
          &quot;timestamp&quot;: 1604851366230,
          &quot;observedAt&quot;: 1604851366000,
          &quot;lag&quot;: 0
        },
        &quot;current_lag&quot;: 0,
        &quot;complete&quot;: 1
      }
    ],
    &quot;partition_count&quot;: 3,
    &quot;maxlag&quot;: {
      &quot;topic&quot;: &quot;burrow-topic&quot;,
      &quot;partition&quot;: 0,
      &quot;owner&quot;: &quot;/192.168.15.100&quot;,
      &quot;client_id&quot;: &quot;consumer-burrow-group-1&quot;,
      &quot;status&quot;: &quot;OK&quot;,
      &quot;start&quot;: {
        &quot;offset&quot;: 47,
        &quot;timestamp&quot;: 1604851356381,
        &quot;observedAt&quot;: 1604851356000,
        &quot;lag&quot;: 0
      },
      &quot;end&quot;: {
        &quot;offset&quot;: 56,
        &quot;timestamp&quot;: 1604851365429,
        &quot;observedAt&quot;: 1604851365000,
        &quot;lag&quot;: 0
      },
      &quot;current_lag&quot;: 0,
      &quot;complete&quot;: 1
    },
    &quot;totallag&quot;: 0
  },
  &quot;request&quot;: {
    &quot;url&quot;: &quot;/v3/kafka/kafka-cluster/consumer/burrow-group/lag&quot;,
    &quot;host&quot;: &quot;kafka-server.local&quot;
  }
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Fin del laboratorio</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_seguridad_en_kafka">16. Seguridad en Kafka</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p><strong>Kafka</strong> ofrece distintas opciones de seguridad, son bastante interesantes si queremos aplicarlas a nuestro cl√∫ster.</p>
</li>
<li>
<p>Las distintas funcionalidades que podemos tener son:</p>
<div class="ulist">
<ul>
<li>
<p>Autenticaci√≥n mediante <strong>SSL</strong></p>
</li>
<li>
<p>Autenticaci√≥n de conexiones entre los <strong>Brokers</strong> y <strong>Zookeeper</strong></p>
</li>
<li>
<p>Autorizaci√≥n de lecturas y/o escrituras para los clientes</p>
</li>
<li>
<p>Soporte de servicios externos de autenticaci√≥n</p>
</li>
<li>
<p>Cifrado de los datos mediante <strong>SSL</strong> para la comunicaci√≥n.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_c√≥mo_funciona_la_seguridad">16.1. C√≥mo funciona la seguridad</h3>
<div class="ulist">
<ul>
<li>
<p>La seguridad en las comunicaciones es algo vital.</p>
</li>
<li>
<p>Los primeros ejemplos documentados de comunicaci√≥n cifrada, datan de la √©poca del Imperio Romano, donde Julio C√©sar usaba un m√©todo simple para comunicarse con sus generales, desplazaban 13 veces en el alfabeto la letra le√≠da, de tal manera que el mensaje "Ataquen" se convert√≠a en "MFMCGQZ".</p>
</li>
<li>
<p>Cuando los generales recib√≠an el mensaje realizaban la operaci√≥n inversa (es decir, se mov√≠an 13 veces en el alfabeto en sentido inverso).</p>
</li>
<li>
<p>Este es un ejemplo de <strong>cifrado con clave sim√©trica</strong>, en el que para cifrar y descifrar el mensaje, hacemos uso de una misma clave.</p>
</li>
<li>
<p>De hecho, las claves sim√©tricas eran la √∫nica opci√≥n que conoc√≠amos hasta hace relativamente poco.</p>
</li>
<li>
<p>Un ejemplo claro de esto fue la m√°quina enigma, utilizada durante la segunda guerra mundial.</p>
</li>
<li>
<p>De forma esquem√°tica, podr√≠amos decir que el proceso es como se muestra en la imagen:</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-01.png" alt="kafka seguridad 01" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A d√≠a de hoy seguimos contando con cifrados de clave sim√©trica, como AES, DES, TripleDES o Blowfish.</p>
<div class="ulist">
<ul>
<li>
<p>Su gran ventaja, son algoritmos muy veloces, ideales para el cifrado de gran cantidad de datos.</p>
</li>
<li>
<p>Su gran inconveniente, las dos partes deben poseer la clave, lo que supone un riesgo a la seguridad, ya que esta clave debe ser distribuida y en este momento podr√≠a ser interceptada y robada, compromentiendo la seguridad.  (¬øOs acord√°is de las t√≠picas pel√≠culas de esp√≠as, que iban con un malet√≠n esposado?)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-02.jpg" alt="kafka seguridad 02" width="600">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Frente a la criptograf√≠a de clave sim√©trica, tenemos la <strong>criptograf√≠a de clave asim√©trica</strong>. Dicha t√©cnica de cifrado no consiste en una √∫nica clave, si no en una pareja de ellas:</p>
<div class="ulist">
<ul>
<li>
<p>Clave privada, que jam√°s es distribuida, y cuyo propietario debe custodiar.</p>
</li>
<li>
<p>Clave p√∫blica, conocida por todos los usuarios y distribuida sin problemas.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Este sistema es mucho mas seguro, ya que suprime la necesidad del env√≠o de una clave que da poder total y absoluto. (!Se acabaron los esp√≠as con maletines!)</p>
</li>
<li>
<p>Por otro lado, tiene un importante inconveniente, es mucho m√°s lento (la operaci√≥n es m√°s compleja).</p>
</li>
<li>
<p>Para generar la pareja de claves se debe:</p>
<div class="ulist">
<ul>
<li>
<p>Escoger dos n√∫meros primos, <strong>p</strong> y <strong>q</strong></p>
</li>
<li>
<p>Calcular <strong>N</strong>, que es el resultado de multpilicar <strong>p x q</strong>.</p>
</li>
<li>
<p>Escoger un n√∫mero <strong>e</strong>, que debe ser primo a <strong>(p-1) x (q-1)</strong> (que no tengan divisores comunes entre ellos)</p>
</li>
<li>
<p>Calcular un n√∫mero <strong>d</strong>, que es el n√∫mero que cumple que <strong>(e x d) mod  p-1) x (q-1 = 1</strong></p>
</li>
<li>
<p>La clave p√∫blica es <strong>(N,e)</strong></p>
</li>
<li>
<p>La clave privada es <strong>(d)</strong></p>
</li>
<li>
<p>La informaci√≥n <strong>I</strong> se cifra con <strong>I^e mod N</strong></p>
</li>
<li>
<p>La informaci√≥n cifrada <strong>C</strong> se descifra con <strong>C^d mod N</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>Un ejemplo ser√≠a el siguiente</p>
<div class="ulist">
<ul>
<li>
<p>Escojo <strong>p=3</strong> y <strong>q=7</strong>, ambos n√∫meros primos</p>
</li>
<li>
<p>Calculo <strong>N=3 x 7=21</strong></p>
</li>
<li>
<p>Busco n√∫mero primo relativo a <strong>(p-1) x (q-1)=2 x 6=12</strong>, cojo <strong>e=5</strong> que es primo relativo a <strong>12</strong></p>
</li>
<li>
<p>Busco <strong>d</strong> en <strong>(e x d) mod  p-1) x (q-1 = 1</strong>, nos sale <strong>d=5</strong> (ya que <strong>25 mod 12 = 1</strong></p>
</li>
<li>
<p>Clave p√∫blica <strong>(N,e)</strong> es <strong>(21,5)</strong></p>
</li>
<li>
<p>Clave privada <strong>d</strong> es <strong>5</strong></p>
</li>
<li>
<p>Voy a cifrar un <strong>M</strong> que vale 4: <strong>C=M^e mod N</strong> que es <strong>4^5 mod 21 = 1024 mod 21=16</strong></p>
</li>
<li>
<p>Voy a descifrar <strong>C</strong> que es <strong>16</strong>: <strong>D=C^d mod N</strong> que es <strong>16^5 mod 21 = 1048576 mod 21 = 4</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>Ahora que entendemos c√≥mo se generan las claves de cifrado asim√©tricas, vamos qu√© opciones tenemos para comunicar dos partes:</p>
<div class="ulist">
<ul>
<li>
<p>Una de las partes (A), posee una pareja de claves p√∫blica/privada.</p>
</li>
<li>
<p>La otra parte (B), no posee ninguna:</p>
</li>
<li>
<p><strong>A</strong> puede usar su clave privada para cifrar la informaci√≥n y enviarla a <strong>B</strong>.</p>
</li>
<li>
<p>Cualquiera puede usar la clave p√∫blica de <strong>A</strong> para abrir el mensaje, con lo que no existe confidencialidad, pero <strong>B</strong> se asegura de que el mensaje fue emitido por <strong>A</strong>, puesto que tuvo que cifrarlo con su clave privada. <strong>* Existe *autenticidad</strong> de emisor.</p>
</li>
<li>
<p><strong>B</strong> puede cifrar mensajes con la clave p√∫blica de <strong>A</strong> y envi√°rselos a <strong>A</strong>.</p>
</li>
<li>
<p>Nadie m√°s puede ver este mensaje, por lo que aseguras la <strong>confidencialidad</strong>, ya que para descifrarlo s√≥lo puede usarse la clave privada de <strong>A</strong>.</p>
</li>
<li>
<p>Sin embargo, cualquier emisor podr√≠a suplantar a <strong>B</strong> (tan s√≥lo tiene que usar la clave p√∫blica de <strong>A</strong>), <strong>A</strong> no tiene la certeza de que su mensaje provenga de <strong>B</strong>.</p>
</li>
<li>
<p>Las dos partes tienen una pareja de claves p√∫blica/privada:</p>
</li>
<li>
<p>Ahora, podemos asegurar la <strong>confidencialidad</strong> y el <strong>autenticidad</strong>.</p>
</li>
<li>
<p>Cuando se van a intercambiar mensajes, se cifran dos veces.</p>
</li>
<li>
<p>Si <strong>A</strong> quiere enviar un mensaje a <strong>B</strong>, lo cifra primero con su clave privada, y luego con la clave p√∫blica de <strong>B</strong>.</p>
</li>
<li>
<p>Para que <strong>B</strong> lo pueda descifrar usa primero la clave p√∫blica de <strong>A</strong> (aseguramos emisor), y luego su propia clave privada (aseguramos confidencialidad).</p>
</li>
<li>
<p>De manera an√°loga, <strong>B</strong> puede enviar mensajes a <strong>A</strong> cifrandolos primero con su clave privada y luego con la clave p√∫blica de <strong>A</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Esto, es tremendamente costoso, con lo que por lo general, se usa esta comunicaci√≥n para intercambiar de forma segura una clave sim√©trica, y tras intercambiar esta clave, el resto de la comunicaci√≥n se cifra mediante ella.</p>
</li>
<li>
<p>Al intercambiar la clave como hemos dicho, nos aseguramos que nadie nos la intercepte.</p>
</li>
<li>
<p>Un ejemplo de una comunicaci√≥n usando s√≥lo una pareja de claves.</p>
</li>
</ul>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="./images/kafka-seguridad-03.png" alt="kafka seguridad 03" width="600">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_certificados_keystores_y_trustores">16.2. Certificados, Keystores y Trustores</h3>
<div class="ulist">
<ul>
<li>
<p>En el tema anterior vimos qu√© eran las claves de cifrado, y c√≥mo estaban compuestas de dos partes, la clave p√∫blica y la clave privada.</p>
</li>
<li>
<p>Con la intenci√≥n de almacenar las claves privadas propias, y las claves p√∫blicas de otros, surge el <strong>keystore</strong>.</p>
</li>
<li>
<p>Este no es nada m√°s que un almac√©n de claves.</p>
</li>
<li>
<p>Un fichero de nuestro disco que va a contener un conjunto de claves.</p>
</li>
<li>
<p>Llegados a este punto, pod√≠amos asegurarnos de que la comunicaci√≥n con otro sistema era segura, pero ¬øqui√©n nos certifica que quien est√° usando unas claves, es quien dice ser?.</p>
<div class="ulist">
<ul>
<li>
<p>Por ejemplo, yo me conecto a la web de la <strong>AEAT</strong>, y voy a hacer mi declaraci√≥n.</p>
</li>
<li>
<p>Si un tercero lo suplantar y tuviera su propio conjunto de claves, ¬øhabr√≠a manera de saber si mi comunicaci√≥n segura es realmente con dicho dominio, o no?</p>
</li>
<li>
<p>Para cubrir este supuesto surgen los <strong>certificados</strong>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Un <strong>certificado</strong> es una pareja de claves (p√∫blica/privada) cuya parte p√∫blica ha sido <strong>firmada</strong> por una <strong>entidad certificadora</strong>, es decir, se han asegurado de que el due√±o de dicho certificado es quien dice ser.</p>
</li>
<li>
<p>Ahora si nos roban nuestro dominio y nos intentan suplantar, podran tener comunicaci√≥n segura pero les saltar√° una advertencia, de que no han podido comprobar la autenticidad de dicho dominio.</p>
</li>
<li>
<p>Pero <strong>who watches the watchmen?</strong>. ¬øqui√©n me asegura que la <strong>entidad certificadora</strong> ha hecho su trabajo?.</p>
</li>
<li>
<p>Existen varias entidades certificadoras, nosotros podemos decidir en cu√°l confiar y en cu√°l no.</p>
</li>
<li>
<p>Para aquellas entidades en las que confiemos, guardaremos su clave p√∫blica de cifrado en nuestro <strong>Trustore</strong>, que es otro almac√©n, donde almaceno s√≥lo aquellas entidades en las que conf√≠o.</p>
</li>
<li>
<p>Ahora, si me comunico con un nuevo sistema, puedo confiar en qui√©n dice ser porque posee una firma que puedo comprobar.</p>
</li>
<li>
<p>Brevemente, para conseguir un certificado digital, necesitamos:</p>
<div class="ulist">
<ul>
<li>
<p>Generar una pareja de claves p√∫blica/privada</p>
</li>
<li>
<p>Emitir una petici√≥n de firmado de certificado (que basicamente es la clave p√∫blica)</p>
</li>
<li>
<p>Enviar dicha petici√≥n a la entidad certificadora</p>
</li>
<li>
<p>La entidad verificadora se asegurar√° de que eres quien dices ser (nombres, direcciones, se pondr√° en contacto, etc&#8230;&#8203;)</p>
</li>
<li>
<p>La entidad certificadora firma el certificado, y nos lo devuelve</p>
</li>
<li>
<p>Ya puedo comunicarme sin problemas con todos los dem√°s sistemas que conf√≠en en dicha entidad certificadora.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_seguridad_en_clientes">16.3. Seguridad en clientes</h3>
<div class="ulist">
<ul>
<li>
<p>La implementaci√≥n de seguridad en productores y consumidores se realiza a partir del certificado cliente.</p>
</li>
<li>
<p>Este certificado cliente de confianza generado con los certificados del servidor permite autenticar y autorizar un cliente</p>
</li>
<li>
<p>La configuraci√≥n que se debe definir es la siguiente:</p>
</li>
<li>
<p>Primero definimos el protocolo SSL como activo</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">security.protocol</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">SSL</span><span class="delimiter">&quot;</span></span>);</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.truststore.location</span><span class="delimiter">&quot;</span></span>, trustStoreLocation);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.truststore.password</span><span class="delimiter">&quot;</span></span>, trustStorePassword);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no est√° habilitada la autenticaci√≥n de clientes, esta segunda parte no es necesaria.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.key.password</span><span class="delimiter">&quot;</span></span>, keyStorePassword);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.keystore.password</span><span class="delimiter">&quot;</span></span>, keyStorePassword);
props.put(<span class="string"><span class="delimiter">&quot;</span><span class="content">ssl.keystore.location</span><span class="delimiter">&quot;</span></span>, keyStoreLocation);</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Otras opciones que podemos configurar:</p>
<div class="ulist">
<ul>
<li>
<p><strong>ssl.provider</strong>: El nombre del proveedor de seguridad usado para conexiones SSL</p>
</li>
<li>
<p><strong>ssl.cipher.suites</strong>: Un conjunto de cifrados usados para negociaci√≥n</p>
</li>
<li>
<p><strong>ssl.enabled.protocols</strong>: Debe poseer alguno de los protocolos del broker (TLSv1.2,TLSv1.1,TLSv1)</p>
</li>
<li>
<p><strong>ssl.truststore.type</strong>: JKS</p>
</li>
<li>
<p><strong>ssl.keystore.type</strong>: JKS</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sasl">16.3.1. SASL</h4>
<div class="ulist">
<ul>
<li>
<p>Kafka usa JAAS (Java Authentication and Authorization Service) para configurar SASL</p>
</li>
<li>
<p>Para configurar JAAS, debemos generar un fichero est√°tico</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Contenido del fichero /etc/kafka/kafka_client_jaas.conf</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json"><span class="error">K</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">C</span><span class="error">l</span><span class="error">i</span><span class="error">e</span><span class="error">n</span><span class="error">t</span> {
    <span class="error">c</span><span class="error">o</span><span class="error">m</span><span class="error">.</span><span class="error">s</span><span class="error">u</span><span class="error">n</span><span class="error">.</span><span class="error">s</span><span class="error">e</span><span class="error">c</span><span class="error">u</span><span class="error">r</span><span class="error">i</span><span class="error">t</span><span class="error">y</span><span class="error">.</span><span class="error">a</span><span class="error">u</span><span class="error">t</span><span class="error">h</span><span class="error">.</span><span class="error">m</span><span class="error">o</span><span class="error">d</span><span class="error">u</span><span class="error">l</span><span class="error">e</span><span class="error">.</span><span class="error">K</span><span class="error">r</span><span class="error">b</span><span class="integer">5</span><span class="error">L</span><span class="error">o</span><span class="error">g</span><span class="error">i</span><span class="error">n</span><span class="error">M</span><span class="error">o</span><span class="error">d</span><span class="error">u</span><span class="error">l</span><span class="error">e</span> <span class="error">r</span><span class="error">e</span><span class="error">q</span><span class="error">u</span><span class="error">i</span><span class="error">r</span><span class="error">e</span><span class="error">d</span>
    <span class="error">u</span><span class="error">s</span><span class="error">e</span><span class="error">K</span><span class="error">e</span><span class="error">y</span><span class="error">T</span><span class="error">a</span><span class="error">b</span><span class="error">=</span><span class="value">true</span>
    <span class="error">s</span><span class="error">t</span><span class="error">o</span><span class="error">r</span><span class="error">e</span><span class="error">K</span><span class="error">e</span><span class="error">y</span><span class="error">=</span><span class="value">true</span>
    <span class="error">k</span><span class="error">e</span><span class="error">y</span><span class="error">T</span><span class="error">a</span><span class="error">b</span><span class="error">=</span><span class="string"><span class="delimiter">&quot;</span><span class="content">/etc/security/keytabs/kafka_client.keytab</span><span class="delimiter">&quot;</span></span>
    <span class="error">p</span><span class="error">r</span><span class="error">i</span><span class="error">n</span><span class="error">c</span><span class="error">i</span><span class="error">p</span><span class="error">a</span><span class="error">l</span><span class="error">=</span><span class="string"><span class="delimiter">&quot;</span><span class="content">kafka-client@kafka.local</span><span class="delimiter">&quot;</span></span><span class="error">;</span>
}<span class="error">;</span></code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Para poder cargar JAAS, en la ejecuci√≥n de java, debemos indicar la siguiente directiva:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="json"> <span class="error">-</span><span class="error">D</span><span class="error">j</span><span class="error">a</span><span class="error">v</span><span class="error">a</span><span class="error">.</span><span class="error">s</span><span class="error">e</span><span class="error">c</span><span class="error">u</span><span class="error">r</span><span class="error">i</span><span class="error">t</span><span class="error">y</span><span class="error">.</span><span class="error">a</span><span class="error">u</span><span class="error">t</span><span class="error">h</span><span class="error">.</span><span class="error">l</span><span class="error">o</span><span class="error">g</span><span class="error">i</span><span class="error">n</span><span class="error">.</span><span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">f</span><span class="error">i</span><span class="error">g</span><span class="error">=</span><span class="error">/</span><span class="error">e</span><span class="error">t</span><span class="error">c</span><span class="error">/</span><span class="error">k</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">/</span><span class="error">k</span><span class="error">a</span><span class="error">f</span><span class="error">k</span><span class="error">a</span><span class="error">_</span><span class="error">c</span><span class="error">l</span><span class="error">i</span><span class="error">e</span><span class="error">n</span><span class="error">t</span><span class="error">_</span><span class="error">j</span><span class="error">a</span><span class="error">a</span><span class="error">s</span><span class="error">.</span><span class="error">c</span><span class="error">o</span><span class="error">n</span><span class="error">f</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_autenticaci√≥n_sasl">16.4. Autenticaci√≥n SASL</h3>
<div class="ulist">
<ul>
<li>
<p>Como m√©todo adicional, poseemos la opci√≥n de aplicar SASL</p>
<div class="ulist">
<ul>
<li>
<p>Simple Authentication Service Layer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Permite separar el mecanismo de autenticaci√≥n del protocolo de Kafka.</p>
</li>
<li>
<p>Posee m√∫ltiples formas de configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_sasl_plaintext">16.4.1. SASL PLAINTEXT</h4>
<div class="ulist">
<ul>
<li>
<p>Permite definir usuario/password</p>
</li>
<li>
<p>Esta informaci√≥n se almacena en los brokers.</p>
</li>
<li>
<p>Cada modificaci√≥n de este sistema necesita un reinicio de los brokers para.</p>
</li>
<li>
<p>No se recomienda para entornos productivos</p>
</li>
<li>
<p>Se debe definir tambi√©n la capa SSL para evitar enviar los datos en plano por el protocolo http.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_sasl_scram">16.4.2. SASL SCRAM</h4>
<div class="ulist">
<ul>
<li>
<p>Permite usar username/password pero con encriptaci√≥n de usuario.</p>
</li>
<li>
<p>Los datos se almacenan en Zookeeper, lo que permite escalar la autenticaci√≥n</p>
</li>
<li>
<p>No es necesario su reinicio</p>
</li>
<li>
<p>Se debe unir junto a SSL para evitar enviar datos en plano</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_sasl_gssapi_kerberos">16.4.3. SASL GSSAPI (Kerberos)</h4>
<div class="ulist">
<ul>
<li>
<p>Permite usar el mecanismo de kerberos basado en tickets</p>
</li>
<li>
<p>Microsoft Active Directory es el mas com√∫n</p>
</li>
<li>
<p>Permite gestionar la seguridad desde un servidor kerberos</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_autorizaci√≥n">16.5. Autorizaci√≥n</h3>
<div class="ulist">
<ul>
<li>
<p>Tras la encriptaci√≥n del canal y la autenticaci√≥n, toca autorizar</p>
</li>
<li>
<p>Est√° controlado por las listas de control de acceso o ACLs</p>
</li>
<li>
<p>Permite</p>
<div class="ulist">
<ul>
<li>
<p><strong>Usuario</strong> A <strong>pueda/o no</strong> hacer la <strong>Operaci√≥n</strong> B en el <strong>Host</strong> C en cualquier <strong>recurso</strong> D que cumpla el <strong>patr√≥n</strong> E</p>
</li>
</ul>
</div>
</li>
<li>
<p>No est√° creado para agrupar reglas o aplicar REGEX para aplicaci√≥n de reglas.</p>
</li>
<li>
<p>Cada regla de seguridad debe ser completamente escrita.</p>
</li>
<li>
<p>Admite wildcards</p>
</li>
<li>
<p>Permite que un topic sea escrito solo por un conjunto de clientes concreto y que sea leido por otro grupo concreto.</p>
</li>
<li>
<p>Podemos usar el comando kafka-acl.sh para gestionar productores y consumidores:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">$ kafka-acl.sh --topic acl-test --producer --authorizer-properties zookeeper.connect=kafka-server.local --add --allow-principal User:alumno</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si usamos el SimpleACLAuthorizer, los datos se guardar√°n en zookeeper.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>authorizer.class.name=kafka.security.authorizer.SimpleAclAuthorizer</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si no existe regla que gestione al usuario y al recurso, por defecto deniega el servicio</p>
</li>
<li>
<p>Se puede cambiar el comportamiento usando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>allow.everyone.if.no.acl.found=true</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Podemos crear la lista de superusuarios desde el server.properties</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code>super.users=User:alumno;User:profesor</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_operaciones">16.5.1. Operaciones</h4>
<div class="ulist">
<ul>
<li>
<p>Las operaciones disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>Read</p>
</li>
<li>
<p>Write</p>
</li>
<li>
<p>Create</p>
</li>
<li>
<p>Delete</p>
</li>
<li>
<p>Alter</p>
</li>
<li>
<p>Describe</p>
</li>
<li>
<p>ClusterAction</p>
</li>
<li>
<p>DescribeConfigs</p>
</li>
<li>
<p>AlterConfigs</p>
</li>
<li>
<p>IdempotentWrite</p>
</li>
<li>
<p>All</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_recursos">16.5.2. Recursos</h4>
<div class="ulist">
<ul>
<li>
<p>Los recursos disponibles son:</p>
<div class="ulist">
<ul>
<li>
<p>Topic: Incluye todas las operaciones contra un Topic</p>
</li>
<li>
<p>Group: Indica los grupos de consumidores en el broker</p>
</li>
<li>
<p>Cluster: Operaciones como apagado del servicio</p>
</li>
<li>
<p>TransactionalId: Implica acciones de transacciones como las confirmaciones (commit)</p>
</li>
<li>
<p>DelegationToken: Representa los tokens de delegaci√≥n en el cluster.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="sect2">
<h3 id="_lab_aplicando_seguridad_en_kafka">16.6. Lab: Aplicando seguridad en Kafka</h3>
<div class="ulist">
<ul>
<li>
<p>Para poder tener una comunicaci√≥n segura con nuestro <strong>brokers</strong>, vamos a cifrar la comunicaci√≥n mediante el uso de claves de cifrado asim√©tricas.</p>
</li>
<li>
<p>Para ello tendremos que crear</p>
<div class="ulist">
<ul>
<li>
<p>Una pareja de claves p√∫blica/privada, que tendremos en nuestro <strong>keystore</strong></p>
</li>
<li>
<p>Una entidad certificadora, que deberemos a√±adir a nuestro <strong>trustore</strong></p>
</li>
<li>
<p>Un certificado firmado (por nuestra entidad certificadora)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Para ello, usaremos la herramienta <strong>keytool</strong> que viene disponible en el propio <strong>JDK</strong>.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_creaci√≥n_del_keystore_y_la_pareja_de_claves_p√∫blicaprivada">16.6.1. Creaci√≥n del keystore y la pareja de claves p√∫blica/privada</h4>
<div class="paragraph">
<p>Llamaremos a <strong>keytool</strong> (desde nuestro $HOME), indicando d√≥nde va a crear ese <strong>keystore</strong>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Indicaremos que genere una clave con <strong>-genkey</strong>, y hemos especificado la validez de dicha clave (360 d√≠as).</p>
</li>
<li>
<p>El <strong>alias</strong> con el que almacenaremos esta clave en nuestro <strong>keystore</strong> es <strong>kafkakafka</strong></p>
</li>
<li>
<p>Al ejecutar dicho comando, nos van a pedir distintos datos, (para nuestro ejemplo usaremos la clave <strong>usuario</strong>)</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -keyalg RSA -validity 360 -genkey
Enter keystore password:
Re-enter new password:
What is your first and last name?
  [Unknown]:  Curso Kafka
What is the name of your organizational unit?
  [Unknown]:  N/A
What is the name of your organization?
  [Unknown]:  Curso
What is the name of your City or Locality?
  [Unknown]:  Madrid
What is the name of your State or Province?
  [Unknown]:  Madrid
What is the two-letter country code for this unit?
  [Unknown]:  ES
Is CN=Curso Kafka, OU=N/A, O=Curso, L=Madrid, ST=Madrid, C=ES correct?
  [no]:  yes</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Al acabar, veremos que hay un fichero <strong>server.keystore.jks</strong> en la ruta en la que hemos ejecutado nuestro comando.</p>
</li>
<li>
<p>Siempre podemos consultar la informaci√≥n de nuestro <strong>keystore</strong> (siempre que tengamos su clave, claro) con el siguiente comando:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Desde la versi√≥n de JDK 8.51 a veces tiene problemas con los idiomas, si da error al ejecutarlo, probad a a√±adirle <strong>-J-Duser.language=en</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -J-Duser.language=en -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a crear ahora nuestro entidad certificadora, y para ello vamos a usar <strong>openssl</strong>.</p>
</li>
<li>
<p>Generaremos tanto la clave privada (que llamaremos ca-key) como la parte p√∫blica (que llamaremos ca-cert):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl req -new -x509 -keyout ca-key -out ca-cert -days 365</code></pre>
</div>
</div>
<div class="paragraph">
<p>Al igual que cuando generamos nuestro <strong>keystore</strong>, nos solicitar√° cierta informaci√≥n (y vuelvo a usar <strong>usuario</strong> como clave)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">Generating a 2048 bit RSA private key
............+++
...........+++
writing new private key to 'ca-key'
Enter PEM pass phrase:
Verifying - Enter PEM pass phrase:
[...]
Country Name (2 letter code) [XX]:ES
State or Province Name (full name) []:Madrid
Locality Name (eg, city) [Default City]:Madrid
Organization Name (eg, company) [Default Company Ltd]:Entidad Certificadora
Organizational Unit Name (eg, section) []:NA
Common Name (eg, your name or your server's hostname) []:
Email Address []:</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Bien, tenemos nuestro <strong>keystore</strong>, tenemos una <strong>entidad certificadora</strong>.</p>
</li>
<li>
<p>Vamos a decir que confiamos en dicha entidad a√±adiendo su clave p√∫blica a nuestro <strong>trustore</strong> (que todav√≠a no existe, lo crearemos con el nombre de <strong>server.trustore.jks</strong>).</p>
</li>
<li>
<p>Recordemos, si estamos con Java 8, mejor especificar el idioma con <strong>-J-Duser.language=en</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">% keytool -keystore server.truststore.jks -alias EntidadNoFake -import -file ca-cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>Una vez hecho esto, podemos confirmar que el certificado est√° disponible con <strong>-list</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -J-Duser.language=en -list -v -keystore server.truststore.jks</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ya tenemos un <strong>keystore</strong> y un <strong>trustore</strong>, en sus respectivos ficheros.</p>
</li>
<li>
<p>Generamos una petici√≥n de certificaci√≥n para nuestra clave almacenada con el <strong>alias</strong> de <strong>kafka</strong>, es decir, vamos a generar un fichero que contiene nuestra clave p√∫blica y nuestros datos para enviar a una <strong>entidad certificadora</strong>, y que nos lo devuelva firmado, corroborando que dicha informaci√≥n es correcta. Para ello usaremos la opci√≥n <strong>-certreq</strong>, que nos generar√° un fichero para firmar (especificado en <strong>-file</strong>).</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -certreq -file cert-file</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Tras introducir la clave de nuestro <strong>keystore</strong>, generamos el fichero <strong>cert-file</strong> que hemos solicitado, con lo que ya podemos realizar el firmado de nuestra clave.</p>
</li>
<li>
<p>Bueno, ahora vamos a usar <strong>openssl</strong> para firmar la petici√≥n de certificaci√≥n que hemos creado en el punto anterior:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days 360 -CAcreateserial -passin pass:usuario</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>-CA &#8594; La clave privada de la entidad certificadora</p>
</li>
<li>
<p>-in &#8594; fichero sobre el que vamos a realizar el firmado</p>
</li>
<li>
<p>-out &#8594; Fichero destino</p>
</li>
<li>
<p>Al acabar, tendremos en <strong>cert-signed</strong> nuestro certificado, ahora si, firmado.</p>
</li>
<li>
<p>Por √∫ltimo, vamos a importar el certificado generado y la clave p√∫blica de la entidad certificadora a nuestro <strong>keystore</strong> (acordaros del <strong>-J-Duser.language=en</strong> si us√°is Java 8):</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias EntidadNoFake -import -file ca-cert
[kafka@kafka-server ~]$ keytool -keystore server.keystore.jks -alias kafka -import -file cert-signed</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Si list√°is ahora con la siguiente instrucci√≥n, ver√©is que ten√©is dos entradas, y dentro de <strong>kafka</strong> figuran los datos de la entidad certificadora que nos ha firmado.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -list -v -keystore server.keystore.jks</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_securizando_los_brokers">16.6.2. Securizando los Brokers</h4>
<div class="ulist">
<ul>
<li>
<p>En primer lugar, tenemos que editar los ficheros de configuraci√≥n de nuestros <strong>brokers</strong>, y cambiar la propiedad <strong>listeners</strong>, donde especificaremos c√≥mo vamos a escuchar.</p>
</li>
<li>
<p>Antes ten√≠amos algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=PLAINTEXT://kafka-server.local:9092</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Ahora tendremos algo como:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Podr√≠amos configurar para escuchar de las dos formas, en distintos puertos, podr√≠amos hacer algo como:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102,PLAINTEXT://kafka-server.local:9092</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>Modificaremos los 3 ficheros y cambiaremos los listeners por <strong>SSL</strong>, dej√°ndolos as√≠:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">kafka-server.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-server.local:9102</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">kafka-node1.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-node1.local:9102</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">kafka-node2.local</div>
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">listeners=SSL://kafka-node2.local:9102</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Hemos pedido que s√≥lo se puedan comunicar v√≠a <strong>SSL</strong>, pero ¬øc√≥mo saben d√≥nde est√° su <strong>keystore</strong>? ¬øy su <strong>trustore</strong>?.</p>
</li>
<li>
<p>Tenemos que especificarlo, as√≠ que tendremos que a√±adir a cada fichero las siguientes configuraciones:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">ssl.keystore.location=/home/kafka/server.keystore.jks
ssl.keystore.password=usuario
ssl.key.password=usuario
ssl.truststore.location=/home/kafka/server.truststore.jks
ssl.truststore.password=usuario
security.inter.broker.protocol=SSL
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Iniciamos los tres <strong>Brokers</strong></p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ sudo systemctl restart kafka
[kafka@kafka-server ~]$ sudo systemctl -H kafka-node1.local restart kafka
[kafka@kafka-server ~]$ sudo systemctl -H kafka-node2.local restart kafka</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Recomendamos hacerlo de uno en uno, y vigilar las trazas con:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ tail -f $KAFKA_HOME/logs/kafkaServer.out</code></pre>
</div>
</div>
<div class="paragraph">
<p>Podemos verificar que est√° escuchando mediante <strong>SSL</strong> con el siguiente comando:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ openssl s_client -debug -connect kafka-server.local:9102 -tls1
CONNECTED(00000003)
write to 0x2683900 [0x269d383] (181 bytes =&gt; 181 (0xB5))
0000 - 16 03 01 00 b0 01 00 00-ac 03 01 a9 ad 97 c1 1f   ................
0010 - 4b 1c 3c b0 84 95 cd 68-67 b8 de ca d6 b0 e2 63   K.&lt;....hg......c
0020 - d8 f4 17 f8 de 9f 22 44-e9 2b bd 00 00 64 c0 14   ......&quot;D.+...d..
0030 - c0 0a 00 39 00 38 00 37-00 36 00 88 00 87 00 86   ...9.8.7.6......
0040 - 00 85 c0 0f c0 05 00 35-00 84 c0 13 c0 09 00 33   .......5.......3
0050 - 00 32 00 31 00 30 00 9a-00 99 00 98 00 97 00 45   .2.1.0.........E
0060 - 00 44 00 43 00 42 c0 0e-c0 04 00 2f 00 96 00 41   .D.C.B...../...A
0070 - c0 12 c0 08 00 16 00 13-00 10 00 0d c0 0d c0 03   ................
0080 - 00 0a 00 07 c0 11 c0 07-c0 0c c0 02 00 05 00 04   ................
0090 - 00 ff 01 00 00 1f 00 0b-00 04 03 00 01 02 00 0a   ................
00a0 - 00 0a 00 08 00 17 00 19-00 18 00 16 00 23 00 00   .............#..
00b0 - 00 0f 00 01 01
...</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_securizando_los_clientes">16.6.3. Securizando los Clientes</h4>
<div class="paragraph">
<p>Si queremos que nuestros clientes puedan conectarse mediante <strong>SSL</strong> a nuestros <strong>Brokers</strong>, tenemos que dar de alta la entidad certificadora en su propio <strong>keystore</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore client.truststore.jks -alias EntidadNoFake -import -file ca-cert</code></pre>
</div>
</div>
<div class="paragraph">
<p>Y en su fichero <strong>properties</strong>, tenemos que a√±adir las siguientes opciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Vamos a hacer esto mismo con el productor y consumidor de consola.</p>
</li>
<li>
<p>Copiamos los ficheros <strong>$KAFKA_HOME/config/consumer.properties</strong> y <strong>$KAFKA_HOME/config/producer.properties</strong> a producer-ssl.properties y consumer-ssl.properties agregando la siguiente configuraci√≥n:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=/home/kafka/client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Creamos un <strong>Topic</strong> sobre el que hacer las pruebas:</p>
</li>
<li>
<p>Para ello creamos un fichero llamado ssl.properties con la misma configuraci√≥n que los clientes</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">security.protocol=SSL
ssl.truststore.location=/home/kafka/client.truststore.jks
ssl.truststore.password=usuario
ssl.endpoint.identification.algorithm=</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos la petici√≥n</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>Aunque de warning el uso del fichero ssl indicando que las directivas no aplican, si est√°n aplicando y son necesarias ya que sino no es capaz de conectar al servicio.</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-topics.sh --bootstrap-server kafka-server.local:9102 --create --topic topic-seguro --partitions 5 --replication-factor 1 --command-config ssl.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Y lanzamos nuestro productor:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-producer.sh --broker-list kafka-node1:9102 --topic topic-seguro --property parse.key=true --property key.separator=, --producer.config $KAFKA_HOME/config/producer-ssl.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Lanzamos nuestro consumidor, y verificamos que todo marcha como esper√°bamos:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ kafka-console-consumer.sh --bootstrap-server kafka-node2:9102 --topic topic-seguro --property print.key=true --consumer.config $KAFKA_HOME/config/consumer-ssl.properties --from-beginning</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_autenticar_clientes">16.6.4. Autenticar clientes</h4>
<div class="ulist">
<ul>
<li>
<p>Si os veis en la necesidad de autenticar clientes contra el broker, vamos a dejar escrito los pasos que se deber√≠an dar:</p>
<div class="ulist">
<ul>
<li>
<p>Habitilar la opci√≥n <strong>ssl.client.auth=required</strong> en el <strong>server.properties</strong> de los <strong>brokers</strong></p>
</li>
<li>
<p>Generar un certificado para cada cliente, y firmarlo mediante la entidad certificadora</p>
</li>
<li>
<p>Importar el certificado del cliente firmado en el <strong>trustore</strong> de cada <strong>broker</strong></p>
</li>
</ul>
</div>
</li>
<li>
<p>A√±adir <strong>ssl.client.auth=required</strong>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ echo &quot;ssl.client.auth=required&quot; &gt;&gt; $KAFKA_HOME/config/server.properties</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Generar y firmar certificados</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore client.keystore.jks -alias kafka -keyalg RSA -certreq -file cert-file-client
[kafka@kafka-server ~]$ openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file-client -out cert-signed-client -days 360 -CAcreateserial -passin pass:usuario</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A√±adir al <strong>trustore</strong> del servidor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="bash">[kafka@kafka-server ~]$ keytool -keystore server.truststore.jks -alias localhost -import -file cert-signed-client</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Una vez hecho esto, bastar√≠a con reiniciar los <strong>brokers</strong>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2021-02-16 16:24:51 +0100
</div>
</div>
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</body>
</html>